    1  make -j32
    2   cd ~/pwd/saliency_on_videoset/_Train/
    3  git clone https://github.com/ndrplz/dilation-tensorflow.git
    4  cd dilation-tensorflow/
    5  python main_tf.py 
    6  python
    7  pytho
    8  python
    9  vim ~/.bashrc
   10  source ~/.bashrc
   11  python
   12  pwd
   13  cd /home/sunnycia/pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master
   14  ls model/
   15  python ./rfcn/demo.py
   16  pip install easydict
   17  python ./rfcn/demo.py
   18  pip install mxnet
   19  ls
   20  python
   21  cd /home/sunnycia/pwd/saliency_on_videoset/_Train/dilation-tensorflow
   22  python
   23  python main_tf.py 
   24  vim ~/.bashrc
   25  source ~/.bashrc
   26  python
   27  pwd
   28  top
   29  cd 
   30  cd pwd/saliency_on_videoset/_Train/dilation-tensorflow/
   31  python
   32  python main_tf.py 
   33  exit()
   34  pip uninstall tensorflow
   35  pip uninstall tensorflow-gpu
   36  cd ~
   37  git clone https://github.com/tensorflow/tensorflow 
   38  unzip tensorflow-master.zip 
   39  cd tensorflow-master/
   40  git checkout
   41  python
   42  cd ~
   43  python
   44  pip install tensorflow
   45  cd pwd/saliency_on_videoset/_Train/dilation-tensorflow/
   46  python main_tf.py 
   47  python
   48  pip install opencv-python
   49  python main_tf.py 
   50  pip uninstall tensorflow
   51  git clone https://github.com/bazelbuild/bazel.git
   52  cd ~
   53  git clone https://github.com/bazelbuild/bazel.git
   54  python
   55  pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp34-cp34m-linux_x86_64.whl
   56  pip install --ignore-installed https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp36-cp36m-linux_x86_64.whl
   57  python
   58  locate libcudnn*
   59  ls /usr/local
   60  cd cuda
   61  cd /usr/local/cuda
   62  ls
   63  cd lib
   64  cd lib64/
   65  ls
   66  ls lib cudnn*
   67  ls libcudnn*
   68  ls -l libcudnn*
   69  nvidia-smi
   70  top
   71  cd pwd/saliency_on_videoset/_Train/
   72  ls
   73  git clone https://github.com/sampepose/flownet2-tf.git
   74  ls
   75  ls flow*
   76  unzip flownet2-tf.zip 
   77  cd flownet2-tf/
   78  pip install enum
   79  python
   80  cd checkpoints/
   81  bash download.sh 
   82  vim download.sh 
   83  bash download.sh 
   84  ls
   85  tar -xzvf weights.tar.gz 
   86  cd ..
   87  ls src
   88  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
   89  python
   90  vim ~/.bahsrc
   91  vim ~/.bashrc
   92  source ~/.bashrc
   93  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
   94  cd pwd/saliency_on_videoset/_Train/
   95  cd flownet2-tf/
   96  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
   97  python
   98  vim ~/.bahsrc
   99  vim ~/.bashrc
  100  source ~/.bashrc
  101  python
  102  cd pwd/saliency_on_videoset/_Train/flownet2-tf/
  103  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  104  pip install image
  105  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  106  make all
  107  nvcc
  108  ls /usr/lib/nvi*
  109  ls /usr/lib
  110  ls nvidia-current
  111  nvcc
  112  vim ~/.bash_profile 
  113  vim ~/.bashrc
  114  source ~/.bashrc
  115  nvcc
  116  cd pwd/saliency_on_videoset/_Train/flownet2-tf/
  117  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  118  make clean
  119  make all
  120  make clean
  121  make -j16 all
  122  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  123  python -m src.flownet2.test --input_a data/samples/frame88.bmp --input_b data/samples/frame90.bmp --out ./
  124  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  125  export CUDA_VISIBLE_DEVICES=6
  126  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  127  python -m src.flownet2.test --input_a data/samples/frame88.bmp --input_b data/samples/frame90.bmp --out ./
  128  cd ..
  129  git clone https://github.com/shekkizh/FCN.tensorflow.git
  130  unzip FCN.tensorflow.zip 
  131  cd FCN.tensorflow/
  132  ls
  133  python FCN.py 
  134  cd Data_zoo/MIT_SceneParsing/
  135  unzip ADEChallengeData2016.zip 
  136  cd ../..
  137  python FCN.py 
  138  df -h
  139  cd /
  140  cd /data/
  141  ls
  142  cd sunnycia/
  143  ls
  144  cd YouTube8m/
  145  ls
  146  cd ..
  147  rm -rf YouTube8m/
  148  df -h
  149  pwd
  150  cd ~/pwd/
  151  du -h --max-depth=1 ./
  152  mv saliency_on_videoset/ /data/sunnycia/
  153  df -h
  154  ln -s /data/sunnycia/saliency_on_videoset/ saliency_on_videoset
  155  cd saliency_on_videoset/
  156  pwd
  157  cd pwd/saliency_on_videoset/
  158  ls
  159  cd _Train/
  160  cd FCN.tensorflow/
  161  python FCN.py 
  162  df -h
  163  ls /data
  164  ls /data/zhangpp/
  165  python FCN.py 
  166  cd pwd/saliency_on_videoset/
  167  pwd
  168  cd _Train/FCN.tensorflow/
  169  python FCN.py 
  170  top
  171  nvidia-smi 
  172  export CUDA_VISIBLE_DEVICES=6
  173  python FCN.py 
  174  cd pwd/saliency_on_videoset/_Train/
  175  cd FCN.tensorflow/
  176  python FCN --mode=test
  177  python FCN.py --mode=test
  178  bash ~/setup.sh 
  179  vim ~/setup.sh 
  180  bash ~/setup.sh 
  181  nvidia-smi
  182  top
  183  python FCN.py --mode=test
  184  python FCN.py --mode=visualize
  185  python FCN_inference.py 
  186  export CUDA_VISIBLE_DEVICES=6
  187  nvidia-smi
  188  python FCN_inference.py 
  189  xtermxtermxterm
  190  python FCN_inference.py 
  191  top
  192  nvidia-smi
  193  top
  194  free -h
  195  nvidia-smi
  196  ls
  197  cd pwd/
  198  ln -s /data/sunnycia/pwd/Industry/ Industry
  199  cd Industry/
  200  unzip A61.zip 
  201  cd ~/pwd/saliency_on_videoset/_Train/
  202  ls
  203  cd YT8M/
  204  ls
  205  cd yt8m-feature-extractor/
  206  ls
  207  pwd
  208  th
  209  luarock
  210  cd pwd/saliency_on_videoset/_Train/YT8M/
  211  l
  212  ls
  213  cd yt8m-feature-extractor/
  214  pwd
  215  cd /data/sunnycia/pwd/Industry/A61深度学习/黄保胶
  216  python parse_model.py 
  217  PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
  218  python parse_model.py 
  219  unzip tensorflow-vgg-master.zip 
  220  cd tensorflow-vgg-master/
  221  ls
  222  cd ..
  223  ls
  224  cd data/
  225  ls
  226  python gen_list.py 
  227  python gen_dat.py 
  228  cd training/OK/
  229  ls 
  230  python
  231  cd ..
  232  python gen_dat.py 
  233  python
  234  python gen_dat.py 
  235  python gen_lbl.py 
  236  ls
  237  cd ..
  238  python calc_mean.py 
  239  cd data/
  240  cd _scripts/
  241  python gen_dat.py 
  242  python gen_dat.py training
  243  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  244  cd ..
  245  python train_vgg19.py 
  246  cd data/_scripts/
  247  python gen_dat.py 
  248  history
  249  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  250  cd ../..
  251  python train_vgg19.py 
  252  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  253  cd data/_scripts/
  254  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  255  cd pwd/Industry/
  256  ls
  257  cd A61/
  258  l
  259  ls
  260  cd data/
  261  python gen_dat.py 
  262  top
  263  nvidia-smi
  264  free -h
  265  top
  266  nvidi-smi
  267  nviid-amsi
  268  nvidia-smi
  269  top
  270  free -h
  271  top
  272  free -h
  273  cd pwd/Industry/A61/data/_scripts/
  274  python gen_dat.py 
  275  history
  276  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  277  cd ../..
  278  python train_vgg19.py 
  279  cd pwd/Industry/A61/
  280  python train_vgg19.py 
  281  nvidia-smi
  282  export CUDA_VISIBLE_DEVICES=7
  283  python train_vgg19.py 
  284  cd data/_scripts/
  285  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  286  top
  287  nvidia-smi
  288  free -h
  289  cd pwd/Industry/A61/
  290  cd data/_scripts/
  291  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  292  python gen_dat.py 
  293  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  294  cd ../..
  295  python train_vgg19.py 
  296  nvidia-smi
  297  python train_vgg19.py 
  298  export CUDA_VISIBLE_DEVICES=7
  299  python train_vgg19.py 
  300  python
  301  python train_vgg19.py 
  302  cd data/_scripts/
  303  python gen_dat.py 
  304  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  305  cd ../..
  306  python train_vgg19.py 
  307  cd data/_scripts/
  308  python gen_dat.py 
  309  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  310  cd ../..
  311  python train_vgg19.py 
  312  cd data/_scripts/
  313  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  314  cd ../..
  315  python train_vgg19.py 
  316  nvidia-smi
  317  python train_vgg19.py 
  318  nvidia-smi
  319  export CUDA_VISIBLE_DEVICES=1
  320  cd pwd/Industry/A61/
  321  python train_vgg19.py 
  322  nvidia-smi
  323  history
  324  export CUDA_VISIBLE_DEVICES=0
  325  cd pwd/Industry/A61/
  326  python train_vgg19.py 
  327  top
  328  nvidia-smi
  329  otp
  330  top
  331  export CUDA_VISIBLE_DEVICES=7
  332  python train_vgg19.py 
  333  cd pwd/Industry/A61/patch_based/
  334  export CUDA_VISIBLE_DEVICES=6
  335  python train_vgg19.py 
  336  cd pwd/Industry/A61/patch_based/
  337  python train_vgg19.py 
  338  nvidia-smi
  339  export CUDA_VISIBLE_DEVICES=7
  340  python train_vgg19.py 
  341  cd /data/sunnycia/pwd/Industry/A61/data/_scripts
  342  python gen_list.py 
  343  python gen_dat.py 
  344  python gen_dat.py training_imgs.pkl training_lbls.pkl _ _
  345  python gen_dat.py 
  346  python gen_dat.py training_imgs.pkl training_lbls.pkl
  347  python gen_dat.py training_imgs.pkl training_lbls.pkl _ _
  348  nvidia-smi
  349  cd pwd/Industry/A61/patch_based/
  350  ls
  351  export CUDA_VISIBLE_DEVICES=6
  352  ls
  353  python 4_convolutional_network.py 
  354  python
  355  python 4_convolutional_network.py 
  356  export CUDA_VISIBLE_DEVICES=7
  357  cd pwd/Industry/A61/patch_based/
  358  python 4_convolutional_network.py 
  359  nvidia-smi
  360  top
  361  nvidia-smi
  362  cd pwd/Industry/A61/data/
  363  cd _scripts/
  364  python gen_dat.py 
  365  python gen_dat.py training_imgs.pkl training_lbls.pkl _ _
  366  export CUDA_VISIBLE_DEVICES=7
  367  python 
  368  cp -R /usr/local/caffe-master/examples/ ~/pwd/
  369  cd pdw
  370  cd ~/pwd/
  371  ls
  372  mv -R caffe_examples/ /data/sunnycia/pwd/
  373  mv caffe_examples/ /data/sunnycia/pwd/
  374  ln -s /data/sunnycia/pwd/caffe_examples/ caffe_examples
  375  df -h
  376  cd caffe_examples/
  377  ls
  378  cd mnist/
  379  caffe
  380  vim ~/.bashrc
  381  source ~/.bashrc
  382  top
  383  nvidia-smi
  384  caffe
  385  locate VGG_ILSVRC_16_layers.caffemodel
  386  rsync -avz 172.31.234.250:/home/qiudan/caffe/models/bvlc_vgg/VGG_ILSVRC_16_layers.caffemodel /home/sunnycia/pwd/Industry/A61
  387  caffe
  388  cd /data/sunnycia/pwd/Industry/A61/caffe/finetune_VGG16
  389  cp VGG_ILSVRC_16_layers_deploy.prototxt deploy.prototxt
  390  cd ..
  391  vim spot.py
  392  python spot.py 
  393  python
  394  vim ~/.bashrc
  395  source ~/.bashrc
  396  top
  397  nvidia-smi
  398  export CUDA_VISIBLE_DEVICES=6
  399  cd pwd/Industry/A61/
  400  cd patch_based/
  401  python 4_convolutional_network.py 
  402  top
  403  nvidia-smi
  404  python spot.py 
  405  vim ~/.bashrc
  406  vim spot.py
  407  python spot.py
  408  nvidia-smi
  409  top
  410  cd /data/root/
  411  ls
  412  cd MATLAB_2017a/
  413  ls
  414  ./install
  415  cd ..
  416  top
  417  nvidia-smi
  418  ls
  419  cd ~/pwd/mat
  420  cd /data/sunnycia/pwd/matconvnet_examples/
  421  ls
  422  matlab -nodesktop
  423  export CUDA_VISIBLE_DEVICES=6
  424  matlab -nodesktop
  425  pwd
  426  cd ..
  427  ls
  428  cd matconvnet-master/
  429  ls
  430  matlab -nodeskto
  431  matlab -nodesktop
  432  top
  433  nvidia-smi
  434  top
  435  ls
  436  matlab -nodesktop
  437  cd pwd/Industry/A61/
  438  mkdir matlab
  439  cd matlab
  440  ls
  441  git clone https://github.com/vlfeat/matconvnet.git
  442  cd matconvnet/
  443  matlab -nodesktop
  444  clear
  445  cd /data/sunnycia/saliency_on_videoset/_Train/Deep-Feature-Flow-master
  446  cd ~
  447  l
  448  ls
  449  cd mxnet/
  450  make -j8
  451  locate cblas_*
  452  make clean
  453  make -j8
  454  make clean
  455  make -j16
  456  ls /root
  457  yum install atlas
  458  cd mxnet/
  459  make -j4
  460  make clean
  461  make -j32
  462  make clean
  463  make -j32
  464  -lcblas
  465  cd mxnet/
  466  make clean
  467  make -j32
  468  cd ~/pwd/saliency_on_videoset/_Train/
  469  ls
  470  git clone https://github.com/lmb-freiburg/flownet2.git
  471  cd flownet2
  472  ls
  473  cp Makefile.config.example Makefile.config
  474  python
  475  conda install nomkl numpy scipy scikit-learn numexpr
  476  python
  477  exit()
  478  vim ~/.bashrc
  479  source ~/.bashrc
  480  python
  481  cd pwd/saliency_on_videoset/_Train/flownet2
  482  ls
  483  make -j5 all tools pycaffe
  484  cd models/
  485  tar -xf flownet2-models.tar.gz 
  486  tar -xf flownet2-models-sintel.tar.gz
  487  tar -xf flownet2-models-kitti.tar.gz
  488  vim ~/.bashrc
  489  source ~/.bashrc
  490  cd pwd/saliency_on_videoset/_Train/flownet2
  491  run-flownet.py /path/to/$net/$net_weights.caffemodel[.h5]                  /path/to/$net/$net_deploy.prototxt.template \ 
  492  cd scripts/
  493  ls
  494  run-flownet.py
  495  cd ..
  496  source set-env.sh 
  497  PATH
  498  $PATH
  499  run-flownet.py models/FlowNet2/FlowNet2_weights.caffemodel.h5 models/FlowNet2/FlowNet2_deploy.prototxt.template x.png y.png z.flo
  500  python run-flownet.py models/FlowNet2/FlowNet2_weights.caffemodel.h5 models/FlowNet2/FlowNet2_deploy.prototxt.template x.png y.png z.flo
  501  cd scripts/
  502  python run-flownet.py models/FlowNet2/FlowNet2_weights.caffemodel.h5 models/FlowNet2/FlowNet2_deploy.prototxt.template x.png y.png z.flo
  503  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template x.png y.png z.flo
  504  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame4.bmp frame6.bmp output.flo
  505  nvidia-smi
  506  export CUDA_VISIBLE_DEVICES=6
  507  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame4.bmp frame6.bmp output.flo
  508  nvidia-smi
  509  export CUDA_VISIBLE_DEVICES=6,7
  510  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame4.bmp frame6.bmp output.flo
  511  cd /data/sunnycia/pwd/Industry/A61/tensorflow/vgg_stuff
  512  nvidia-smi
  513  export CUDA_VISIBLE_DEVICES=6
  514  python train_vgg19.py 
  515  nvidia-smi
  516  export CUDA_VISIBLE_DEVICES=7
  517  cd /data/sunnycia/pwd/Industry/A61/tensorflow/patch_based
  518  python 4_convolutional_network.py 
  519  python train_vgg19.py 
  520  nvidia-smi
  521  cd mxnet/
  522  make -j16
  523  cd ..
  524  mkdir mxtest
  525  cd mxtest/
  526  git clone https://github.com/msracver/Deep-Feature-Flow.git
  527  git clone --recursive https://github.com/dmlc/mxnet.git
  528  unzip mxnet.zip 
  529  cd mxnet/
  530  git checkout 62ecb60
  531  make -j16
  532  cd /data/sunnycia/
  533  ls
  534  mkdir ILSVRC2015
  535  cd ILSVRC2015/
  536  mkdir VID && cd VID
  537  wget http://bvisionweb1.cs.unc.edu/ilsvrc2015/ILSVRC2015_VID.tar.gz
  538  ls
  539  rm ILSVRC2015_VID.tar.gz 
  540  wget http://bvisionweb1.cs.unc.edu/ilsvrc2015/ILSVRC2015_VID.tar.gz
  541  x25% frame6.bmp frame7.bmp
  542  ls
  543  ls -l
  544  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.bmp frame7.bmp output.flo
  545  convert -sample 25%x25% frame6.bmp frame7.jpg
  546  convert -sample 25%x25% frame4.bmp frame5.jpg
  547  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
  548  python
  549  caffe --version
  550  python
  551  pwd
  552  cd ../../Deep-Feature-Flow-master/
  553  python rfcn/demo.py 
  554  du -h max-depth=3 /data/sunnycia
  555  du -h max-depth=1 /data/sunnycia
  556  du -h max_depth=1 /data/sunnycia
  557  du -h --max-depth=1 /data/sunnycia
  558  du -h --max-depth=1 /data/sunnycia/pwd
  559  du -h --max-depth=1 /data/sunnycia/pwd/saliency_on_videoset/
  560  du -h --max-depth=1 /data/sunnycia/pwd/saliency_on_videoset/_Saliencymap/
  561  du -h --max-depth=1 /data/sunnycia/ImageSet
  562  du -h --max-depth=1 /data
  563  du -h --max-depth=1 /data/zhangpp
  564  cd /data/sunnycia/saliency_on_videoset/_Train/sam-master
  565  python main.py test figs
  566  python
  567  vim ~/.bashrc
  568  source ~/.bashrc
  569  python
  570  pip install keras==1.1.0
  571  python main.py test figs
  572  vim ~/.keras/keras.json 
  573  locate keras.json
  574  vim ~/.keras/keras.json 
  575  python main.py test figs
  576  vim ~/.keras/keras.json 
  577  python main.py test figs
  578  vim ~/.keras/keras.json 
  579  python main.py test figs
  580  cd ..
  581  git clone https://github.com/marcellacornia/sam.git
  582  unzip sam-master
  583  cd sam-master
  584  python main.py test sample_images
  585  top
  586  ssh qiudan@172.31.234.248
  587  cd pwd/saliency_on_videoset/_Train/
  588  ls
  589  cd sam-master/
  590  ls
  591  vim main.py 
  592  python main.py test sample_images/
  593  vim main.py 
  594  pwd
  595  cd /data/sunnycia/SaliencyDataset/Image/SALICON/Tools/salicon-api/PythonAPI
  596  python saliconDemo.py 
  597  conda install nomkl numpy scipy scikit-learn numexpr
  598  vim ~/.bashrc
  599  source ~/.bashrc
  600  python
  601  cd /data/sunnycia/
  602  ls
  603  cd ImageSet
  604  ls
  605  pwd
  606  cd ..
  607  ls
  608  clean
  609  cd ILSVRC2015/
  610  ls
  611  cd VID/
  612  ls
  613  cd ..
  614  wget --help
  615  wget -c 
  616  cd VID/
  617  ls
  618  tail -f wget-log
  619  wget -c http://bvisionweb1.cs.unc.edu/ilsvrc2015/ILSVRC2015_VID.tar.gz
  620  top
  621  nvidia-smi
  622  top
  623  tar -tf ILSVRC2015_VID.tar.gz 
  624  vim ILSVRC2015_VID.tar.gz 
  625  tar -vf ILSVRC2015_VID.tar.gz 
  626  tar -xf ILSVRC2015_VID.tar.gz 
  627  cd pwd/saliency_on_videoset/_Train/
  628  ls
  629  cd sam-master/
  630  ls
  631  cd /data/sunnycia/SaliencyDataset/Image/SALICON/Tools/salicon-api/PythonAPI
  632  python
  633  python saliconDemo.py 
  634  cd /data/sunnycia/SaliencyDataset/Image/SALICON/Images
  635  unzip image.zip 
  636  cd ..
  637  ls
  638  cd salicon-api/
  639  ls
  640  cd PythonAPI/
  641  python saliconDemo.py
  642  cd PythonAPI/
  643  python saliconDemo.py
  644  python gen_saliconset.py 
  645  python
  646  whereis python
  647  ls -l /usr/bin/python*
  648  ls
  649  python saliconDemo.
  650  python saliconDemo.py
  651  python gen_saliconset.py 
  652  python saliconDemo.
  653  python saliconDemo.py
  654  python gen_saliconset.py 
  655  ls
  656  cd ..
  657  ls
  658  cd ..
  659  ls
  660  cd ..
  661  cd DATA/
  662  ls
  663  df -h
  664  python assign_images.py 
  665  rsync -avz 172.31.234.248:/home/qiudan/sunnycia/sam-master-from-dd ./
  666  cd sam-master-from-dd/
  667  python main.py test sample_images/
  668  vim ~/.bashrc
  669  vim ~/.keras/keras.json 
  670  python main.py test sample_images/
  671  cd ..
  672  rm -rf sam-master-from-dd/
  673  cd pwd/saliency_on_videoset/_Train/
  674  ls
  675  cd Deep-Feature-Flow-master/
  676  ls
  677  cd experiments/
  678  ls
  679  cd rfcn/
  680  ls
  681  cd /data/sunnycia/saliency_on_videoset/_Train/Deep-Feature-Flow-master/model/fortrain
  682  unzip pretrained_model.zip 
  683  clear
  684  cd pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master/
  685  ls
  686  nvidia-smi
  687  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  688  export CUDA_VISIBLE_DEVICES=6,7
  689  nvidia-smi
  690  clear
  691  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  692  cd /data/sunnycia/saliency_on_videoset/_Train/Deep-Feature-Flow-master
  693  export CUDA_VISIBLE_DEVICES=4,5,6,7
  694  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  695  cd pwd/saliency_on_videoset/Train/
  696  cd gen_dataset/
  697  python gen_dataset.py 
  698  top
  699  free -h
  700  python
  701  top
  702  free -h
  703  history
  704  clear
  705  ls /data/sunnycia/
  706  ls /data/sunnycia/ImageSet
  707  ls /data/sunnycia/ImageSet/frame/
  708  cd /data/sunnycia/ImageSet/frame/
  709  cd videoSRC001
  710  ls
  711  cd ..
  712  pwd
  713  cd ~/pwd/saliency_on_videoset/Train/
  714  ls
  715  cd gen_dataset/
  716  python gen_dataset.py 
  717  top
  718  nvidia-smi
  719  python gen_dataset.py 
  720  cd ..
  721  ls
  722  python training.py 
  723  nvidia-smi
  724  export CUDA_VISIBLE_DEVICES=6
  725  python training.py 
  726  python
  727  cd /data/sunnycia/ILSVRC2015/ImageSets
  728  clear
  729  cd DET/
  730  rename
  731  for f in *;do mv "$f" "DET_$f";done
  732  cd ../VID/
  733  ls
  734  for f in *;do mv "$f" "VID_$f";done
  735  pwd
  736  cd ..
  737  pwd
  738  ls
  739  nvidia-smi
  740  top
  741  nvidia-smi
  742  top
  743  nvidia-smi
  744  top
  745  nvidia-smi
  746  top
  747  nvidia-smi
  748  nvidi-amsi
  749  nvidia-smi
  750  top
  751  nvidia-smi
  752  top
  753  nvidia-smi
  754  top
  755  pwd
  756  cd ~/caffe-master/
  757  ls
  758  make matcaffe
  759  make -j16 matcaffe
  760  vim Makefile.config
  761  top
  762  vim Makefile.config
  763  cd /usr/local/MATLAB/
  764  ls
  765  nvidia-smi
  766  top
  767  nvidia-smi
  768  vim ~/.bashrc
  769  df -h
  770  top
  771  free -h
  772  cd /data/sunnycia/saliency_on_videoset/Train
  773  python training.py 
  774    name: "bn4f_branch2c"
  775  CFLAGS="-O0" pip install greenlet==0.4.0
  776  python training.py 
  777  cd pwd/saliency_on_videoset/_Train/
  778  ls
  779  cd Deep-Feature-Flow-master/
  780  ls
  781  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  782  cd /data/sunnycia/saliency_on_videoset/Train
  783  python training.py 
  784  nvidia-smi
  785  python training.py 
  786  nvidia-smi
  787  en_dataset.py 
  788  free -h
  789  python gen_dataset.py 
  790  cd /data/sunnycia/saliency_on_videoset/Train/dataset
  791  python
  792  cd ..
  793  python training.py
  794  ls
  795  top
  796  nviida-smi
  797  nvidia-smi
  798  pwd
  799  nvidia-smi
  800  cp *.p* training_script
  801  cd training_script/
  802  cd ..
  803  cd script/
  804  ls
  805  git init
  806  git add --all
  807  git commit -m 'Init. Commit first convergence network. all scripts should be placed under this folder.'
  808  git config --global user.email sunzhenhao@sina.com
  809  git config --global user.name sunnycia
  810  git commit -m 'Init. Commit first convergence network. all scripts should be placed under this folder.'
  811  git log
  812  git stage
  813  git add .
  814  git stage
  815  vim solver_new.prototxt 
  816  git status
  817  git add .
  818  git status
  819  git commit 'a dummy test for version unroll'
  820  git add --all
  821  git commit 'a dummy test for version unroll'
  822  git log
  823  git commit 'a dummy test for version unroll'
  824  vim solver_new.prototxt 
  825  git commit 'a dummy test for version unroll'
  826  git fetch
  827  git checkout
  828  git remote add origin https://github.com/sunnycia/scripts.git
  829  git push -u origin master
  830  git status
  831  git add --all
  832  git status
  833  git commit 'a dummy test'
  834  git clone https://github.com/sunnycia/scripts.git
  835  cd scripts/
  836  ls
  837  vim solver_new.prototxt 
  838  git status
  839  git add -a
  840  git add --all
  841  git commit 'a dummy test'
  842  git commit "a dummy test"
  843  git commit "adummytest"
  844  git commit -m "a dummy test"
  845  git push -u origin master
  846  cd ..
  847  rm -rf scripts/
  848  git status
  849  git reset HEAD solver_new.prototxt
  850  git status
  851  git checkout -- solver_new.prototxt
  852  git status
  853  git fetch
  854  git status
  855  git pull
  856  vim ~/.bashrc
  857  source ~/.bashrc
  858  cd /data/sunnycia/saliency_on_videoset/Train
  859  export CUDA_VISIBLE_DEVICES=6
  860  python training.py 
  861  cd scripts/
  862  python test.py 
  863  nvidia-smi
  864  python 
  865  cd /data/sunnycia/saliency_on_videoset/Train/scripts
  866  export CUDA_VISIBLE_DEVICES=6
  867  python test.py 
  868  cd ~/pwd/saliency_on_videoset/
  869  ls
  870  cd _Train/Deep-Feature-Flow-master/
  871  ls
  872  export CUDA_VISIBLE_DEVICES=6,7
  873  cd experiments/
  874  ls
  875  cd dff_rfcn/
  876  ls
  877  cd cfgs/
  878  ls
  879  vim resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml 
  880  cd ../../..
  881  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  882  history
  883  git log
  884  git reset --hard 0a667d660f7e906c1c632d481ecbf90bacee9b60
  885  vim solver_new.prototxt 
  886  top
  887  nvidia-smi
  888  cd ..
  889  rm -rf script/
  890  git clone https://github.com/sunnycia/scripts.git
  891  cd scripts/
  892  ls
  893  git log
  894  vim solver_new.prototxt 
  895  git reset --hard 0a667d660f7e906c1c632d481ecbf90bacee9b60
  896  vim solver_new.prototxt 
  897  export CUDA_VISIBLE_DEVICES=7
  898  python training.py
  899  python training.py 
  900  top
  901  nvidia-smi
  902  pwd
  903  top
  904  nvidia-smi
  905  top
  906  history
  907  cd /data/sunnycia/saliency_on_videoset/Train
  908  convert_imageset -encoded -shuffle -encode_type jpg / imagedata_mini.txt dataset/mini_lmdb
  909  export locate convert_imageset
  910  locate convert_imageset
  911  export PATH=$PATH:/usr/local/caffe-master/tools/
  912  convert_imageset -encoded -shuffle -encode_type jpg / imagedata_mini.txt dataset/mini_lmdb
  913  export PATH=$PATH:/usr/local/caffe-master/.build_release/tools/
  914  convert_imageset -encoded -shuffle -encode_type jpg / imagedata_mini.txt dataset/mini_lmdb
  915  python 
  916  free -h
  917  python
  918  cd nvidia-smi
  919  nvidia-smi
  920  free -h
  921  export CUDA_VISIBLE_DEVICES=6
  922  free -h
  923  top
  924  nvidia-smi
  925  free -h
  926  cd ../_Train/
  927  ls
  928  cd Deep-Feature-Flow-master/
  929  ls
  930  cd experiments/dff_rfcn/cfgs/
  931  vim resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml 
  932  cd ../../
  933  cd ..
  934  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  935  export CUDA_VISIBLE_DEVICES=4,5,6,7
  936  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  937  cd /data/sunnycia/saliency_on_videoset/Train/scripts
  938  export CUDA_VISIBLE_DEVICES=6
  939  python training.py
  940  cd pwd/saliency_on_videoset/Train
  941  cd dataset/
  942  ls
  943  top
  944  python gen_dataset.py 
  945  top
  946  nvidia-smi
  947  df -h
  948  pwd
  949  cd ..
  950  python gen_lmdb.py 
  951  ls 
  952  convert_imageset
  953  vim ~/.bahser
  954  vim ~/.bahsr
  955  vim ~/.bashrc
  956  clear
  957  locate convert_imageset.bin
  958  cp /usr/local/caffe-master/.build_release/tools/convert_imageset.bin ./
  959  ls
  960  convert_imageset
  961  ./convert_imageset
  962  ./bin
  963  ./convert_imageset.bin
  964  ls /usr/local/caffe-master/.build_release/tools/
  965  export PATH=$PATH:/usr/local/caffe-master/.build_release/tools/
  966  clear
  967  convert_imagenet
  968  ./convert_imagenet
  969  convert_imageset
  970  convert_imageset -encoded -shuffle -encode_type jpg / imagedata.txt dataset/lmdb
  971  python gen_lmdb.py 
  972  convert_imageset -encoded -shuffle -encode_type jpg / framedata.txt dataset/lmdb
  973  cxx
  974  CXX
  975  convert_imageset -encoded -shuffle -encode_type jpg / framedata.txt dataset/lmdb
  976  cd /data/sunnycia/SaliencyDataset/Image/CAT2000
  977  unzip trainSet.zip 
  978  cd ~/pwd/saliency_on_videoset/Train/
  979  cd scripts/
  980  python gen_salicon_dataset.py 
  981  export CUDA_VISIBLE_DEVICES=6
  982  python training.
  983  python training.py 
  984  git status
  985  git add --all
  986  git commit -m "add test module, revise on salicon dataset. Salicon-Ver-1.'
  987  git commit -m "add test module, revise on salicon dataset. Salicon-Ver1'
  988  git commit -m "add test module, revise on salicon dataset. Salicon-Ver1"
  989  git push -u origin master
  990  git pull
  991  git status
  992  git log
  993  git reset --hard 4e7cda7fa4cebd123a7c81912d2a2db3cc8c756b
  994  git status
  995  git push -u origin master
  996  git pull
  997  git push -u origin master
  998  top
  999  nvidia-smi
 1000  df -h
 1001  clear
 1002  top
 1003  cd pwd/saliency_on_videoset/clearn
 1004  clear
 1005  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1006  git fetch
 1007  git status
 1008  git add --all
 1009  git commit -m "Version3, combination of euc loss and kld/nss loss."
 1010  git push -u origin master
 1011  clear
 1012  python metric.py 
 1013  python
 1014  python metric.py 
 1015  python
 1016  python -h
 1017  python -m 'import matlab.engine'
 1018  nvidia-smi
 1019  python -m 'import matlab.engine'
 1020  python -m 'import matlab'
 1021  python metric.py 
 1022  top
 1023  export CUDA_VISIBLE_DEVICES=6 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1024  python metric.py 
 1025  python
 1026  python metric.py 
 1027  cd /usr/lib/python2.7/site-packages/
 1028  ls
 1029  python metric.py 
 1030  cd -
 1031  python metric.py 
 1032  python
 1033  python metric.py 
 1034  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1035  python gen_salicon_dataset.py 
 1036  nvidia-smi
 1037  top
 1038  nvidia-smi
 1039  top
 1040  nvidia-smi
 1041  top
 1042  python
 1043  top
 1044  nvidia-smi
 1045  cd ../caffe-saliency/
 1046  ls
 1047  make clean
 1048  cd ..
 1049  ls
 1050  cd caffe-saliency/
 1051  make clean
 1052  ls
 1053  vim Makefile.config
 1054  make -j8 all
 1055  make -j4 all
 1056  make clean
 1057  make -j8 all
 1058  make clean
 1059  vim Makefile.config
 1060  make -j8 all
 1061  vim Makefile.config
 1062  cp ~/caffe-master/ ../
 1063  cp -R ~/caffe-master/ ../
 1064  cd ../caffe-master/
 1065  ls
 1066  make clean
 1067  make -j8 all
 1068  make -j4 pycaffe
 1069  cd ..
 1070  cd scripts/
 1071  top
 1072  nvidia-smi
 1073  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1074  export CUDA_VISIBLE_DEVICES=6
 1075  python training.py 
 1076  python test.py 
 1077  python
 1078  ls /usr/local/MATLAB/
 1079  ls
 1080  python training.py 
 1081  vim bashrc
 1082  vim ~/.bashrc
 1083  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1084  python
 1085  top
 1086  nvidia-smi
 1087  top
 1088  nvidia-smi
 1089  top
 1090  nvidia-smi
 1091  top
 1092  python avg_metric.py 
 1093  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1094  python training.py 
 1095  export CUDA_VISIBLE_DEVICES=7
 1096  python training.py --debug=True
 1097  python training.py -debug=True
 1098  python training.py --debug=True
 1099  python training.py 
 1100  python training.py -h
 1101  python training.py --debug True
 1102  git add --all
 1103  git commit -m "Last version for loss=95820 on salicon dataset.Consider it may due to bad performance of sigmoid layer, loss layer will be changed in next version."
 1104  git push -u origin master
 1105  git fetch
 1106  git status
 1107  git push
 1108  python training.py
 1109  python training.py --debug True
 1110  python training.py --debug False
 1111  nvidia-smi
 1112  top
 1113  nvidia-smi
 1114  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1115  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1116  python training.py --debug=True --prototxt='train_nssloss.prototxt'
 1117  python training.py --debug=True --train_prototxt='train_nssloss.prototxt'
 1118  python training.py --debug=False --train_prototxt='train_nssloss.prototxt'
 1119  python training.py --debug=False --train_prototxt='train_kldloss_withouteuc.prototxt'
 1120  python training.py --debug=False --use_snapshot=True --train_prototxt='train_kldloss_withouteuc.prototxt'
 1121  python training.py --debug=False --use_snapshot=True --train_prototxt='../train_prototxt/train_kldloss_withouteuc.prototxt'
 1122  python training.py --debug=False --use_snapshot=True --train_prototxt='train_prototxt/train_kldloss_withouteuc.prototxt'
 1123  python training.py --debug=False --use_snapshot=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1124  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1125  export CUDA_VISIBLE_DEVICES=4
 1126  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1127  python training.py --debug=True --train_prototxt='train_igloss.prototxt'
 1128  python training.py --debug=True --train_prototxt='train_kldloss.prototxt'
 1129  python training.py --debug=False --train_prototxt='train_kldloss.prototxt'
 1130  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1131  export CUDA_VISIBLE_DEVICES=5
 1132  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1133  python training.py --debug=True --train_prototxt='train_nss-kldloss.prototxt'
 1134  python training.py --debug=False --train_prototxt='train_nss-kldloss.prototxt'
 1135  python training.py --debug=False --train_prototxt='train_nssloss_withouteuc.prototxt'
 1136  cd pwd/saliency_on_videoset/Train/scripts/
 1137  python test.py 
 1138  python test.py
 1139  top
 1140  nvidia-smi
 1141  export CUDA_VISIBLE_DEVICES=6
 1142  python test.py 
 1143  df -h
 1144  cd /data/sunnycia/SaliencyDataset/Image/NUS
 1145  python change_name.py 
 1146  cd -
 1147  python test.py
 1148  cd /data/sunnycia/SaliencyDataset/Image/MIT1003
 1149  python change_name.py 
 1150  cd ALLFIXATIONMAPS/
 1151  rm -f *_fixPts.jpg
 1152  cd -
 1153  cd --
 1154  cd pwd/saliency_on_videoset/Train/scripts/
 1155  python avg_metric.py 
 1156  top
 1157  nvidia-smi
 1158  ./plot_training_log.py.example
 1159  cd caffe_plot/
 1160  chmod u+x *
 1161  ./parse_log.sh ../../log/train_kldloss_withouteuc 
 1162  ./plot_training_log.py.example 0 save.png ../../log/train_kldloss
 1163  ./plot_training_log.py.example 0 save.png ../../log/train_nss_kldloss_goodweight
 1164  ./plot_training_log.py.example 0 save.png caffe.localhost.localdomain.sunnycia.log.INFO.20171012-085342.16593 
 1165  ./plot_training_log.py.example 0 save.png ../../log/train_nss_kldloss_goodweight
 1166  ./plot_training_log.py.example 0 save.png ../../log/caffe.localhost.localdomain.sunnycia.log.INFO.20171012-085342.16592
 1167  df -h
 1168  cd /data/sunnycia/SaliencyDataset/Image/CAT2000
 1169  unzip testSet.zip 
 1170  cd trainSet/
 1171  python combine.py 
 1172  cd  
 1173  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1174  python test.py 
 1175  nvidia-smi
 1176  export CUDA_VISIBLE_DEVICES=6
 1177  python test.py 
 1178  top
 1179  nvidia-smi
 1180  top
 1181  matlab -nodesktop
 1182  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1183  matlab -nodesktop
 1184  export CUDA_VISIBLE_DEVICES=5 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1185  python training.py --debug=False --train_prototxt='./training_protocol/train_nss_kldloss_goodweight.prototxt 2>&1 | tee ../log/train_nss_kldloss_goodweight_SGDSOLVER
 1186  python training.py --debug=False --train_prototxt='./training_protocol/train_nss_kldloss_goodweight.prototxt' 2>&1 | tee ../log/train_nss_kldloss_goodweight_SGDSOLVER
 1187  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1188  nvidia-smi
 1189  export CUDA_VISIBLE_DEVICES=6
 1190  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1191  python training.py --debug=True --train_prototxt='train_nss-kldloss_withouteuc.prototxt'
 1192  top
 1193  nvidia-smi
 1194  git fetch
 1195  git add --all
 1196  git status
 1197  git commit -m "Add different loss function training prototxt. Add metric code."
 1198  git push -u origin master
 1199  ./train.sh
 1200  chmod u+x train.sh
 1201  ./train.sh
 1202  vim train.sh 
 1203  ./train.sh
 1204  ./train.sh ../training_protocol/train_nss_kldloss_withouteuc.prototxt
 1205  ./train.sh training_protocol/train_nss_kldloss_withouteuc.prototxt
 1206  ./train.sh training_protocol/train_nss_kldloss_withouteuc.prototxt False
 1207  df -h
 1208  clear
 1209  cd pwd/saliency_on_videoset/Train/scripts/
 1210  ./train.sh ./training_protocol/train_nss_kldloss_goodweight.prototxt False
 1211  nvidia-smi
 1212  export CUDA_VISIBLE_DEVICES=7
 1213  ./train.sh ./training_protocol/train_nss_kldloss_goodweight.prototxt False
 1214  export CUDA_VISIBLE_DEVICES=7 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1215  ./train.sh ./training_protocol/train_nss_kldloss_goodweight.prototxt False
 1216  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1217  matlab -nodesktop
 1218  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1219  ls /home
 1220  top
 1221  nvidia-smi
 1222  matlab -nodesktop
 1223  cd pwd/saliency_on_videoset/Train/scripts/
 1224  vim ~/.bashrc
 1225  cd /data/sunnycia/saliency_on_videoset/_Train/DSCLRCN/caffe-master
 1226  make -j8 all
 1227  vim Makefile.config
 1228  make clean
 1229  make -j8 all
 1230  vim Makefile.config
 1231  make clean
 1232  make -j8 all
 1233  vim Makefile.config
 1234  cd ..
 1235  cd caffe-master/
 1236  ls
 1237  vim Makefile.config
 1238  make -j8 all
 1239  make clean
 1240  make -j8 all
 1241  vim Makefile.config
 1242  make clean
 1243  make -j16 all
 1244  cd /home/sunnycia/pwd/saliency_on_videoset/Train/scripts
 1245  python metric.py
 1246  cd /home/sunnycia/pwd/saliency_on_videoset/Train/scripts
 1247  python metric.py
 1248  cd pwd/saliency_on_videoset/Train/scripts/
 1249  python avg_metric.py 
 1250  top
 1251  nvidia-smi
 1252  python avg_metric.py 
 1253  vim /etc/profile
 1254  git clone https://github.com/herrlich10/saliency.git
 1255  mv saliency/ pymetric
 1256  python metric.py
 1257  clear
 1258  python metric.py
 1259  clear
 1260  python metric.py
 1261  clear
 1262  python metric.py
 1263  clear
 1264  python metric.py
 1265  clear
 1266  python metric.py
 1267  pwd
 1268  top
 1269  nvidia-smi
 1270  cd pwd/saliency_on_videoset/Train/scripts/
 1271  matlab -nodesktop
 1272  clear
 1273  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1274  python avg_metric.py 
 1275  nvidia-smi
 1276  export CUDA_VISIBLE_DEVICES=6 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1277  python test.py 
 1278  python admin.py 
 1279  vim ~/.bashrc
 1280  python admin.py 
 1281  python test.py 
 1282  python admin.py 
 1283  top
 1284  nvdia-smi
 1285  nvidia-smi
 1286  clear
 1287  rsync -avz 172.31.234.248:/home/data/qiudan/DATASET/SALICON/val2014/saliency/* /data/sunnycia/SaliencyDataset/Image/SALICON/DATA/train_val/val2014/saliency/sam
 1288  rsync -avz 172.31.234.248:/home/data/qiudan/DATASET/MIT1003/saliency/* /data/sunnycia/SaliencyDataset/Image/MIT1003/saliency/sam
 1289  matlab -nodesktop
 1290  python metric.py
 1291  clear
 1292  python metric.py
 1293  cd /data/sunnycia/saliency_on_videoset/_Train/flownet2-tf
 1294  python
 1295  cd /data/sunnycia/saliency_on_videoset/_Train/flownet2
 1296  python
 1297  clear
 1298  cd /data/sunnycia/SaliencyDataset/Video/XU
 1299  python
 1300  clear
 1301  python gen_fixation_map.py 
 1302  cd ..
 1303  cd DIEM/
 1304  python gen_fixation.py 
 1305  clear
 1306  python gen_fixation.py 
 1307  clear
 1308  python gen_fixation.py 
 1309  clear
 1310  python gen_fixation.py 
 1311  clear
 1312  cd ..
 1313  cd MSU/
 1314   python gen_fixation.py 
 1315  clear
 1316   python gen_fixation.py 
 1317  ls
 1318  python playground.py 
 1319  python add_frame_index.py 
 1320  clear
 1321  python add_frame_index.py 
 1322  vim ~/.bashrc
 1323  cd /data/sunnycia/saliency_on_videoset/_Train/flownet2
 1324  source set-env.sh 
 1325  vim ~/.bashrc
 1326  PATH
 1327  $PATH
 1328  python run-flownet.py
 1329  ls ~/.*
 1330  vim ~/.bash_history 
 1331  cd scripts/
 1332  ls -h
 1333  ls /home
 1334  cd ~/pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master/
 1335  history>history.txt
 1336  export CUDA_VISIBLE_DEVICES=4,5,6,7
 1337  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1338  export CUDA_VISIBLE_DEVICES=6,7
 1339  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1340  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1341  python add_frame_index_hist.py 
 1342  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1343  export CUDA_VISIBLE_DEVICES=7
 1344  python training.py --debug=True --train_prototxt='train_nss-kldloss_withouteuc.prototxt'
 1345  export CUDA_VISIBLE_DEVICES=7
 1346  python training.py --debug=True --train_prototxt='../training_protocol/train_nss-kldloss_withouteuc.prototxt'
 1347  python training.py --debug=True --train_prototxt='training_protocol/train_nss-kldloss_withouteuc.prototxt'
 1348  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1349  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1350  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1351  clear
 1352  cd pwd/saliency_on_videoset/Train/scripts/
 1353  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1354  export CUDA_VISIBLE_DEVICES=5
 1355  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1356  clear
 1357  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1358  bash set_env.sh 
 1359  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8 --debug=1
 1360  source set_env.sh 
 1361  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8 --debug=1
 1362  cd pwd/saliency_on_videoset/Train/scripts/
 1363  python scavenger.py 
 1364  git status
 1365  git add --all
 1366  git commit -m "add dilated convolution network prototxt"
 1367  git push -u origin master
 1368  clear
 1369  cd pwd/saliency_on_videoset/Train/scripts/
 1370  source set_env.sh 
 1371  history
 1372  clear
 1373  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8 --debug=1
 1374  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1375  clear
 1376  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1377  export CUDA_VISIBLE_DEVICES=6
 1378  python training.py --train_prototxt='prototxt/debug_add_lr_train_kldloss_withouteuc.prototxt' --batch=8
 1379  python training.py --train_prototxt='prototxt/debug_add_lr_train_kldloss_withouteuc.prototxt' --batch=8 --debug=1
 1380  python training.py --train_prototxt='prototxt/debug_add_lr_train_kldloss_withouteuc.prototxt' --batch=8
 1381  export CUDA_VISIBLE_DEVICES=6 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1382  history
 1383  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1384  python
 1385  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1386  ls
 1387  git status
 1388  git add --all
 1389  git commit -m "Add loss plot module in training.py"
 1390  git push -u origin master
 1391  git status
 1392  cd /data/sunnycia/fang
 1393  python pictureshow.py 
 1394  cd 
 1395  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1396  python change_net_test.py 
 1397  python training.py 
 1398  python training.py --debug=False
 1399  python training.py --debug=False --train_prototxt='net/train.prototxt'
 1400  python training.py --debug=False
 1401  python training.py --debug=False --train_prototxt='net/train.prototxt'
 1402  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=512
 1403  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=32
 1404  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=512
 1405  python training.py --debug False --train_prototxt='net/train.prototxt' --batch=512
 1406  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=512
 1407  export CUDA_VISIBLE_DEVICES=7
 1408  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=512
 1409  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=64
 1410  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=16
 1411  export CUDA_VISIBLE_DEVICES=6,7
 1412  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=8
 1413  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=16
 1414  python training.py --debug='False' --train_prototxt='net/train.prototxt' --batch=16
 1415  python scavenger.py 
 1416  python training.py --debug='False' --train_prototxt='net/train.prototxt' --batch=16
 1417  python training.py --debug='False' --train_prototxt='net/train.prototxt' --batch=8
 1418  python training.py --debug='False' --train_prototxt='net/train_kldloss_withouteuc.prototxt' --batch=8
 1419  clear
 1420  python training.py --train_prototxt='net/train_kldloss_withouteuc.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate'
 1421  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate'
 1422  df -h
 1423  python utils/scavenger.py 
 1424  python utils/scavenger.py --snapshot=1
 1425  git status
 1426  git add --all
 1427  git commit -m "add generate density map script. Clean training script, add vo-training script(not done yet)"
 1428  git push -u origin master
 1429  cd /data/sunnycia/SaliencyDataset/Video/XU
 1430  clear
 1431  python extract_fixation.py 
 1432  matlab
 1433  top
 1434  nvidia-smi
 1435  clear
 1436  df -h
 1437  cd ..
 1438  cd DIEM/
 1439  python gen_fixation.py 
 1440  clear
 1441  python gen_fixation.py 
 1442  clear
 1443  python gen_fixation.py 
 1444  ffmpeg
 1445  cd ../MSU/
 1446  ffmpeg -r 25 -f image2 -s 1920x1080 -i _temp/frame_%d.jpg -vcodec libx264 -crf 25 -pix_fmt yuv420p test.mp4
 1447  python
 1448  nvidia-smi
 1449  top
 1450  nvidia-smi
 1451  top
 1452  nvidia-smi
 1453  python add_frame_index_hist.py 
 1454  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1455  git status
 1456  git add --all
 1457  git commit -m "update, forget what i've done.."
 1458  git push -u origin master
 1459  python avg_metric.py 
 1460  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1461  history > history.txt
 1462  python training.py
 1463  python training.py --debug=True
 1464  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1465  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1466  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1467  export CUDA_VISIBLE_DEVICES=6
 1468  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1469  python scavenger.py 
 1470  git add --all
 1471  git commit -m "add batch training function.Programatically change net prototxt"
 1472  git push -u origin master
 1473  python scavenger.py 
 1474  git status
 1475  git add --all
 1476  git commit -m "fixed some bug"
 1477  git push -u origin master
 1478  python scavenger.py 
 1479  python training.py --debug --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt'
 1480  python training.py --debug=1 --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt'
 1481  python training.py --debug=1 --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt' batch=8
 1482  export CUDA_VISIBLE_DEVICES=3
 1483  python training.py --debug=1 --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt' batch=8
 1484  python training.py --debug=1 --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt' --batch=8
 1485  python training.py --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt' --batch=8
 1486  cd ../../_Train/
 1487  git clone https://github.com/remega/OMCNN_2CLSTM.git
 1488  clear
 1489  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_dilated4_conv.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc_dilated4_conv-batch-8_1509601246/snapshot-_iter_100000.solverstate'
 1490  cd ../Train/scripts/
 1491  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_dilated4_conv.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc_dilated4_conv-batch-8_1509601246/snapshot-_iter_100000.solverstate'
 1492  python utils/scavenger.py 
 1493  python test.py 
 1494  nvidia-smi
 1495  export CUDA_VISIBLE_DEVICES=5
 1496  python test.py 
 1497  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1498  python gen_density.py 
 1499  git clone https://github.com/clibs/lmdb.git
 1500  ls
 1501  pip install lmdb
 1502  cd /data/sunnycia/saliency_on_videoset/_Train/flownet2
 1503  cd python/
 1504  python
 1505  cd ..
 1506  cd ~
 1507  clear
 1508  wget https://s3.amazonaws.com/videomattingstor/savam/sources.zip
 1509  ls
 1510  ls sources.zip 
 1511  ls -l sources.zip 
 1512  rm sources.zip 
 1513  clear
 1514  cd /data/sunnycia/SaliencyDataset/Video/XU
 1515  python gen_fixation_map.py 
 1516  vim ~/.bashrc
 1517  cd ..
 1518  ls
 1519  cd MSU/
 1520  ls
 1521  unzip sources.zip 
 1522  nvidia-smi
 1523  free -h
 1524  top
 1525  df ph
 1526  df -h
 1527  ls
 1528  mv COPYRIGHTED_sources/*.avi videos/
 1529  mv VQEG_sources/*.avi videos/
 1530  top
 1531  nvidia-smi
 1532  top
 1533  cd ~/pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master/
 1534  export CUDA_VISIBLE_DEVICES=6,7
 1535  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/
 1536  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1537  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/
 1538  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1539  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1540  python add_frame_index.py 
 1541  cd /data/sunnycia/saliency_on_videoset/_Train/Deep-Feature-Flow-master
 1542  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1543  export CUDA_VISIBLE_DEVICES=6,7
 1544  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1545  free -h
 1546  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1547  python training.py
 1548  python training.py --debug=True
 1549  python training.py --debug=True --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1550  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1551  python training.py --debug=True --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1552  export CUDA_VISIBLE_DEVICES=7
 1553  python training.py --debug=True --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1554  python training.py --debug=False --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1555  python training.py --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1556  clera
 1557  clear
 1558  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc_dilated_conv-batch-8_1509595085/snapshot-_iter_100000.solverstate'
 1559  nvidia-smi
 1560  top
 1561  nvidia-smi
 1562  heaven
 1563  nvidia-smi
 1564  python
 1565  top
 1566  clear
 1567  free -h
 1568  nvidia-smi
 1569  python utils/slice_frames.py 
 1570  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --wildcard='*left.*' --debug=1
 1571  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --wildcard="*left.*" --debug=1
 1572  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --vowildcard="*left.*" --debug=1
 1573  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --vowildcard="*left.*"
 1574  unrar
 1575  cd ..
 1576  cd -
 1577  cd /data/sunnycia/SaliencyDataset/Video/LEDOV
 1578  unrar LEDOV.part1.rar 
 1579  unrar e LEDOV.part1.rar 
 1580  unrar x LEDOV.part1.rar 
 1581  cd -
 1582  clear
 1583  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1584  python gen_fixation.py 
 1585  vim gen_fixation.py 
 1586  clear
 1587  python gen_fixation.py 
 1588  python gen_density.py --sigma=32
 1589  clear
 1590  cd pwd/saliency_on_videoset/Train/scripts/
 1591  source set_env.sh 
 1592  nvidia-smi
 1593  source set_env.sh 
 1594  python test.py
 1595  clear
 1596  python test.py
 1597  cd /data/sunnycia/SaliencyDataset/Image/NCTU
 1598  unzip NCTU-3DFixation.zip 
 1599  unzip -q NCTU-3DFixation.zip 
 1600  cd -
 1601  clear
 1602  source set_env.sh 
 1603  export CUDA_VISIBLE_DEVICES=7
 1604  python test.py 
 1605  python 
 1606  clear
 1607  python
 1608  clear
 1609  python test.py
 1610  python metric/metric.py 
 1611  clear
 1612  python metric/metric.py 
 1613  clear
 1614  python metric/metric.py --debug --ds_name='mit1003'
 1615  python metric/metric.py --debug=1 --ds_name=mit1003
 1616  clear
 1617  python metric/metric.py --debug=1 --ds_name=mit1003
 1618  clear
 1619  python metric/metric.py --debug=1 --ds_name=mit1003
 1620  clear
 1621  python metric/metric.py --ds_name=mit1003
 1622  nvidia-smi
 1623  top
 1624  nvidia-smi
 1625  top
 1626  nvidia-smi
 1627  df -h
 1628  top
 1629  nvida-smi
 1630  nvidia-smi
 1631  clear
 1632  nvidia-smi
 1633  top
 1634  nvidia-smi
 1635  top
 1636  python metric/metric_video.py 
 1637  python metric/metric_video.py -dsname='videoset'
 1638  python metric/metric_video.py --dsname='videoset'
 1639  python metric/avg_metric.py 
 1640  cd pwd/saliency_on_videoset/Train/scripts/
 1641  source set_env.sh 
 1642  export CUDA_VISIBLE_DEVICES=0
 1643  clear
 1644  python test.py 
 1645  top
 1646  nvidia-smi
 1647  top
 1648  nvidia-smi
 1649  clear
 1650  cd  /data/sunnycia/saliency_on_videoset/_Train
 1651  git clone https://github.com/liruoteng/FlowNet.git
 1652  top
 1653  nvidia-smi
 1654  top
 1655  free -h
 1656  python
 1657  cd ../Train/
 1658  cd scripts/
 1659  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1660  python all_in_one.py 
 1661  top
 1662  nvidia-smi
 1663  clear
 1664  top
 1665  nvidia-smi
 1666  top
 1667  clear
 1668  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1669  python training_image.py --train_prototxt='prototxt/train_kldloss_withouteuc_msra.prototxt' --batch=8
 1670  export CUDA_VISIBLE_DEVICES=4
 1671  python training_image.py --train_prototxt='prototxt/train_kldloss_withouteuc_msra.prototxt' --batch=8
 1672  python training_image.py --train_prototxt='prototxt/train_kldloss_withouteuc_msra.prototxt' --batch=8 --debug=1
 1673  python training_image.py --train_prototxt='prototxt/train_kldloss_withouteuc_uniform.prototxt' --batch=8
 1674  free
 1675  free -h
 1676  vim ~/.bashrc
 1677  top
 1678  nvidia-smi
 1679  top
 1680  clear
 1681  cd pwd/saliency_on_videoset/Train/scripts/
 1682  source set_env.sh 
 1683  nvidia-smi
 1684  export CUDA_VISIBLE_DEVICES=7
 1685  python test.py 
 1686  clear
 1687  python test.py
 1688  clear
 1689  python metric/metric.py --dsname='salicon'
 1690  python training_video.py 
 1691  cler
 1692  clear
 1693  python training_video.py 
 1694  matlab
 1695  python training_video.py 
 1696  python training_video.py --train_prototxt='prototxt/vo_train_kldloss_withouteuc.prototxt' 
 1697  clear
 1698  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' 
 1699  export CUDA_VISIBLE_DEVICES=6
 1700  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' 
 1701  export CUDA_VISIBLE_DEVICES=6,7
 1702  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' 
 1703  clear
 1704  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' 
 1705  clear
 1706  python test.py 
 1707  python metric/metric.py 
 1708  python metric/metric.py --dsname='mit1003'
 1709  python metric/avg_metric.py 
 1710  export CUDA_VISIBLE_DEVICES=5
 1711  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 1712  clear
 1713  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 1714  clear
 1715  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 1716  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --visualization=1
 1717  clear
 1718  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1719  top
 1720  nvidia-smi
 1721  top
 1722  nvidia-smi
 1723  export CUDA_VISIBLE_DEVICES=0
 1724  cd pwd/saliency_on_videoset/Train/scripts/
 1725  source set_env.sh 
 1726  export CUDA_VISIBLE_DEVICES=0
 1727  clear
 1728  python test.py 
 1729  clear
 1730  git status
 1731  git add --all 
 1732  git commit -m "regular update. 5 layer deconvolution."
 1733  git push -u origin master
 1734  python metric/avg_metric.py 
 1735  python utils/scavenger.py 
 1736  cd /data/sunnycia/SaliencyDataset/Video/MSU/density/sigma32
 1737  rename 's/(.*)/$1_left/' *
 1738  rename 's/(*)/$1_left/' *
 1739  rename 's/^/_left/' *
 1740  for f in *; do mv "$f" "$f_left"; done
 1741  rename 's/^//_left' *
 1742  rename 's/^/_left' *
 1743  rename 's/^/^_left' *
 1744  rename 's/^/^_left/' *
 1745  rename 's/*/*_left/' *
 1746  rename 's/(*)/$1_left/' *
 1747  rename 's/(.*)$/$1_left/' *
 1748  rename 's/(.*)$/.$1_left/' *
 1749  python
 1750  cd -
 1751  git status
 1752  git add --all
 1753  git commit -m "VideoDataset complete, training video script complete.Network version-1, concate RGB and flow vector after datalayer"
 1754  git push -u origin master
 1755  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1756  python all_in_one.py 
 1757  cd -
 1758  clear
 1759  nvidia-smi
 1760  top
 1761  nvidia-smi
 1762  export CUDA_VISIBLE_DEVICES=6
 1763  python test.py 
 1764  cd -
 1765  ls
 1766  cd -
 1767  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --vowildcard='*_left.*'
 1768  cd -
 1769  python all_in_one.py 
 1770  cd -
 1771  python test.py 
 1772  git status
 1773  git add --all
 1774  git commit -m "Done for video network version-3"
 1775  git push -u origin master
 1776  clear
 1777  python visualize_weight.py 
 1778  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='conv1.jpg' 
 1779  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='conv2.jpg' --layer='conv2'
 1780  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='upsample1.jpg' --layer='upsample_1'
 1781  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='upsample2.jpg' --layer='upsample_2'
 1782  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='scale5c_branch2c.jpg' --layer='scale5c_branch2c'
 1783  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='saliency_map.jpg' --layer='saliency_map'
 1784  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='res3c_branch2c.jpg' --layer='res3c_branch2c'
 1785  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='res2a_branch2a.jpg' --layer='res2a_branch2a'
 1786  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='scale_conv1.jpg' --layer='scale_conv1'
 1787  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='res2a_branch1.jpg' --layer='res2a_branch1'
 1788  nvidia-smi
 1789  vim ~/.bashrc
 1790  clear
 1791  nvidia-smi
 1792  df -h
 1793  nvidia-smi
 1794  clear
 1795  cd /data/sunnycia/saliency_on_videoset
 1796  python main.py 
 1797  cd Fruit-Ninja-Final-Project/
 1798  python main.py 
 1799  clear
 1800  history
 1801  nvidia-smi
 1802  cd ../../
 1803  cd pwd/saliency_on_videoset/
 1804  ls
 1805  cd ~/pwd/saliency_on_videoset/Train/scripts/
 1806  python utils/scavenger.py 
 1807  top
 1808  nvidia-smi
 1809  free -h
 1810  clear
 1811  clc
 1812  cd ../../_Train/Deep-Feature-Flow-master/
 1813  ls
 1814  pwd
 1815  export CUDA_VISIBLE_DEVICES=4,5,6,7
 1816  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1817  clear
 1818  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1819  nvidia-smi
 1820  export CUDA_VISIBLE_DEVICES=4,7
 1821  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1822  nvidia-smi
 1823  top
 1824  nvidia-smi
 1825  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1826  nvidia-smi
 1827  export CUDA_VISIBLE_DEVICES=5,6
 1828  clear
 1829  python training_video.py --train_prototxt='prototxt/vo-v2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1830  source set_env.sh 
 1831  export CUDA_VISIBLE_DEVICES=5,6
 1832  python training_video.py --train_prototxt='prototxt/vo-v2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1833  clear
 1834  cd pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master/
 1835  ls
 1836  nvidia-smi
 1837  export CUDA_VISIBLE_DEVICES=4,5
 1838  history > histroy.txt
 1839  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1840  clear
 1841  cd ../../Train/
 1842  cd scripts/
 1843  export PYTHONPATH=../caffe-flownet/python:$PYTHONPATH
 1844  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1845  export CUDA_VISIBLE_DEVICES=3
 1846  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1847  clear
 1848  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1849  export CUDA_VISIBLE_DEVICES=6
 1850  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1851  export CUDA_VISIBLE_DEVICES=6,7
 1852  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1853  clear
 1854  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1855  clear
 1856  cd 
 1857  cd /home/sunnycia/pwd/saliency_on_videoset/Train/caffe-flownet
 1858  make -j16 all
 1859  make -j8 pycaffe
 1860  make clean
 1861  make -j16 all && make -j4 pycaffe
 1862  make clean
 1863  make -j16 all && make -j4 pycaffe
 1864  make clean
 1865  make -j16 all && make -j4 pycaffe
 1866  make clean
 1867  make -j16 all && make -j4 pycaffe
 1868  make clean
 1869  make -j16 all && make -j4 pycaffe
 1870  make clean
 1871  make -j16 all && make -j4 pycaffe
 1872  make clean
 1873  make -j16 all && make -j4 pycaffe
 1874  make clean
 1875  make -j16 all && make -j4 pycaffe
 1876  make clean
 1877  make -j16 all && make -j4 pycaffe
 1878  cd ../scripts/
 1879  ls
 1880  pwd
 1881  source set_env.sh 
 1882  vim set_env.sh 
 1883  source set_env.sh 
 1884  python training.py --debug 
 1885  python training.py --debug =1
 1886  python training.py --debug =1 --solver_prototxt='net/train.prototxt'
 1887  python training.py --debug =1 --train_prototxt='net/train.prototxt'
 1888  python training.py --debug =1 --train_prototxt='net/train_kldloss_withouteuc.prototxt'
 1889  cd ..
 1890  cd Train/caffe-flownet/
 1891  make -j8 pycaffe
 1892  cd ..
 1893  cd scripts/
 1894  python training.py --debug =1 --train_prototxt='net/train_kldloss_withouteuc.prototxt'
 1895  cd ../caffe-flownet/
 1896  make clean
 1897  vim Makefile.config
 1898  make clean
 1899  make -j16 all && make pycaffe
 1900  cd ..
 1901  cd scripts/
 1902  python training.py --debug =1 --train_prototxt='net/train_kldloss_withouteuc.prototxt'
 1903  clear
 1904  export PYTHONPATH=../caffe-flownet/python:$PYTHONPATH
 1905  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1906  export CUDA_VISIBLE_DEVICES=6
 1907  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1908  nvidia-smi
 1909  export CUDA_VISIBLE_DEVICES=7
 1910  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1911  top
 1912  nvidia-smi
 1913  top
 1914  nvidia-smi
 1915  top
 1916  clear
 1917  top
 1918  nvidia-smi
 1919  free -h
 1920  top
 1921  nvidia-smi
 1922  cd pwd/saliency_on_videoset/Train/scripts/
 1923  source set_env.sh 
 1924  nvidia-smi
 1925  export CUDA_VISIBLE_DEVICES=7
 1926  python test_video.py --output_type='image' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet"
 1927  top
 1928  clear
 1929  top
 1930  clear
 1931  ssh qiudan@172.31.234.248
 1932  source set_env.sh 
 1933  nvidia-smi
 1934  export CUDA_VISIBLE_DEVICES=5,6
 1935  python test_image.py 
 1936  python utils/video_image_type_converter.py --type='tomany' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1937  python utils/video_image_type_converter.py --type='toone' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1938  python utils/video_image_type_converter.py --type='tomany' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1939  python utils/video_image_type_converter.py --type='toone' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1940  python utils/video_image_type_converter.py --type='tomany' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1941  python utils/video_image_type_converter.py --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/saliency' --type='tomany' --group=1
 1942  top
 1943  nvidia-smi
 1944  cd pwd/saliency_on_videoset/Train/scripts/
 1945  ls
 1946  python utils/visualization.py 
 1947  clear
 1948  python utils/visualization.py 
 1949  git status
 1950  git add --all
 1951  git commit -m "Video inference module"
 1952  git push -u origin master
 1953  python utils/visualization.py 
 1954  python metric/avg_metric.py 
 1955  python utils/visualization.py 
 1956  git status
 1957  git add --all
 1958  git commit -m "Done for v1 model inference and metric "
 1959  clear
 1960  python test_video.py 
 1961  python test_video.py --output_type='video' --model_code='v3'
 1962  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet"
 1963  export CUDA_VISIBLE_DEVICES=7
 1964  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet"
 1965  python utils/convert_2_all_in_one.py --basedir="/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/v3"
 1966  cler
 1967  clear
 1968  python metric/metric.py --dsname='videoset'
 1969  python metric/avg_metric.py 
 1970  nvidia-smi
 1971  python utils/scavenger.py 
 1972  ls -a utils
 1973  mv .py video_image_type_converter.py
 1974  cd utils && mv .py video_image_type_converter.py
 1975  cd ..
 1976  python utils/video_image_type_converter.py --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/v3' --type='tomany'
 1977  python utils/video_image_type_converter.py --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/v1' --type='tomany'
 1978  top
 1979  clear
 1980  python
 1981  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 1982  python TestDemo.py 
 1983  top
 1984  nvidia-smi
 1985  python TestDemo.py 
 1986  pwd
 1987  python TestDemo.py 
 1988  top
 1989  nvidia-smi
 1990  top
 1991  free -h
 1992  clear
 1993  cd pwd/saliency_on_videoset/Train/
 1994  cd scripts/
 1995  python test_video.py 
 1996  nvidia-smi
 1997  export CUDA_VISIBLE_DEVICES=4
 1998  python test_video.py 
 1999  nvidia-smi
 2000  export CUDA_VISIBLE_DEVICES=4,5
 2001  python test_video.py 
 2002  source set_env.sh 
 2003  export CUDA_VISIBLE_DEVICES=4,5
 2004  python test_video.py 
 2005  clear
 2006  python test_video.py 
 2007  clear
 2008  python test_video.py 
 2009  clear
 2010  python test_video.py 
 2011  sudo apt-get purge nvidia* 
 2012  python test_video.py 
 2013  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/ImageSet/frame
 2014  ffmpeg
 2015  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 100 -b 200k test.mp4
 2016  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 100 test.mp4
 2017  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 50 test.mp4
 2018  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 10 test.mp4
 2019  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 5 test.mp4
 2020  top
 2021  nvidia-smi
 2022  pwd
 2023  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 2024  python TestDemo.py 
 2025  python
 2026  cd ~/pwd/saliency_on_videoset/
 2027  ls
 2028  cd _Utils/
 2029  ls
 2030  clear
 2031  cd metric_code/
 2032  ls
 2033  matlab -nodesktop
 2034  clear
 2035  cd pwd/saliency_on_videoset/Train/
 2036  ls
 2037  cd scripts/
 2038  ls
 2039  source set_env.sh 
 2040  nvidia-smi
 2041  export CUDA_VISIBLE_DEVICES=5,6
 2042  python test_video.py 
 2043  python test_video.py --output_type=image
 2044  python test_video.py --output_type="image"
 2045  python test_video.py --output_type="image" allinone=1
 2046  python test_video.py --output_type="image" --allinone=1
 2047  python test_video.py --output_type="image" --allinone=1 --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet"
 2048  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one
 2049  python
 2050  python change_name.py 
 2051  cd -
 2052  python metric/metric.py --ds_name='videoset' --debug=1
 2053  python metric/metric.py --dsname='videoset' --debug=1
 2054  cd -
 2055  python change_name.py 
 2056  cd -
 2057  python metric/metric.py --dsname='videoset' --debug=1
 2058  python metric/metric.py --dsname='videoset'
 2059  cler
 2060  clear
 2061  python metric/metric.py --dsname='videoset' --debug=1
 2062  python metric/metric.py --dsname='videoset'
 2063  clear
 2064  python metric/metric.py --dsname='videoset'
 2065  git status
 2066  git add --all
 2067  git commit -m "v3 model inference"
 2068  git push -u origin master
 2069  top
 2070  nvidia-smi
 2071  cd pwd/saliency_on_videoset/Train/scripts/
 2072  ls
 2073  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir="/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos"
 2074  top
 2075  nvidia-smi
 2076  git status
 2077  git add --all
 2078  git commit -m "Copy last frame for video"
 2079  git push -u origin master
 2080  clear
 2081  python metric/avg_metric.py 
 2082  matlab
 2083  top
 2084  nvidia-smi
 2085  top
 2086  clear
 2087  clc
 2088  clear
 2089  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --plotdir="../analyse_vomodel"
 2090  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2091  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --plotdir="../analyse_vomodel"
 2092  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2093  clear
 2094  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2095  clear
 2096  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2097  clear
 2098  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2099  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/sam" --plotdir="../analyse_vomodel"
 2100  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --plotdir="../analyse_vomodel"
 2101  clear
 2102  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --plotdir="../analyse_vomodel"
 2103  git status
 2104  python utils/VorI/combine_frames.py --framedir="/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --videolength=5 --resolution=(1920,1080)
 2105  python utils/VorI/combine_frames.py --framedir="/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --videolength=5 
 2106  python utils/blend_video.py --orivideodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --salvideodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_blend_baseline' --weight=0.3
 2107  python utils/blend_video.py --orivideodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --salvideodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_blend_baseline' --weight=0.3  clear
 2108  ccccccccccccccccc
 2109  clear
 2110  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --outputbase="../analyse_vomodel"
 2111  git status
 2112  git add --all
 2113  python utils/analyse_vomodel_metric.py 
 2114  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --outputbase="../analyse_vomodel"
 2115  clear
 2116  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --outputbase="../analyse_vomodel"
 2117  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputdir='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2118  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2119  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --outputbase="../analyse_vomodel"
 2120  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2121  claer
 2122  clear
 2123  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2124  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputbase="../analyse_vomodel"
 2125  clear
 2126  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputbase="../analyse_vomodel"
 2127  clear
 2128  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputbase="../analyse_vomodel"
 2129  clear
 2130  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputbase="../analyse_vomodel"
 2131  git status 
 2132  git add --all
 2133  git commit -m "Done for jigsaw video visualization"
 2134  git push -u origin master
 2135  python
 2136  clear
 2137  top
 2138  nvidia-smi
 2139  top
 2140  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2141  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --outputbase='../analyse_vomodel'
 2142  python utils/metric_plot_video.py 
 2143  python utils/metric_plot_video.py --metricdir
 2144  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40'
 2145  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --outputbase='../analyse_vomodel'
 2146  python utils/VorI/combine_frames.py --framedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/video_model_result/xu_dupext40' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/video_model_result/xu_dupext40' --videolength=5 
 2147  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/image_model_result/SAM
 2148  python
 2149  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/SAM' --outputbase='../all_visualization
 2150  '
 2151  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/SAM' --outputbase='../all_visualization'
 2152  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2153  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/SAM' --outputbase='../all_visualization'
 2154  cd utils/
 2155  ls
 2156  touch concat_videos.py
 2157  cd ..
 2158  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/xu_dupext40/jud' --outputpath='../output.avi'
 2159  git status
 2160  git add --all
 2161  git commit -m "Add concat video function"
 2162  git push -m origin master
 2163  git push -u origin master
 2164  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/xu_dupext40/jud' --outputpath='../output.avi' --randomorder=1
 2165  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/xu_dupext40/visualization/jud' --outputpath='../xulstm_jud.avi' --randomorder=1
 2166  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/xu_dupext40/visualization/sauc' --outputpath='../xulstm_sauc.avi' --randomorder=1
 2167  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/xu_dupext40/visualization/kld' --outputpath='../xulstm_kld.avi' --randomorder=1
 2168  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/xu_dupext40/visualization/nss' --outputpath='../xulstm_nss.avi' --randomorder=1
 2169  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000/visualization/nss' --outputpath='../propose_nss.avi' --randomorder=1
 2170  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/sam/visualization/nss' --outputpath='../sam_nss.avi' --randomorder=1
 2171  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/SAM/visualization/nss' --outputpath='../sam_nss.avi' --randomorder=1
 2172  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/SAM/visualization/kld' --outputpath='../sam_kld.avi' --randomorder=1
 2173  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/SAM/visualization/sauc' --outputpath='../sam_sauc.avi' --randomorder=1
 2174  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/SAM/visualization/jud' --outputpath='../sam_jud.avi' --randomorder=1
 2175  ls
 2176  vim ~/.bashrc
 2177  top
 2178  etop
 2179  top
 2180  clear
 2181  python
 2182  cd pwd/saliency_on_videoset/
 2183  cd _Train/OMCNN_2CLSTM/
 2184  ls
 2185  nvidia-smi
 2186  export CUDA_VISIBLE_DEVICES=6
 2187  python TestDemo.py 
 2188  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --ouptutdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu' --outputtype='video'
 2189  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu' --outputtype='video'
 2190  top
 2191  nvidia-smi
 2192  top
 2193  pwd
 2194  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu_dupext30" --outputtype="video"
 2195  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu_dupext30' --outputtype="video"
 2196  nvidia-smi
 2197  export CUDA_VISIBLE_DEVICES=6
 2198  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu_dupext30' --outputtype="video"
 2199  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu_dupext30' --outputtype="image"
 2200  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu_dupext40' --outputtype="image"
 2201  top
 2202  cd -
 2203  cd ~/pwd/saliency_on_videoset/Train/scripts/
 2204  ls
 2205  clear
 2206  cd 
 2207  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/Videos
 2208  python rename.py 
 2209  top
 2210  nvidia-smi
 2211  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2212  git status
 2213  git add --all
 2214  git commit -m "add common util. add videl/frame level analysis module"
 2215  git push -u origin master
 2216  nvidia-smi
 2217  top
 2218  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../analyse_vomodel'
 2219  top
 2220  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../analyse_vomodel'
 2221  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../analyse_vomodel'
 2222  cd /data/sunnycia/saliency_on_videoset/_Train
 2223  git clone https://github.com/piiswrong/deep3d.git
 2224  df -h
 2225  top
 2226  cd /data/sunnycia/saliency_on_videoset/_Utils/metric_code
 2227  matlab -nodesktop
 2228  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2229  ls
 2230  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --outputbase='../analyse_vomodel'
 2231  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../analyse_vomodel'
 2232  ls
 2233  python utils/VorI/combine_frames.py --framedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/image_model_result/SAM' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --videolength=5
 2234   python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/video_model_result/xu_dupext40' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/xu_dupext40' --outputbase='../all_visualization' 
 2235   python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../all_visualization' 
 2236  clear
 2237  cd pwd/saliency_on_videoset/_Train/OMCNN_2CLSTM/
 2238  python test.py 
 2239  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu' --outputtype='image'
 2240  nvidia-smi
 2241  clear
 2242  export CUDA_VISIBLE_DEVICES=7
 2243  clear
 2244  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu' --outputtype='image'
 2245  clear
 2246  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu' --outputtype='image'
 2247  clear
 2248  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu' --outputtype='image'
 2249  python TestDemo.py 
 2250  cd ~/pwd/saliency_on_videoset/Train/
 2251  ls
 2252  cd scripts/
 2253  ls
 2254  git status
 2255  git add --all
 2256  git commit -m "routine submit"
 2257  git push -u origin master
 2258  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir"/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2259  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir="/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2260  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir"/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2261  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir="/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2262  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=40 --outputdir="/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2263  cd /data/sunnycia/saliency_on_videoset/_Utils
 2264  cd -
 2265  matlab -nodesktop
 2266  top
 2267  cd /data/sunnycia/SaliencyDataset/Image/MIT300
 2268  ls
 2269  unzip BenchmarkIMAGES.zip 
 2270  ls
 2271  cd BenchmarkIMAGES/
 2272  ls
 2273  cd pwd/saliency_on_videoset/Train/scripts/
 2274  git clone https://github.com/lmb-freiburg/flownet2.git
 2275  cp -R /data/sunnycia/saliency_on_videoset/_Train/flownet2 ./
 2276  cd flownet2/
 2277  git status
 2278  cd ../pymetric/
 2279  ls -a
 2280  cd ..
 2281  cd flownet2/
 2282  ls
 2283  history > history
 2284  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2285  cd scripts/
 2286  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2287  cd ..
 2288  ./set-env.sh 
 2289  cd scripts/
 2290  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2291  python
 2292  cd ..
 2293  ./set-env.sh 
 2294  export PYTHONPATH="$CAFFE_PATH/python:$PYTHONPATH"
 2295  export PYTHONPATH="./python:$PYTHONPATH"
 2296  python
 2297  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2298  cd scripts/
 2299  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2300  cd ..
 2301  source set-env.sh 
 2302  cd scripts/
 2303  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2304  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame4.bmp frame6.bmp output.flo
 2305  cd ..
 2306  cp -R flownet2/ ../
 2307  cd ..
 2308  cd caffe-flownet/
 2309  make clean
 2310  pwd
 2311  cd ../scripts/
 2312  python scavenger.py 
 2313  cd flownet2/
 2314  source set-env.sh 
 2315  cd scripts/
 2316  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2317  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2318  python call_flownet.py 
 2319  cd flownet2/
 2320  source set-env.sh 
 2321  cd ..
 2322  python call_flownet.py 
 2323  source set_env.sh 
 2324  python call_flownet.py 
 2325  export CUDA_VISIBLE_DEVICES=0
 2326  python call_flownet.py 
 2327  git status
 2328  git add --all
 2329  git commit -m "Add flownet module, set environment variable"
 2330  git push -u origin master
 2331  git clone https://github.com/liruoteng/OpticalFlowToolkit.git
 2332  git status
 2333  git add --all 
 2334  git commit -m "clean my table. Something need to be modify later"
 2335  git push -u origin master
 2336  python call_flownet.py 
 2337  $PATH
 2338  python call_flownet.py 
 2339  git status
 2340  git add --all
 2341  git commit -m "Extract Saliencynet from test module, not check yet"
 2342  clear
 2343  export CUDA_VISIBLE_DEVICES=7
 2344  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 2345  pwd
 2346  git status
 2347  git add --all
 2348  git commit -m "Video network version-2 on going"
 2349  git push -u origin master
 2350  clear
 2351  nvidia-smi
 2352  python utils/scavenger.py 
 2353  clear
 2354  python metric/metric.py --dsname='msu'
 2355  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/saliency
 2356  ls
 2357  cd -
 2358  cd /data/sunnycia/saliency_on_videoset/_Utils/metric_code
 2359  matlab -nodesktop
 2360  matlab
 2361  matlab -nodesktop
 2362  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2363  ls
 2364  git status
 2365  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2366  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --outputbase='../analyse_vomodel'
 2367  source set_env.sh 
 2368  nvidia-smi
 2369  export CUDA_VISIBLE_DEVICES=6
 2370  python test_image.py 
 2371  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/SAM' --outputbase='../analyse_vomodel'
 2372  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/video_model_result/xu_dupext40' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/xu_dupext40' --outputbase='../analyse_vomodel'
 2373  df -h
 2374  top
 2375  nvidia-smi
 2376  top
 2377  nvidia-smi
 2378  top
 2379  nvidia-smi
 2380  top
 2381  nvidia-smi
 2382  top
 2383  nvidia-smi
 2384  top
 2385  cd pwd/saliency_on_videoset/Train/scripts/
 2386  ls
 2387  git status
 2388  python metric/img2mat.py --help
 2389  python metric/img2mat.py --imgdir='/data/sunnycia/SaliencyDataset/Image/MIT1003/fixPts' --matdir='/data/sunnycia/SaliencyDataset/Image/MIT1003/fixPts-mat'
 2390  git status
 2391  git add --all
 2392  git commit -m "Clean code for metric 1. add function: img2mat"
 2393  git push -u origin master
 2394  git status
 2395  python metric/avg_metric.py --metricdir='../metric-matlab'
 2396  pwd
 2397  top
 2398  nvidia-smi
 2399  cd metric/l
 2400  cd metric/
 2401  ls
 2402  cd saliency/
 2403  ls
 2404  cd code_forOptimization/
 2405  ls
 2406  matlab 
 2407  cd ../..
 2408  cd ..
 2409  git status
 2410  git add --all
 2411  git commit -m "add metric for videoset data base. Special:fadopt frame_cut"
 2412  git push -u origin master
 2413  cd pwd/saliency_on_videoset/Train/scripts/
 2414  ls
 2415  python metric/avg_metric.py --metricdir='../metric-matlab'
 2416  history >history
 2417  clear
 2418  cd pwd/saliency_on_videoset/Train/
 2419  ls
 2420  cd scripts/
 2421  matlab -nodesktop
 2422  top
 2423  df -h
 2424  top
 2425  nvidia-smi
 2426  free -h
 2427  python test_image.py --testset='mit1003' --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000' --iterselection='full'
 2428  export CUDA_VISIBLE_DEVICES=7
 2429  nvidia-smi
 2430  python test_image.py --testset='mit1003' --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000' --iterselection='full'
 2431  clear
 2432  python test_image.py --testset='mit1003' --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000' --iterselection='full'
 2433  matlab -nodesktop
 2434  clear 
 2435  clear
 2436  matlab -nodesktop
 2437  python metric/avg_metric.py 
 2438  python metric/avg_metric.py --metricdir='../metric-matlab'
 2439  python test_image.py --testset='mit1003' --modelname='train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --iterselection='full'
 2440  matlab -nodesktop
 2441  top
 2442  nvidia-smi
 2443  top
 2444  free -h
 2445  cd pwd/saliency_on_videoset/
 2446  ls
 2447  cd Train/
 2448  ls
 2449  git clone https://github.com/chuckcho/video-caffe.git
 2450  cd video-caffe/
 2451  ls
 2452  cp Makefile.config.example Makefile.config
 2453  make -j4
 2454  ls /usr/lib/
 2455  make clean
 2456  mkdir build && cd build
 2457  cmake ..
 2458  cd ..
 2459  clear
 2460  make -j4
 2461  cd examples/c3d_ucf101/
 2462  ls
 2463  unrar
 2464  clear
 2465  cd /data/sunnycia/UCF101
 2466  unrar x UCF101.rar 
 2467  cd -
 2468  ls
 2469  clear
 2470  export CUDA_VISIBLE_DEVICES=7
 2471  nvidia-smi
 2472  bash extract_UCF-101_frames.sh 
 2473  cd /data/sunnycia/UCF-101/PlayingFlute/v_PlayingFlute_g18_c03
 2474  ls
 2475  cd -
 2476  cd /data/sunnycia/UCF-101/PlayingFlute/
 2477  ls
 2478  cd ..
 2479  cd -
 2480  rmdir 
 2481  rmdir --help
 2482  rmdir .
 2483  rmdir -p ./
 2484  pwd
 2485  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2486  bash extract_UCF-101_frames.sh 
 2487  top
 2488  nvidia-smi
 2489  top
 2490  topq
 2491  top
 2492  nvidia-smi
 2493  free -h
 2494  clear
 2495  cd pwd/saliency_on_videoset/Train/
 2496  cd scripts/
 2497  matlab -nodesktop
 2498  ls
 2499  python metric/metric.py --dsname='mit1003' --modelname='cb-train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000'
 2500  python metric/avg_metric.py 
 2501  cd ../..
 2502  cd _Utils/metric_code/
 2503  matlab -nodesktop
 2504  pwd
 2505  cd ../..
 2506  cd Train/scripts/
 2507  cd utils/
 2508  ls
 2509  git clone https://github.com/cvzoya/saliency.git
 2510  ls
 2511  cd ..
 2512  ls
 2513  matlab
 2514  matlab -nodesktop
 2515  clear
 2516  matlab -nodekstop
 2517  clear
 2518  matlab -nodesktop
 2519  clear
 2520  matlab -nodesktop
 2521  clear
 2522  matlab -nodesktop
 2523  clear
 2524  matlab -nodesktop
 2525  clear
 2526  matlab -nodesktop
 2527  clear
 2528  matlab -nodesktop
 2529  clear
 2530  matlab -nodesktop
 2531  clear
 2532  python test_image.py --
 2533  nvidia-smi
 2534  export CUDA_VISIBLE_DEVICES=7
 2535  python test_image.py --train_prorotxt='train_kldloss.prototxt' --updatesolverdict={'lr_policy':'"step"','stepsize':'100000','gamma':'0.1'} --extrainfodict={'dataset':'bigunion'} --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2536  python test_image.py --train_prorotxt='train_kldloss.prototxt' --updatesolverdict='{'lr_policy':'"step"','stepsize':'100000','gamma':'0.1'}' --extrainfodict='{'dataset':'bigunion'}' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2537  python test_image.py --train_prorotxt='train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2538  python test_image.py --train_prototxt='train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2539  python training_image.py --train_prototxt='train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2540  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2541  source set_env.sh 
 2542  export CUDA_VISIBLE_DEVICES=7
 2543  clear
 2544  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2545  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' --debug=1
 2546  clear
 2547  top
 2548  nvidia-smi
 2549  python metric/avg_metric.py 
 2550  python metric/avg_metric.py --metricdir='../metric-matlab'
 2551  df -h
 2552  top
 2553  nvidia-smi
 2554  clear
 2555  cd /data//sunnycia/SaliencyDataset/Video/MSU/
 2556  ls
 2557  cd frames_allinone/
 2558  ls F*
 2559  ls A*
 2560  ls a*
 2561  ls
 2562  clear
 2563  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Image/
 2564  cd /data/sunnycia/SaliencyDataset/Image/SALICON/DATA
 2565  ls
 2566  cd images
 2567  ls *
 2568  clear
 2569  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Image
 2570  cd ..
 2571  ls
 2572  cd train_val/
 2573  ls
 2574  cd train2014/
 2575  ls
 2576  pwd
 2577  ls
 2578  cd images/
 2579  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Image/
 2580  cd ../..
 2581  ls
 2582  cd val2014/
 2583  ls
 2584  cd images/
 2585  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Image
 2586  cd ..
 2587  ls
 2588  cd density/
 2589  cp * /
 2590  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Density
 2591  pwd
 2592  cd ../../train2014/density/
 2593  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Density
 2594  cd ..
 2595  cd /home/sunnycia/pwd/saliency_on_videoset/Train/scripts
 2596  ls
 2597  clear
 2598  claer
 2599  source set_env.sh 
 2600  nvidia-smi
 2601  export CUDA_VISIBLE_DEVICES=6
 2602  history > history.txt 
 2603  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/alicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='bigunion' --debug=True
 2604  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='bigunion' --debug=True
 2605  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='bigunion'
 2606  cd pwd/saliency_on_videoset/Train/scripts/
 2607  ls
 2608  history > history
 2609  python test_image.py 
 2610  clear
 2611  top
 2612  python test_image.py --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000' 
 2613  python test_image.py --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000'  --testset='mit1003'
 2614  nvidia-smi
 2615  export CUDA_VISIBLE_DEVICES=7
 2616  python test_image.py --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000'  --testset='mit1003'
 2617  ls
 2618  pwd
 2619  matlab
 2620  matlab -nodesktop
 2621  clear
 2622  ls -l /data/sunnycia/SaliencyDataset/Image/MIT1003/saliency
 2623  cd metric/
 2624  matlab -nodesktop
 2625  clear
 2626  cd pwd/saliency_on_videoset/Train/
 2627  ls
 2628  cd scripts/
 2629  history >history
 2630  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/OpticalFlowToolkit/data/example/Middlebury
 2631  matlab
 2632  cd pwd/saliency_on_videoset/Train/scripts/
 2633  source set_env.sh 
 2634  nvidia-smi
 2635  export CUDA_VISIBLE_DEVICES=6
 2636  clear
 2637  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2638  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2639  top
 2640  nvidia-smi
 2641  clear
 2642  pwd
 2643  cd ..
 2644  ls
 2645  git clone https://github.com/facebook/C3D.git
 2646  cd C3D/
 2647  ls
 2648  cd C3D-v1.1/
 2649  ls
 2650  cd examples/
 2651  ls
 2652  cd c3d_ucf101_finetuning/
 2653  ls
 2654  vim finetuning_ucf101.sh 
 2655  pwd
 2656  cd ../..
 2657  ls
 2658  cp Makefile.config.example Makefile.config
 2659  make -j8 all
 2660  make pycaffe
 2661  cd -
 2662  ls
 2663  clear
 2664  ls
 2665  bash finetuning_ucf101.sh 
 2666  clear
 2667  top
 2668  nvidia-smi
 2669  cd pwd/saliency_on_videoset/Train/scripts/
 2670  source set_env.sh 
 2671  export CUDA_VISIBLE_DEVICES=6
 2672  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2673  clear
 2674  top
 2675  nvidia-smi
 2676  cd pwd/saliency_on_videoset/Train/
 2677  cd video-caffe/
 2678  tools/extra/plot_training_loss.sh 
 2679  tools/extra/plot_training_loss.sh examples/c3d_ucf101/c3d_ucf101_train.log 
 2680  top
 2681  nvidia-smi
 2682  cd ..
 2683  cd scripts/
 2684  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2685  export CUDA_VISIBLE_DEVICES=6
 2686  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2687  source set_env.sh 
 2688  export CUDA_VISIBLE_DEVICES=6
 2689  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2690  clear
 2691  clear
 2692  cd pwd/saliency_on_videoset/Train/scripts/
 2693  source set_env.sh 
 2694  nvidia-smi
 2695  top
 2696  export CUDA_VISIBLE_DEVICES=6
 2697  pwd
 2698  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2699  export CUDA_VISIBLE_DEVICES=6
 2700  clear
 2701  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2702  top
 2703  nvidia-smi
 2704  top
 2705  nvidia-smi
 2706  top
 2707  clear
 2708  cd /data/sunnycia/SaliencyDataset/Video/LEDOV/LEDOV
 2709  matlab 
 2710  top
 2711  nvidia-smi
 2712  cd pwd/saliency_on_videoset/_Train/
 2713  ls
 2714  cd ../Train/
 2715  ls
 2716  cd video-caffe/
 2717  ls
 2718  make -j4
 2719  make pycaffe
 2720  ls
 2721  cd examples/
 2722  ls
 2723  cd c3d_ucf101/
 2724  ls
 2725  pwd
 2726  export CUDA_VISIBLE_DEVICES=7
 2727  cd ../..
 2728  examples/c3d_ucf101/train_ucf101.sh
 2729  ./build/tools/caffe
 2730  ./build/tools/caffe   train   --solver=examples/c3d_ucf101/c3d_ucf101_solver.prototxt   $@   2>&1 | tee examples/c3d_ucf101/c3d_ucf101_train.log
 2731  make clean
 2732  top
 2733  nvidia-smi
 2734  make -j8 all
 2735  ./build/tools/caffe   train   --solver=examples/c3d_ucf101/c3d_ucf101_solver.prototxt   $@   2>&1 | tee examples/c3d_ucf101/c3d_ucf101_train.log
 2736  cd /data/sunnycia/saliency_on_videoset/Train/scripts/prototxt
 2737  ls
 2738  cd .
 2739  cd ..
 2740  clear
 2741  git status
 2742  git add --all
 2743  git status
 2744  git commit -m "FIX BUG:V3 model bug"
 2745  git push -u origin master
 2746  history > history
 2747  source set_env.sh 
 2748  clear
 2749  nvidia-smi
 2750  export CUDA_VISIBLE_DEVICES=7
 2751  clear
 2752  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2753  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2754  clear
 2755  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2756  cler
 2757  clear
 2758  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2759  clear
 2760  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2761  to
 2762  top
 2763  nvidia-smi
 2764  clear
 2765  top
 2766  nvidia-smi
 2767  cd pwd/saliency_on_videoset/Train/scripts/
 2768  ls
 2769  git status
 2770  git add --all
 2771  git commit -m "Debug stack based v3 training process. add stack8/16 network prototxt"
 2772  git push -u origin master
 2773  clera
 2774  clear
 2775  top
 2776  nvidia-smi
 2777  top
 2778  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2779  nvidia-smi
 2780  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2781  nvidia-smi
 2782  cd pwd/saliency_on_videoset/Train/scripts/
 2783  ls
 2784  source set_env.sh 
 2785  ls
 2786  export CUDA_VISIBLE_DEVICES=7
 2787  ls
 2788  clear
 2789  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack8.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=8
 2790  top
 2791  nvidia-smi
 2792  top
 2793  nvidia-smi
 2794  export CUDA_VISIBLE_DEVICES=4
 2795  cd pwd/saliency_on_videoset/Train/scripts/
 2796  source set_env.sh 
 2797  export CUDA_VISIBLE_DEVICES=4
 2798  clear
 2799  python python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --imagesize=(480,288) --keyframeinterv=16
 2800  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --imagesize=(480,288) --keyframeinterv=16
 2801  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=16
 2802  clear
 2803  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack16.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=16
 2804  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack16.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=8
 2805  export CUDA_VISIBLE_DEVICES=7
 2806  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack16.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=8
 2807  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack16.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=16
 2808  git status 
 2809  git add --all 
 2810  git commit -m "Done for v4-1. set_env.sh add argument. Done for C3D training scripts"
 2811  git push -u origin master
 2812  top
 2813  clear
 2814  cd pwd/saliency_on_videoset/Train/scripts/
 2815  source set_env.sh 
 2816  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2817  export CUDA_VISIBLE_DEVICES=6
 2818  nvidia-smi
 2819  export CUDA_VISIBLE_DEVICES=7
 2820  clear
 2821  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2822  clear
 2823  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2824  clear
 2825  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2826  clear
 2827  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2828  clear
 2829  clera
 2830  clear
 2831  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2832  clear
 2833  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2834  ffprobe
 2835  clear
 2836  cd pwd/saliency_on_videoset/Train/scripts/
 2837  ls
 2838  git status
 2839  git add --all
 2840  git commit -m "add c3d dataset interface(not finish yet)"
 2841  git push -u origin master
 2842  clear
 2843  cd ..
 2844  ls
 2845  git clone python
 2846  python
 2847  pip3
 2848  ls /usr/local/bin/
 2849  clear
 2850  pip3
 2851  clear
 2852  pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl 
 2853  git clone https://github.com/kenshohara/video-classification-3d-cnn-pytorch.git
 2854  ls
 2855  ls -l
 2856  pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl 
 2857  pip install --upgrade pip
 2858  pip3 install --upgrade pip3
 2859  pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl 
 2860  pip
 2861  clear
 2862  pip3
 2863  clear
 2864  ls .pip
 2865  ls ~/.pip
 2866  pip
 2867  cd scripts/
 2868  sl
 2869  ls
 2870  cd ../video-caffe/examples/c3d_ucf101/
 2871  ls
 2872  pwd
 2873  ./train_ucf101.sh 
 2874  cd ../..
 2875  ./examples/c3d_ucf101/train_ucf101.sh 
 2876  nvidia-smi
 2877  top
 2878  clear
 2879  export CUDA_VISIBLE_DEVICES=6
 2880  ./examples/c3d_ucf101/train_ucf101.sh 
 2881  cd pwd/saliency_on_videoset/Train/scripts/
 2882  history > history
 2883  nvidia-smi
 2884  cd pwd/saliency_on_videoset/Train/scripts/
 2885  source set_env.sh ../video-caffe/
 2886  export CUDA_VISIBLE_DEVICES=4
 2887  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1
 2888  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1
 2889  cd pwd/saliency_on_videoset/Train/scripts/
 2890  clear
 2891  source set_env.sh ../video-caffe/
 2892  nvidia-smi
 2893  export CUDA_VISIBLE_DEVICES=4
 2894  export CUDA_VISIBLE_DEVICES=6
 2895  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=20 --lastlayer='fc9'
 2896  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=10 --lastlayer='fc9'
 2897  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=20
 2898  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=10
 2899  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=5
 2900  export CUDA_VISIBLE_DEVICES=6
 2901  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=2 --plot_iter=20
 2902  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=2 --plotiter=20
 2903  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=1 --plotiter=40
 2904  source set_env.sh ../caffe-flownet/
 2905  export CUDA_VISIBLE_DEVICES=6
 2906  clear
 2907  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2908  top
 2909  nvidia-smi
 2910  clear
 2911  cd pwd/saliency_on_videoset/Train/scripts/
 2912  th
 2913  clear
 2914  source set_env.sh 
 2915  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet" --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2916  nvidia-smi
 2917  clear
 2918  export CUDA_VISIBLE_DEVICES=3
 2919  nvidia-smi
 2920  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet" --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2921  clear
 2922  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet" --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2923  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2924  clear
 2925  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2926  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_150000.caffemodel' --framestack=5 
 2927  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_150000.caffemodel' --framestack=5  &
 2928  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_150000.caffemodel' --framestack=5
 2929  clear
 2930  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt
 2931  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --output='./'
 2932  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --output='./' --layer='conv1_new'
 2933  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --output='./output.jpg' --layer='conv1_new'
 2934  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_200000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3_deploy.prototxt' --output='./output.jpg' --layer='conv1_new'
 2935  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101/c3d_ucf101_iter_35000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101/c3d_ucf101_deploy.prototxt' --output='./output.jpg' --layer='conv1a'
 2936  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2937  source set_env.sh 
 2938  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe
 2939  make pycaffe
 2940  cd -
 2941  bash set_env.sh 
 2942  vim set_env.sh 
 2943  bash set_env.sh 
 2944  source set_env.sh 
 2945  pytho viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt'
 2946  python viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt'
 2947  python viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt' --output='./output.jpg'
 2948  python
 2949  source set_env.sh 
 2950  python viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt' --output='./output.jpg'
 2951  python viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt' --output='./output.jpg' --layer='conv1a'
 2952  top
 2953  nvidia-smi
 2954  cd ..
 2955  cd ~/pwd/saliency_on_videoset/Train/scripts/
 2956  source set_env.sh 
 2957  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2958  cd ../..
 2959  bash ./tools/extra/plot_training_loss.sh 
 2960  bash ./tools/extra/plot_training_loss.sh examples/c3d_ucf101/*.log
 2961  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2962  bash ../../tools/extra/plot_training_loss.sh *.log
 2963  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2964  bash ../../tools/extra/plot_training_loss.sh *.log
 2965  eog
 2966  bash ../../tools/extra/plot_training_loss.sh *.log
 2967  python ../../py_plot_training_loss.py /tmp/iter_loss_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt /tmp/iter_loss_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.png /tmp/iter_accuracy_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt /tmp/iter_accuracy_top5_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt
 2968  python ../../tools/extra/py_plot_training_loss.py /tmp/iter_loss_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt /tmp/iter_loss_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.png /tmp/iter_accuracy_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt /tmp/iter_accuracy_top5_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt
 2969  $TMPTIME
 2970  clear
 2971  vim /etc/default/rcS
 2972  vim /etc/default/rc5
 2973  ls /etc/default/
 2974  clear
 2975  ls /etc/cron*
 2976  vim /etc/cron.daily/
 2977  ls /usr/lib/tmpfiles.d/tmp.conf 
 2978  vim /usr/lib/tmpfiles.d/tmp.conf 
 2979  clear
 2980  nvidia-smi
 2981  top
 2982  nvidia-smi
 2983  top
 2984  nvidia-smi
 2985  watch -n 1 nvidia-smi
 2986  watch -n 0.5 nvidia-smi
 2987  top
 2988  nvidia-smi
 2989  cd ~/pwd/saliency_on_videoset/Train/scripts/
 2990  source set_env.sh ../video-caffe/
 2991  export CUDA_VISIBLE_DEVICES=7
 2992  clear
 2993  $
 2994  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1
 2995  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1
 2996  python
 2997  clear
 2998  python test_video.py --output_type="video" --test_base='videoset'  --model_code='v4' --video_deploy_path='prototxt/vo-v4-1-deploy.prototxt' --video_model_path='../training_output/vo-v4-1-static/snapshot-_iter_1000.caffemodel'
 2999  clear
 3000  python test_video.py --output_type="video" --test_base='videoset'  --model_code='v4' --video_deploy_path='prototxt/vo-v4-1-deploy.prototxt' --video_model_path='../training_output/vo-v4-1-static/snapshot-_iter_1000.caffemodel'
 3001  cd pwd/saliency_on_videoset/Train/scripts/
 3002  source set_env.sh 
 3003  nvidia-smi
 3004  export CUDA_VISIBLE_DEVICES=5
 3005  clear
 3006  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_100000.caffemodel' --framestack=8
 3007  nvidia-smi
 3008  export CUDA_VISIBLE_DEVICES=4
 3009  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_100000.caffemodel' --framestack=8
 3010  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3011  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=16
 3012  git status
 3013  git add --all
 3014  git commit -m "Done for v3 5/8/16 testing code."
 3015  git push -u origin master
 3016  clear
 3017  $1
 3018  $0
 3019  bash set_env.sh ../video-caffe/
 3020  python
 3021  source set_env.sh ../video-caffe/
 3022  python
 3023  clear
 3024  python training_video_c3d_based.py 
 3025  nvidia-smi
 3026  export CUDA_VISIBLE_DEVICES=5
 3027  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt'
 3028  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3029  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=16 
 3030  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=50
 3031  python utils/scavenger.py 
 3032  clear
 3033  python utils/scavenger.py 
 3034  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=50
 3035  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3036  clear
 3037  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3038  clear
 3039  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3040  clear
 3041  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3042  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25
 3043  top
 3044  nvidia-smi
 3045  top
 3046  nvidia-smi
 3047  cd pwd/saliency_on_videoset/Train/scripts/
 3048  history > history
 3049  source set_env.sh ../caffe-flownet/
 3050  nvidia-smi
 3051  export CUDA_VISIBLE_DEVICES=6
 3052  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=16
 3053  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=16
 3054  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25
 3055  source set_env.sh ../video-caffe/
 3056  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25
 3057  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=20
 3058  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 
 3059  clear
 3060  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 
 3061  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 clear
 3062  clear
 3063  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 
 3064  top
 3065  watch -n 0.5 nvidia-smi
 3066  top
 3067  free -h
 3068  nvidia-smi
 3069  clear
 3070  cd pwd/saliency_on_videoset/Train/scripts/
 3071  git status
 3072  source set_env.sh ../caffe-flownet/
 3073  export CUDA_VISIBLE_DEVICES=7
 3074  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3075  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3076  nvidia-smi
 3077  export CUDA_VISIBLE_DEVICES=6
 3078  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3079  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3080  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon//data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_350000.caffemodel' --framestack=16
 3081  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon//data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_350000.caffemodel' --framestack=8
 3082  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_350000.caffemodel' --framestack=8
 3083  nvidia-smi
 3084  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_350000.caffemodel' --framestack=8
 3085  git clone https://github.com/albioTQ/CNN_Visualization.git
 3086  git clone https://github.com/hvy/chainer-visualization.git
 3087  top
 3088  nvidia-smi
 3089  cd ../C3D-v1.0/
 3090  vim Makefile.config
 3091  make clean
 3092  make -j8 all
 3093  cd examples/
 3094  ls
 3095  cd c3d_feature_extraction/
 3096  ls
 3097  chmod u+x c3d_sport1m_feature_extraction_*sh
 3098  ls
 3099  ./c3d_sport1m_feature_extraction_video.sh 
 3100   cd ~/pwd/saliency_on_videoset/Train/scripts/
 3101  source set_env.sh ../C3D-v1.0/
 3102  python
 3103  clea
 3104  clear
 3105  ls
 3106  cd ..
 3107  cd Train/
 3108  cd C3D-v1.1/
 3109  make runtest
 3110  export CUDA_VISIBLE_DEVICES=5
 3111  make runtest
 3112  cd ..
 3113  cd scripts/
 3114  ls
 3115  python training_video_c3d_based.py 
 3116  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu' --videolength=16
 3117  source set_env.sh ../C3D-v1.1/
 3118  nvidia-smi
 3119  export CUDA_VISIBLE_DEVICES=5
 3120  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu' --videolength=16
 3121  python
 3122  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3123  cd ../../
 3124  cd Train/
 3125  cd C3D-v1.1/
 3126  make clean
 3127  make -j8 all
 3128  make pycaffe
 3129  make clean
 3130  make -j8 all && make -j4 pycaffe
 3131  cd ..
 3132  cd scripts/
 3133  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu' --videolength=16
 3134  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3135  cd ..
 3136  git clone https://github.com/facebook/C3D.git
 3137  cd C3D/
 3138  cd ../C3D-v1.1/
 3139  ls
 3140  cp Makefile.config.example Makefile.config
 3141  ls
 3142  pwd
 3143  ls
 3144  cd ..
 3145  cd C3D-v1.1/
 3146  ls
 3147  cp Makefile.config.example Makefile.config
 3148  vim Makefile.config
 3149  cd src/
 3150  ls
 3151  cd ..
 3152  make -j8 all && make -j4 pycaffe
 3153  cd ../scripts/
 3154  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3155  source set_env.sh ../C3D-v1.1/
 3156  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3157  nvidia-smi
 3158  export CUDA_VISIBLE_DEVICES=6
 3159  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3160  cd -
 3161  make clean
 3162  make -j8 all && make -j8 pycaffe
 3163  cd -
 3164  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3165  cd -
 3166  make clean
 3167  make -j8 all && make pycaffe
 3168  make clean
 3169  make -j8 all
 3170  make -j8 pycaffe
 3171  cd -
 3172  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3173  cd -
 3174  make clean
 3175  make -j16 all -make -j16 pycaffe
 3176  make -j16 all && make -j16 pycaffe
 3177  make clean
 3178  make -j16 all && make -j16 pycaffe
 3179  cd -
 3180  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3181  cd -
 3182  make clean 
 3183  make -j8 caffe && make -j16 pycaffe
 3184  make -j8 all && make -j16 pycaffe
 3185  cd -
 3186  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3187  cd -
 3188  make clean 
 3189  make -j8 all && make -j16 pycaffe
 3190  make clean
 3191  make -j8 all && make -j16 pycaffe
 3192  cd ..
 3193  git clone https://github.com/sjtutsb/caffe-3DConv-master.git
 3194  ls -l
 3195  rm -rf caffe-3DConv-master/
 3196  git clone https://github.com/dutran/C3D_dev.git
 3197  cd C3D_dev/
 3198  ls
 3199  cp Makefile.config.example Makefile.config
 3200  vim Makefile.config
 3201  make -j8 all && make pycaffe
 3202  vim Makefile.config
 3203  make -j8 all && make pycaffe
 3204  vim Makefile.config
 3205  make -j8 all && make pycaffe
 3206  make clean
 3207  make -j16 all
 3208  cd ..
 3209  rm -rf C3D_dev/
 3210  ls
 3211  git clone https://github.com/BVLC/caffe.git
 3212  cd caffe
 3213  ls
 3214  cp Makefile.config.example Makefile.config
 3215  vim Makefile.config
 3216  cd src/
 3217  ls
 3218  cd caffe/
 3219  screen -h
 3220  top
 3221  cd pwd/saliency_on_videoset/Train/scripts/
 3222  source set_env.sh ../video-caffe/
 3223  export CUDA_VISIBLE_DEVICES=5
 3224  python test_video.py --output_type="video" --test_base='videoset'  --model_code='v4' --video_deploy_path='prototxt/vo-v4-1-deploy.prototxt' --video_model_path='../training_output/vo-v4-1-static/snapshot-_iter_1000.caffemodel'
 3225  python test_video.py --output_type="video" --test_base='videoset'  --model_code='v4' --video_deploy_path='prototxt/vo-v4-1-deploy.prototxt' --video_model_path='../training_output/vo-v4-1-static-adadelta/snapshot-_iter_1000.caffemodel'
 3226  cd /data/sunnycia/saliency_on_videoset/Train/C3D/C3D-v1.0
 3227  ls
 3228  cp Makefile.config.example Makefile.config
 3229  vim Makefile.config
 3230  make -j8 all
 3231  make clean
 3232  make -j8 all
 3233  make pycaffe
 3234  python
 3235  clear
 3236  cd ../../
 3237  git clone https://github.com/chuckcho/video-caffe.git
 3238  cd video-caffe
 3239  make -j8 all
 3240  cd ..
 3241  cd video-caffe-c3d/
 3242  make -j8 all
 3243  cp Makefile.config.example Makefile.config
 3244  vim Makefile.config
 3245  make -j8 all
 3246  cd ..
 3247  ls
 3248  cd C3D
 3249  cd ..
 3250  cd C3D-v1.0/
 3251  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.0/examples/c3d_feature_extraction
 3252  bash c3d_sport1m_feature_extraction_video.sh 
 3253  nvidia-smi
 3254  export CUDA_VISIBLE_DEVICES=5
 3255  bash c3d_sport1m_feature_extraction_video.sh 
 3256  cd ../..
 3257  vim Makefile.config
 3258  make runtest
 3259  make -j8 runtest
 3260  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.0
 3261  make clean
 3262  ls
 3263  cm -rf include/
 3264  rm -rf include/
 3265  make -j8 all
 3266  cd ..
 3267  ls
 3268  cd C3D-v1.1/
 3269  make -j8 all
 3270  make clean
 3271  make -j8 all
 3272  ls
 3273  cd ../scripts/
 3274  source set_env.sh ../C3D-v1.1/
 3275  python
 3276  cd -
 3277  vim Makefile
 3278  vim Makefile.config
 3279  ls
 3280  cd python/
 3281  python
 3282  make pycaffe
 3283  cd ..
 3284  make pycaffe
 3285  cd -
 3286  cd ..
 3287  cd ../scripts/
 3288  source set_env.sh ../C3D-v1.1/
 3289  python
 3290  clea
 3291  clear
 3292  python utils/scavenger.py 
 3293  nvidia-smi
 3294  top
 3295  nvidia-smi
 3296  clear
 3297  export CUDA_VISIBLE_DEVICES=5
 3298  export CUDA_VISIBLE_DEVICES=6
 3299  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 3300  source set_env.sh ../video-caffe/
 3301  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 3302  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' stack=8
 3303  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 3304  clear
 3305  top
 3306  nvidia-smi
 3307  cd~
 3308  cd ~
 3309  cd ~/pwd/saliency_on_videoset/Train/
 3310  cd caffe-master/
 3311  ls
 3312  cd src/caffe/layers/
 3313  ls
 3314  pwd
 3315  ls
 3316  top
 3317  cd pwd/saliency_on_videoset/
 3318  ls
 3319  top
 3320  nvidia-smi
 3321  top
 3322  nvidia-smi
 3323  ls
 3324  cd pwd/
 3325  ls
 3326  git clone 
 3327  git clone https://github.com/swook/autocrop.git
 3328  ls
 3329  cd autocrop/
 3330  ls
 3331  make
 3332  mkdir build
 3333  cd build/
 3334  cmake ..
 3335  cd ..
 3336  l
 3337  ls
 3338  make clean
 3339  cd ~/pwd/saliency_on_videoset/
 3340  ls
 3341  cd Train/
 3342  ls
 3343  clear
 3344  ls
 3345  cd scripts/
 3346  source set_env.sh ../caffe-flownet 4
 3347  nvidia-smi
 3348  source set_env.sh ../caffe-flownet 4
 3349  clear
 3350  python test_video.py --output_type="video" --test_base='videoset' --model_code='v3' --infertype='slide' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_50000.caffemodel'
 3351  python test_video.py --output_type="video" --test_base='videoset' --model_code='v3' --infertype='slide' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_50000.caffemodel' --videolength=16
 3352  nvidia-smi
 3353  clear
 3354  cd ..
 3355  ls
 3356  cd C3D/
 3357  ls
 3358  cd C3D-v1.0/
 3359  ls
 3360  cp Makefile.config.example Makefile.config
 3361  vim Makefile.config
 3362  make -j8 all
 3363  make pycaffe
 3364  ls
 3365  cd python/
 3366  ls
 3367  python
 3368  cd ..
 3369  make pycaffe
 3370  export CPLUS_INCLUDE_PATH=/usr/include/python2.7
 3371  make pycaffe
 3372  python
 3373  cd python/
 3374  import caffe
 3375  python
 3376  cd ..
 3377  cd..
 3378  cd ..
 3379  cp C3D-v1.0/ ../
 3380  cp -R C3D-v1.0/ ../
 3381  cd ..
 3382  ls -l
 3383  ls -ls
 3384  cd scripts/
 3385  source set_env.sh ../C3D-v1.0/
 3386  nvidia-smi
 3387  source set_env.sh ../C3D-v1.0/ 4
 3388  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3389  python
 3390  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu' --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 
 3391  cd ..
 3392  git clone https://github.com/AustinVan/IC.git
 3393  cd IC/
 3394  la
 3395  python
 3396  cd python/
 3397  python
 3398  cd ..
 3399  vim Makefile.config
 3400  make clean
 3401  make -j8 all
 3402  cd ..
 3403   rm -rf IC/ 
 3404  clear
 3405  ls
 3406  cd C3D-v1.1/
 3407  ls
 3408  cd python/
 3409  python
 3410  cd ..
 3411  make pycaffe
 3412  make clean
 3413  make -j16 all && make -j8 pycaffe
 3414  cd ..
 3415  rm -rf C3D-v1.0/ C3D-v1.1/
 3416  ls
 3417  cp C3D/C3D-v1.1/ ./
 3418  cp -R C3D/C3D-v1.1/ ./
 3419  cd C3D-v1.1/
 3420  ls
 3421  cd python/
 3422  python
 3423  cd ..
 3424  make clean
 3425  cp Makefile.config.example Makefile.config
 3426  vim Makefile.config
 3427  make -j8 all && make pycaffe
 3428  cd python/
 3429  python
 3430  clear
 3431  cd ..
 3432  cd scripts/
 3433  source set_env.sh ../C3D-v1.1/
 3434  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3435  source set_env.sh ../C3D-v1.1/ 4
 3436  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3437  cd ..
 3438  cd C3D-v1.1/
 3439  ls
 3440  make clean
 3441  make all && make pycaffe
 3442  make clean
 3443  make all && make pycaffe
 3444  cd -
 3445  cd scripts/
 3446  ls
 3447  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3448  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --trainingbase='msu'
 3449  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3450  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu'
 3451  cd pwd/saliency_on_videoset/
 3452  ls
 3453  cd Train/scripts/
 3454  history > history
 3455  source set_env.sh ../caffe-flownet/
 3456  pwd
 3457  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/
 3458  export CUDA_VISIBLE_DEVICES=6
 3459  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/
 3460  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/'
 3461  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='bigunion'
 3462  cd pwd/autocrop/
 3463  cd src/
 3464  mkdir build
 3465  cd build/
 3466  cmake ..
 3467  ls
 3468  cd ..
 3469  cd build/
 3470  ls
 3471  make install
 3472  make
 3473  make clean
 3474  cd ..
 3475  ls
 3476  rm -rf build/
 3477  cd ..
 3478  ls
 3479  rm -rf build/
 3480  cd ..
 3481  tar -czf autocrop/ autocrop.tar.gz
 3482  tar -czf autocrop.tar.gz autocrop/
 3483  top
 3484  nvidia-smi
 3485  clear
 3486  nvidia-smi
 3487  watch -n 2 nvidia-smi
 3488  top
 3489  nvidia-smi
 3490  cd saliency_on_videoset/Train/scripts/
 3491  source set_env.sh ../C3D-v1.1/ 4
 3492  nvidia-smi
 3493  source set_env.sh ../C3D-v1.1/ 6
 3494  clear
 3495  history > history 
 3496  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1/examples/c3d_ucf101_finetuning
 3497  bash testing_ucf101.sh 
 3498  clear
 3499  cd -
 3500  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3501  nvidi-asmi
 3502  nvidia-smi
 3503  top
 3504  cd pwd/saliency_on_videoset/Train/scripts/
 3505  ls
 3506  source set_env.sh ../C3D-v1.1/ 6
 3507  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3508  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=16
 3509  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3510  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=16
 3511  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3512  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-noscale.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3513  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3514  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3515  python utils/scavenger.py 
 3516  clear
 3517  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3518  clear
 3519  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3520  clear
 3521  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3522  clear
 3523  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3524  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8
 3525  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3526  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8
 3527  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --overlap=15 --trainingexampleprops=0.8 --validiter=1800 --savemodeliter=1800
 3528  nvidia-smi
 3529  nvidia-smi
 3530  clear
 3531  top
 3532  nvidia-smi
 3533  clear
 3534  cd pwd/saliency_on_videoset/Train/scripts/
 3535  source set_env.sh ../C3D-v1.1-kldloss/ 7
 3536   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15
 3537   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15
 3538   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=0
 3539   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15
 3540   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=0
 3541   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.995 --overlap=0
 3542   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.99 --overlap=0
 3543  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.99 --overlap=0 --debug=1
 3544  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15
 3545  clear
 3546  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 
 3547  clear
 3548  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 
 3549  clear
 3550  clera
 3551  clear
 3552  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.99 --overlap=0 --debug=1
 3553  clear
 3554  clera
 3555  clear
 3556  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 --extramodinfo='abs'
 3557  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --overlap=15 --trainingexampleprops=0.8 --validiter=1800
 3558  nvidia-smi
 3559  cd pwd/saliency_on_videoset/Train/scripts/
 3560  source set_env.sh ../C3D-v1.1-kldloss/ 5
 3561  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 --extramodinfo='relu'
 3562  clear
 3563  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 --extramodinfo='relu'
 3564  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --overlap=15 --trainingexampleprops=0.8 --validiter=1800
 3565  clear
 3566  cd pwd/saliency_on_videoset/Train/scripts/
 3567  git status
 3568  git add --all
 3569  git commit -m "add v3-2 model(multiple input, one output), add v4-2 model(not finished for the caffe problem)
 3570  "
 3571  git push -u origin master
 3572  nvidia-smi
 3573  python training_video_framestack_based.py --train_prototxtrototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_150958ion=2 --keyframeinterv=9
 3574  source set_env.sh ../caffe-flownet/
 3575  vim set_env.sh 
 3576  source set_env.sh ../caffe-flownet/ 7
 3577  source set_env.sh ../caffe-flownet/ 5
 3578  python training_video_framestack_based.py --train_prototxtrototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_150958ion=2 --keyframeinterv=16 -overlap=15
 3579  python training_video_framestack_based.py --train_prototxtrototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_150958ion=2 --keyframeinterv=16 --overlap=15
 3580  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_150958ion=2 --keyframeinterv=16 --overlap=15
 3581  clear
 3582   python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --version=2 --keyframeinterv=16 --overlap=15
 3583  nvidia-smi
 3584  git status
 3585  git add --all
 3586  git commit -m "Modify v4-2 to v4-2-fixweight+dropout, fix the weight of feature extractor, add dropout layer"
 3587  git push -u origin master
 3588  top
 3589  nvidia-smi
 3590  source set_env.sh ../C3D-v1.1 2
 3591  nvdia-smi
 3592  nvidia-smi
 3593  top
 3594  nvidia-smi
 3595  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.0001-snapshot-999999-display-1-momentum-0.95--batch-8_1513596875/snapshot-21600.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3596  nvidia-smi
 3597  export CUDA_VISIBLE_DEVICES=1
 3598  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.0001-snapshot-999999-display-1-momentum-0.95--batch-8_1513596875/snapshot-21600.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3599  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.0001-snapshot-999999-display-1-momentum-0.95--batch-8_1513596875/snapshot-21600.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3600  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597332/snapshot-21000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3601  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.00001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597365/snapshot-21000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3602  clear
 3603  matlab -nodesktop
 3604  clear
 3605  cd pwd/saliency_on_videoset/Train/scripts/
 3606  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/density-cv2'
 3607  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/density-cv2' --fixationtype='image'
 3608  top
 3609  nvidia-smi
 3610  top
 3611  nvidia-smi
 3612  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3613  source set_env.sh ../C3D-v1.1 0
 3614  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3615  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3616  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/train_kldloss-leaky-batch-8_1513739634_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_150000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3617  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3618  clear
 3619  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3620  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-39000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3621  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-39000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3622  clear &&clear
 3623  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/train_kldloss-leaky-batch-8_1513739634_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_150000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3624  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-999999-display-1-ledovSet-batch-8_1513764025/snapshot-11250.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3625  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-999999-display-1-ledovSet-batch-8_1513764025/snapshot-11250.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3626  nvidia-smi
 3627  matlab -nodesktop
 3628  clear
 3629  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2500-display-1--batch-2_1513846105/snapshot-_iter_7500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3630  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2500-display-1--batch-2_1513846105/snapshot-_iter_7500.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3631  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-999999-display-1-ledovSet-batch-8_1513764025/snapshot-22500.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3632  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2500-display-1--batch-2_1513846105/snapshot-_iter_67500.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3633  top
 3634  nvidia-smi
 3635  clear
 3636  top
 3637  nvidia-smi
 3638  top
 3639  nvidia-smi
 3640  top
 3641  nvidia-smi
 3642  source set_env.sh ../C3D-v1.1 0
 3643  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3644  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=1
 3645  source set_env.sh ../C3D-v1.1 5
 3646  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=8
 3647  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3648  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3649  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8
 3650  clear
 3651  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8
 3652  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.9995
 3653  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.9995 --plot_iter=5 --validiter=5
 3654  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.9995 --plotiter=5 --validiter=5
 3655  df -h
 3656  nvidia-smi
 3657  cd pwd/saliency_on_videoset/
 3658  cd Train/metric
 3659  matlab -nodesktop
 3660  cd /data/sunnycia/SaliencyDataset/Video/LEDOV/mats
 3661  matlab
 3662  matlab -nodesktop
 3663  nvidia-smi
 3664  cd pwd/saliency_on_videoset/Train/scripts/
 3665  pwd
 3666  clear
 3667  source set_env.sh ../caffe-flownet/ 3
 3668  python test_video.py --output_type='image' --test_base='videoset' --model_code='v3' video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image'
 3669  python test_video.py --output_type='image' --test_base='videoset' --model_code='v3' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image'
 3670  python test_video.py --output_type='image' --test_base='videoset' --model_code='v3' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --videolength=16
 3671  top
 3672  nvidia-smi
 3673  git status
 3674  git add -all
 3675  git add --all
 3676  git commit -m "Modify Saliencynet.py, abstract class VideoSaliencyNet'
 3677  '
 3678  git commit -m "Modify Saliencynet.py, abstract class VideoSaliencyNet"
 3679  git push -u origin master
 3680  source set_env.sh ../C3D-v1.1/ 3
 3681  nvidia-smi
 3682  clear
 3683  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3684  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-6000.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3685  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3686  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-2000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3687  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-3000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3688  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-3000.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3689  top
 3690  nvidia-smi
 3691  history > history
 3692  python utils/scavenger.py 
 3693  vim utils/scavenger.py 
 3694  vim utils/scavenger.py  --snapshot=1
 3695  python utils/scavenger.py --snapshot=1
 3696  top
 3697  nvidia-smi
 3698  source set_env.sh ../C3D-v1.1 2
 3699  clear
 3700  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3701  cd /data/sunnycia/SaliencyDataset/Video/LEDOV/LEDOV/..
 3702  ls
 3703  python script_for_classify_data.py 
 3704  wpd
 3705  pwd
 3706  cd LEDOV/
 3707  touch generate_fixation.m
 3708  vim generate_fixation.m 
 3709  to
 3710  top
 3711  cd -
 3712  cd ~/pwd/saliency_on_videoset/Train/scripts/
 3713  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/density'
 3714  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/density' --fixationtype='image'
 3715  nvidia-smi
 3716  git statsu
 3717  git status
 3718  git push -u origin master
 3719  nvidia-smi
 3720  source set_env.sh ../caffe-flownet/ 1
 3721  python test_image.py --modelbase='' --testset='mit1003
 3722  python test_image.py --modelpath='../training_output/salicon/train_kldloss-leaky-batch-8_1513739634_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='mit1003'  && python test_image.py --modelpath='../training_output/salicon/train_kldloss-base_lr-0.0001-weight_decay-0.000005-momentum-0.95-batch-8_1513602632_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='mit1003'
 3723  clear
 3724  python test_image.py --modelpath='../training_output/salicon/train_kldloss-leaky-batch-8_1513739634_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='mit1003'  && python test_image.py --modelpath='../training_output/salicon/train_kldloss-base_lr-0.0001-weight_decay-0.000005-momentum-0.95-batch-8_1513602632_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='mit1003'
 3725  git status
 3726  python metric/avg_metric.py --metricdir='../metric-matlab'
 3727  nvidia-smi
 3728  git status
 3729  git add --all
 3730  git commit -m "Done for v4-2-resnet model arch and v4-2-resnet-catfeat model arch."
 3731  git push -u origin master
 3732  clear
 3733  to
 3734  top
 3735  nvidia-smi
 3736  clear
 3737  cd pwd/saliency_on_videoset/Train/scripts/
 3738  git status
 3739  git add --all
 3740  git commit -m "Done for v4-2 model, use dconv3d to restruct saliency map"
 3741  git push -u origin master
 3742  source set_env.sh ../caffe-flownet/ 3
 3743  python test_video.py --output_type='video' --test_base='videoset' --model_code='v3' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' 
 3744  python test_video.py --output_type='video' --test_base='videoset' --model_code='v3' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' --videolength=16
 3745  python metric/avg_metric.py /data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/
 3746  python metric/avg_metric.py --metricdia='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/'
 3747  python metric/avg_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/'
 3748  python metric/avg_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset'
 3749  python metric/avg_metric.py --metricdir='metric-matlab'
 3750  python metric/avg_metric.py --metricdir='../metric-matlab'
 3751  clear
 3752  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deplot.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' 
 3753  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deplot.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset'
 3754  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deplot.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2'
 3755  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2'
 3756  source set_env.sh ../C3D-v1.1/ 3
 3757  nvidia-smi
 3758  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2'
 3759  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3760  top
 3761  nvidia-smi
 3762  top
 3763  nvidia-smi
 3764  top
 3765  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='msu' --model_code='v4-2' --videolength=16
 3766  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-1500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3767   git status
 3768  git add --all
 3769  git commit -m "add validation plot function. "
 3770  git push -u origin master
 3771  cd ../C3D-v1.1-kldloss/
 3772  make clean
 3773  make -j16 all 
 3774  make -j4 pycaffe
 3775  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-9000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3776  cd ../scripts/
 3777  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-9000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3778  source set_env.sh ../C3D-v1.1 3
 3779  nvidia-smi
 3780  source set_env.sh ../C3D-v1.1 2
 3781  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-9000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3782  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy-fixweight+dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-9000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3783  clear
 3784  source set_env.sh ../C3D-v1.1 3
 3785  nvidia-smi
 3786  nvidia-smi 2
 3787  source set_env.sh ../C3D-v1.1 2
 3788  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-21600.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3789  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416541/snapshot-0.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3790  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-stepsize-500-lr_policy-step-base_lr-0.01-snapshot-20000-display-1-batch-8_1513221679/snapshot-31500.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3791  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-stepsize-500-lr_policy-step-base_lr-0.01-snapshot-20000-display-1-batch-8_1513221679/snapshot-31500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3792  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597332/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3793  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.0001-snapshot-999999-display-1-momentum-0.95--batch-8_1513596875/snapshot-5400.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3794  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.00001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597365/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3795  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.00001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597365/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3796  clear
 3797  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.00001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597365/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3798  clear
 3799  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3800  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.9
 3801  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3802  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3803  top
 3804  nvidia-smi
 3805  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75 
 3806  python utils/VorI/slice_frame.py
 3807  python utils/VorI/slice_frames.py 
 3808  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/LEDOV/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/LEDOV/frames' 
 3809  cd /data/sunnycia/SaliencyDataset/Video/LEDOV
 3810  rm -rf fixation/
 3811  rm -rf frames/
 3812  cd -
 3813  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/LEDOV/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/LEDOV/frames' 
 3814  clear
 3815  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/LEDOV/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/LEDOV/frames' 
 3816  top
 3817  nvidia-smi
 3818  df -h
 3819  top
 3820  ssh root@172.31.70.212
 3821  ssh wangxu@172.31.70.212
 3822  ssh root@172.31.234.205
 3823  cd pwd/saliency_on_videoset/Train/scripts/
 3824  source set_env.sh ../C3D-v1.1 0
 3825  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=10 --validiter=10 --snapshotincode=False
 3826  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=10 --validiter=10 
 3827  clear
 3828  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=2500 --validiter=2500
 3829  nvidia-smi
 3830  top
 3831  nvidia-smi
 3832  clear
 3833  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=2500 --validiter=2500
 3834  clear
 3835  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=2500 --validiter=2500
 3836  ls
 3837  nvidia-smi
 3838  top
 3839  nvidia-smi
 3840  top
 3841  cd pwd/saliency_on_videoset/Train/scripts/
 3842  git status
 3843  git add --all
 3844  git commit -m "Training baseline with leaky relu"
 3845  clear
 3846  source set_env.sh ../C3D-v1.1 7
 3847  nvidia-smi
 3848  top
 3849  nvidia-smi
 3850  source set_env.sh ../C3D-v1.1 1
 3851  python training_video_voxel_based.py --train_prototxt='prototxt/voo-v4-2-resnet.prototxt'--use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu
 3852  '
 3853  python training_video_voxel_based.py --train_prototxt='prototxt/voo-v4-2-resnet.prototxt'--use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3854  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt'--use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3855  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3856  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=8 --debug=1
 3857  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --debug=1
 3858  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 
 3859  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.99995
 3860  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9999
 3861  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9995
 3862  clear
 3863  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9995
 3864  clear
 3865  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9995 --trainingbase='ledov'
 3866  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9999 --trainingbase='ledov'
 3867  nvidia-smi
 3868  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9999 --trainingbase='ledov'
 3869  nvidia-smi
 3870  clear
 3871  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9995 --trainingbase='ledov' --savemodeliter=2500 --validiter=2500
 3872  clear
 3873  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --batch=2 --trainingexampleprops=0.9995 --trainingbase='ledov' --savemodeliter=2500 --validiter=2500
 3874  clear
 3875  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --batch=2 --trainingexampleprops=0.9995 --trainingbase='ledov' --savemodeliter=2500 --validiter=2500
 3876  cd pwd/saliency_on_videoset/Train/
 3877  ls
 3878  nvidia-smi
 3879  top
 3880  clear
 3881  cd caffe
 3882  make -j8 all 
 3883  clear
 3884  top
 3885  nvidia-smi
 3886  clear
 3887  cd ~/pwd/saliency_on_videoset/Train/scripts/
 3888  source set_env.sh ../caffe-flownet/
 3889  nvidia-smi
 3890  export CUDA_VISIBLE_DEVICES=7
 3891  clear
 3892  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --version=2 --keyframeinterv=9 
 3893  clear
 3894  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --version=2 --keyframeinterv=9 
 3895  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --version=2 --keyframeinterv=16 --overlap=15 
 3896  top
 3897  nvidia-smi
 3898  git status
 3899  git add --all
 3900  git commit -m "Done for v4-3-1 model, use kldloss, C3D-v1.1-kldloss, output 1 saliency map, add abs layer to avoid nan loss value"
 3901  git push -u origin master
 3902  top
 3903  nvidia-smi
 3904  clear
 3905  nvidia-smi
 3906  cd ../caffe-master/
 3907  mv src/caffe/ include/
 3908  mv src/caffe/voxel_wise_softmax_loss_layer.hpp include/
 3909  cd include/
 3910  ls
 3911  cd ..
 3912  make -j8 all
 3913  clear
 3914  make clean
 3915  make -j8 all
 3916  make clean
 3917  make -j8 all
 3918  make clean
 3919  make -j8 all
 3920  clear
 3921  nvidia-smi
 3922  top
 3923  nvidia-smi
 3924  clear
 3925  top
 3926  nvidia-smi
 3927  top
 3928  nvidia-smi
 3929  top
 3930  nvidia-smi
 3931  top
 3932  nvidia-smi
 3933  cd ~
 3934  cd pwd/saliency_on_videoset/_Train/
 3935  ls
 3936  git clone https://github.com/cagdasbak/dynamicsaliency.git
 3937  nvidia-smi
 3938  vim ~/.bashrc
 3939  python
 3940  nvidia-smi
 3941  top
 3942  nvidia-smi
 3943  git status
 3944  cd pwd/saliency_on_videoset/Train/scripts/
 3945  git status
 3946  nvidia-smi
 3947  source set_env.sh ../C3D-v1.1 2
 3948  clear
 3949  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='ledov' --extrainfo='ledovSet'
 3950  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='ledov' --extramodinfo='ledovSet'
 3951  source set_env.sh ../C3D-v1.1-kldloss/ 2
 3952  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='ledov' --extramodinfo='ledovSet'
 3953  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet'
 3954  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='1.0'
 3955  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='1.0' --batch=8
 3956  clear
 3957  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='1.0' --batch=8
 3958  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8
 3959  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.9999' --batch=8
 3960  clear
 3961  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.9999' --batch=8
 3962  cd /data/sunnycia/SaliencyDataset/Video/LEDOV
 3963  python rename.py 
 3964  cd -
 3965  clear
 3966  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8
 3967  clear
 3968  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8
 3969  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8 --validiter=2250 --savemodeliter=2250 
 3970  claer
 3971  clear
 3972  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8 --validiter=2250 --savemodeliter=2250 
 3973  top
 3974  nvidia-smi
 3975  watch -n 0.5 nvidia-smi
 3976  top
 3977  nvidia-smi
 3978  top
 3979  nvidia-smi
 3980  clear
 3981  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3982  cd pwd/saliency_on_videoset/Train/scripts/
 3983  source set_env.sh ../C3D-v1.1/ 3
 3984  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8
 3985  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt'
 3986  clear
 3987  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt'
 3988  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2
 3989  clear
 3990  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2
 3991  clear
 3992  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2
 3993  clear
 3994  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2
 3995  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.99
 3996  clear
 3997  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.99
 3998  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 3999  clear
 4000  ls
 4001  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4002  clear
 4003  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4004  clear
 4005  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4006  clear
 4007  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4008  clear
 4009  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4010  clear
 4011  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4012  clear
 4013  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.8 
 4014  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995
 4015  clear
 4016  clera
 4017  clear
 4018  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.995 --validiter=5 --plotiter=10 --overlap=12
 4019  clear
 4020  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=12
 4021  clear
 4022  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=12
 4023  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.998 --overlap=12
 4024  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.998 --overlap=12 --validiter=4 --plotiter=7
 4025  clear
 4026  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=12
 4027  clear
 4028  source set_env.sh ../caffe-flownet/ 3
 4029  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --usesnapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstte' --batch=8 --dsname='salicon'
 4030  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --usesnapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4031  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4032  clear
 4033  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4034  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4035  clear
 4036  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4037  source set_env.sh ../caffe-master/ 3
 4038  nvidia-smi
 4039  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4040  source set_env.sh ../caffe-flownet/ 3
 4041  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4042  clear
 4043  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4044  python utils/scavenger.py 
 4045  python utils/scavenger.py --snapshot
 4046  python utils/scavenger.py --snapshot=1
 4047  clear
 4048  -------test-leaky-relu performance-improvement-----------
 4049  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4050  watch -n 5 nvidia-smi
 4051  watch -n 1 nvidia-smi
 4052  nvidia-smi
 4053  cd pwd/saliency_on_videoset/Train/scripts/
 4054  watch -n -0.5 nvidia-smi
 4055  source set_env.sh ../C3D-v1.1/ 4
 4056  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 4057  python training_video_voxel_based.py --solver_prototxt='prototxt/solver-static.prototxt' --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --staticsolver=1
 4058  clear
 4059  python training_video_voxel_based.py --solver_prototxt='prototxt/solver-static.prototxt' --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --staticsolver=1
 4060  python training_video_voxel_based.py --solver_prototxt='prototxt/solver-static.prototxt' --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --staticsolver=1 --batch=8
 4061  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-fixweight+dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800
 4062  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-fixweight+dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.99 --overlap=0 --validiter=1800 --savemodeliter=1800
 4063  clear
 4064  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-fixweight+dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800
 4065  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='msu'
 4066  source set_env.sh ../caffe-flownet/ 4
 4067  clear
 4068  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='msu'
 4069  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4070  clear
 4071  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4072  top
 4073  nvidia-smi
 4074  cd pwd/saliency_on_videoset/Train/scripts/
 4075  source set_env.sh ../C3D-v1.1 4
 4076  python utils/scavenger.py 
 4077  python utils/scavenger.py --snapshot
 4078  python utils/scavenger.py --snapshot=1
 4079  top
 4080  nvidia-smi
 4081  cd pwd/saliency_on_videoset/Train/scripts/
 4082  ls
 4083  source set_env.sh ../C3D-v1.1 7
 4084  history > history
 4085  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2500 --savemodeliter=2500 --trainingexampleprops=0.95 
 4086  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.95 --plotiter=50
 4087  clear
 4088  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4089  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='fulldens'
 4090  clear && clear
 4091  nvidia-smi
 4092  cd pwd/saliency_on_videoset/Train/scripts/
 4093  source set_env.sh ../C3D-v1.1 6
 4094  clear
 4095  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4096  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4097  clear
 4098  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4099  clear
 4100  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4101  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='fulldens'
 4102  nvidia-smi
 4103  clear
 4104  cd pwd/saliency_on_videoset/Train/scripts/metric/
 4105  ls
 4106  matlab -nodesktop
 4107  clear && clear
 4108  cd ..
 4109  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/snapshot-_iter_28000.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 4110  source set_env.sh ../C3D-v1.1 5
 4111  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/snapshot-_iter_28000.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 4112  nvidia-smi
 4113  top
 4114  python utils/VorI/slice_frames.py 
 4115  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/DIEM/video'
 4116  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/DIEM/video' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames'
 4117  matlab -nodesktop
 4118  top
 4119  nvidia-smi
 4120  top
 4121  nvidia-smi
 4122  top
 4123  nvidia-smi
 4124  top
 4125  locate ChairsSDHom.tar.gz
 4126  rlocate
 4127  op
 4128  top
 4129  nvidia-smi
 4130  clear
 4131  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205/snapshot-_iter_474000.caffemodel' --infertype='slide'
 4132  top
 4133  nvidia-smi
 4134  top
 4135  cd pwd/saliency_on_videoset/Train/scripts/
 4136  source set_env.sh ../C3D-v1.1 5
 4137  nvidia-si
 4138  nvidia-smi
 4139  clear
 4140  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset' && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_72000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset'
 4141  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_72000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset'
 4142  cd utils/
 4143  ls
 4144  touch gen_lmdb.py
 4145  vim gen_lmdb.py 
 4146  cd ..
 4147  top
 4148  nvidia-smi
 4149  clear
 4150  source set_env.sh ../C3D-v1.1 4
 4151  nvidia-smi
 4152  clear
 4153  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/snapshot-_iter_28000.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 4154  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/snapshot-_iter_28000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 4155  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/snapshot-_iter_96000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 4156  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/snapshot-_iter_96000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 4157  matlab -nodesktop
 4158  clear
 4159  source set_env.sh ../C3D-v1.1 6
 4160  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1-fulldens-batch-2_1514129183/snapshot-_iter_468000.caffemodel' --infertype='slide'
 4161  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1-fulldens-batch-2_1514129183/snapshot-_iter_468000.caffemodel' --infertype='slide'
 4162  clear
 4163  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1-fulldens-batch-2_1514129183/snapshot-_iter_468000.caffemodel' --infertype='slide'
 4164  clear
 4165  cd pwd/saliency_on_videoset/Train/scripts/
 4166  source set_env.sh ../C3D-v1.1 5
 4167  nvidia-smi
 4168  source set_env.sh ../C3D-v1.1 4
 4169  clear
 4170  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='' --infertype='slide' ----test_base='videoset' --model_code='v4-2' --videolength=16 
 4171  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_48000.caffemodel' --infertype='slide' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4172  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_48000.caffemodel' --infertype='slide' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4173  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4174  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4175  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4176  clear
 4177  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4178  clear
 4179  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_14000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4180  clear
 4181  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4182  clear
 4183  vim utils/scavenger.py 
 4184  python utils/scavenger.py 
 4185  vim utils/scavenger.py 
 4186  python utils/scavenger.py 
 4187  nvidia-smi
 4188  source set_env.sh ../C3D-v1.1 4
 4189  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videoength=16 infertype='slide' 
 4190  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videoength=16 infertype='slide' --test_base='videoset'
 4191  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videoength=16 --infertype='slide' --test_base='videoset'
 4192  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset'
 4193  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset' 
 4194  top
 4195  clear && clear
 4196  top
 4197  nvidia-smi
 4198  top
 4199  nvidia-smi
 4200  clear
 4201  git status
 4202  git add --all
 4203  git commit -m "Done for training v4-2 v4-2-resnet and v4-2-resnet-catfeat, add v4-2-softmax"
 4204  git push -u origin master
 4205  clear
 4206  nvidia-smi
 4207  clear
 4208  top
 4209  nvidia-smi
 4210  clear && clear
 4211  git status
 4212  git add --all
 4213  git commit -m "Tried v4-2-sigmoid, not good. Add generate lmdb util"
 4214  git push -u origin master
 4215  cd /data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000
 4216  python
 4217  nvidia-smi
 4218  cd ~
 4219  cd /data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205
 4220  python
 4221  top
 4222  nvidia-smi
 4223  top
 4224  nvidia-smi
 4225  top
 4226  nvidia-smi
 4227  python
 4228  top
 4229  clear && clear
 4230  cd ..
 4231  cd ../scripts/
 4232  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-catfeat-snapshot-2000-display-1-fulldens-batch-2_1514129183/plot_dict.pkl'
 4233  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205/plot_dict.pkl'
 4234  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/plot_dict.pkl'
 4235  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/plot_dict.pkl'
 4236  clear
 4237  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000'
 4238  top
 4239  nvidia-smi
 4240  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000'
 4241  clear && clear
 4242  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000'
 4243  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=0
 4244  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=0 --examples=20
 4245  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=2 --examples=10
 4246  git status
 4247  git add --all
 4248  git commit -m "add utils: visualize plotdict & find best and worst performance of a metric"
 4249  git push -u origin master
 4250  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=2 --examples=10
 4251  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=3 --examples=10
 4252  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=3 --examples=3
 4253  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=0 --examples=3
 4254  touch metric/findBW.sh
 4255  vim metric/findBW.sh 
 4256  bash metric/findBW.sh 
 4257  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/plot_dict.pkl'
 4258  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/plot_dict.pkl'
 4259  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205/plot_dict.pkl'
 4260  df -h
 4261  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/plot_dict.pkl'
 4262  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205/plot_dict.pkl'
 4263  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/plot_dict.pkl'
 4264  python ss_test_video.py 
 4265  python
 4266  python ss_test_video.py 
 4267  python
 4268  python ss_test_video.py 
 4269  clear
 4270  python ss_test_video.py 
 4271  top
 4272  python ss_test_video.py 
 4273  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/snapshot-_iter_454000.caffemodel' --infertype='slide' 
 4274  matlab -nodesktop
 4275  cd pwd/saliency_on_videoset/Train/scripts/
 4276  source set_env.sh ../C3D-v1.1-kldloss/ 4
 4277  nvidia-smi
 4278  cler
 4279  clear
 4280  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4281  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.99995 --plotiter=50
 4282  clear
 4283  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.99995 --plotiter=50
 4284  clear
 4285  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4286  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.99995 --plotiter=50
 4287  clear
 4288  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.99995 --plotiter=50
 4289  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4290  clear
 4291  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4292  cd   /data/sunnycia/SaliencyDataset/Video/LEDOV
 4293  python check_density.py 
 4294  clear
 4295  clearw
 4296  clear
 4297  cd -
 4298  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4299  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmax.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4300  clear
 4301  python utils/scavenger.py 
 4302  python utils/scavenger.py --snapshot=1
 4303  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmax.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4304  python utils/scavenger.py 
 4305  python utils/scavenger.py --snapshot=1
 4306  clear
 4307  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmax.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4308  clear
 4309  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-sigmoid.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4310  clear
 4311  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --usesnapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4312  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_snapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4313  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_snapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4314  clear
 4315  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_snapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4316  clear
 4317  claer
 4318  clear
 4319  python utils/scavenger.py 
 4320  clear
 4321  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_snapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4322  clear
 4323  matlab -nodesktop
 4324  cd /data/sunnycia/SaliencyDataset/Video/Hollywood2
 4325  ls
 4326  tar xf Hollywood2-actions.tar.gz 
 4327  tar xf Hollywood2-scenes.tar.gz
 4328  cd ../Coutort1/
 4329  unzip ERB3_Stimuli.zip 
 4330  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
 4331  cd ..
 4332  python metric/metric_distribution.py --metricdir='' --outputdir='' --metricname='cc'
 4333  python metric/metric_distribution.py --metricdir='../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0' --outputdir='../metric_distribution' --metricname='cc'
 4334  python metric/metric_distribution.py --metricdir='../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0' --outputdir='../metric_distribution' --metricname='sauc'
 4335  python metric/metric_distribution.py --metricdir='../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0' --outputdir='../metric_distribution' --metricname='auc_jud'
 4336  top
 4337  nvidia-smi
 4338  python metric/metric_distribution.py --metricdir='../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0' --outputdir='../metric_distribution' --metricname='auc_jud'
 4339  bash metric/metric_distribution.sh vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0
 4340  vim metric/metric_distribution.sh 
 4341  bash metric/metric_distribution.sh vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0
 4342  vim metric/metric_distribution.sh 
 4343  bash metric/metric_distribution.sh vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0
 4344  bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0
 4345  bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_96000_threshold0
 4346  bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167_snapshot-_iter_28000_threshold0 && bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167 &&  bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491_snapshot-_iter_72000_threshold0 && bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-snapshot-999999-display-1-ledovSet-batch-8_1513764025_snapshot-11250_threshold0
 4347  nvidia-smi
 4348  top
 4349  python ss_test_video.py
 4350  source set_env.sh ../C3D-v1.1-kldloss/ 6
 4351  nvidia-smi
 4352  python ss_test_video.py
 4353  clear
 4354  python ss_test_video.py
 4355  df -h
 4356  cd /data/sunnycia/SaliencyDataset/Video
 4357  cd GAZECOM/
 4358  ls
 4359  unzip movies-m2t.zip 
 4360  mkdir movies && mv *m2t movies
 4361  mkdir gaze && cd gaze && unzip ../gaze.zip
 4362  mkdir images && cd images && unzip ../static-images.zip 
 4363  cd ..
 4364  cd /data/sunnycia/SaliencyDataset/Video/GAZECOM
 4365  mkdir images && cd images && unzip ../static-images.zip 
 4366  top
 4367  nvidia-smi
 4368  top
 4369  nvidia-smi
 4370  top
 4371  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4372  nvidia-smi
 4373  source set_env.sh ../C3D-v1.1 0
 4374  python ss_test_video.py 
 4375  top
 4376  nvidia-smi
 4377  top
 4378  nvidia-smi
 4379  top
 4380  nvidi-asmi
 4381  cd pwd/saliency_on_videoset/Train/scripts
 4382  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/DIEM/fixation_map/image' --density_base='/data/sunnycia/SaliencyDataset/Video/DIEM/density/image' --fixationtype='image'
 4383  cd pwd/saliency_on_videoset/_Train/
 4384  ls
 4385  git clone https://github.com/ZhaofanQiu/pseudo-3d-residual-networks.git
 4386  cd ../Train/scripts/
 4387  ls
 4388  cd ..
 4389  ls
 4390  cp /data/sunnycia/saliency_on_videoset/_Train/pseudo-3d-residual-networks/caffe_add_layers/src/*.cpp caffe-master/src/caffe/layers/
 4391  cp /data/sunnycia/saliency_on_videoset/_Train/pseudo-3d-residual-networks/caffe_add_layers/src/*.cu caffe-master/src/caffe/layers/
 4392  cp /data/sunnycia/saliency_on_videoset/_Train/pseudo-3d-residual-networks/caffe_add_layers/include/*.hpp caffe-master/include/caffe/layers/
 4393  cd caffe-master/
 4394  ls
 4395  make clean
 4396  cp /data/sunnycia/saliency_on_videoset/_Train/pseudo-3d-residual-networks/caffe_add_layers/caffe.proto src/caffe/proto/
 4397  make clean && make -j8 all && make pycaffe
 4398  make clean
 4399  make clean && make -j2 all && make pycaffe
 4400  make clean && make -j8 all && make pycaffe
 4401  vim Makefile.config
 4402  make clean && make -j8 all && make pycaffe
 4403  make -j8 pycaffe
 4404  make clean && make -j8 all && make -j8 pycaffe
 4405  cd ..
 4406  rm -rf caffe-master/
 4407  git clone https://github.com/BVLC/caffe.git
 4408  ls
 4409  cd caffe
 4410  make -j8 all
 4411  make clean
 4412  cd ..
 4413  rm -rf caffe
 4414  git clone https://github.com/BVLC/caffe.git
 4415  ls
 4416  unzip caffe-master.zip 
 4417  cd caffe-master/
 4418  cp Makefile.config.example Makefile.config
 4419  vim Makefile.config
 4420  make -j8 pycaffe
 4421  make -j8 all
 4422  vim Makefile.config
 4423  make -j8 all
 4424  make clean
 4425  make -j8 all
 4426  make -j8 pycaffe
 4427  clear
 4428  make clean
 4429  make -j16 all
 4430  make clean
 4431  make -j2 all && make -j2 pycaffe
 4432  make clean
 4433  make -j4 all && make -j4 pycaffe
 4434  top
 4435  nvidia-smi
 4436  top
 4437  ls
 4438  clear
 4439  source set_env.sh ../C3D-v1.1 4
 4440  nvidia-smi
 4441  clear
 4442  top
 4443  nvidia-smi
 4444  clear
 4445  nvidia-smi
 4446  clear
 4447  top
 4448  nvidia-smi
 4449  clear
 4450  source set_env.sh ../C3D-v1.1 4
 4451  clear
 4452  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmaxloss.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=4 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4453  clear && clear
 4454  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmaxloss.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=4 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4455  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmaxloss.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4456  clear && clear
 4457  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmaxloss.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4458  clear
 4459  top
 4460  nvidia-smi
 4461  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4462  nvidia-smi
 4463  source set_env.sh ../C3D-v1.1 6
 4464  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4465  matlab -nodesktop
 4466  cd metric/
 4467  matlab -nodesktop -nodisplay -nosplash -r "run("metric_video_base.m")
 4468  matlab -nodesktop -nodisplay -nosplash -r "run("metric_video_base.m")"
 4469  matlab -nodesktop -nodisplay -nosplash -r "metric_video_base.m"
 4470  matlab -nodesktop -nodisplay -nosplash -r "run("metric_video_base")"
 4471  matlab -nodesktop -nodisplay -nosplash -r "metric_video_base;exit()"
 4472  matlab -nodesktop -nodisplay -nosplash -r "metric_statistics;exit()"
 4473  matlab -nodesktop -nodisplay -nosplash
 4474  cd pwd/saliency_on_videoset/Train/scripts
 4475  source set_env.sh ../C3D-v1.1 5
 4476  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4477  clear
 4478  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4479  clear
 4480  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4481  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='fulldens'
 4482  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxto' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4483  clear && clear
 4484  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxto' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4485  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4486  clear && clear
 4487  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4488  clear && clear
 4489  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4490  clear && clear
 4491  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4492  python test_video.py --output_type='image' --test_base='gazecom' --model_code'v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide' 
 4493  python test_video.py --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide' 
 4494  python test_video.py --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide' && python test_video.py --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_50000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide' && python test_video.py --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_100000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide'
 4495  nvidia-smi
 4496  top
 4497  nvidia-smi
 4498  top
 4499  nvidia-smi
 4500  top
 4501  cd pwd/saliency_on_videoset/Train/scripts/
 4502  python test_video.py --output_type='image' --test_base='diem' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --inferoverlap=15
 4503  source set_env.sh ../C3D-v1.1 7
 4504  nvidia-smi
 4505  source set_env.sh ../C3D-v1.1 4
 4506  python test_video.py --output_type='image' --test_base='diem' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --inferoverlap=15
 4507  clear && clear
 4508  python test_video.py --output_type='image' --test_base='diem' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --inferoverlap=15
 4509  cd /data/sunnycia/SaliencyDataset/Video/MSU/videos
 4510  mv *_right.avi ../right_videos/
 4511  cd ../saliency_map/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787_snapshot-_iter_26000_threshold0/
 4512  rm -rf *_right
 4513  cd ../..
 4514  python gen_fixation.py 
 4515  top
 4516  cd /data/sunnycia/saliency_on_videoset/_Model
 4517  clear
 4518  matlab -nodesktop -nodisplay -nosplash
 4519  nvidia-smi
 4520  cd pwd/saliency_on_videoset/Train/
 4521  cd scripts/
 4522  source set_env.sh ../C3D-v1.1 3
 4523  clear
 4524  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout01.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='01dropout_fulldens'
 4525  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --plotiter=200 --extramodinfo='lowbaselr_05dropout_fulldens'
 4526  top
 4527  nvidia-smi
 4528  top
 4529  nvidia-smi
 4530  cd pwd/saliency_on_videoset/Train/scripts/
 4531  cd metric/
 4532  matlab -nodesktop -nodisplay
 4533  cd ..
 4534  python ss_test_video.py 
 4535  source set_env.sh ../C3D-v1.1
 4536  source set_env.sh ../C3D-v1.1 6
 4537  python ss_test_video.py 
 4538  clear && clear
 4539  python ss_test_video.py 
 4540  clear && clear
 4541  python ss_test_video.py 
 4542  nvidia-smi
 4543  export CUDA_VISIBLE_DEVICES=6
 4544  python ss_test_video.py 
 4545  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_100000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16  
 4546  source set_env.sh ../C3D-v1.1 6
 4547  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_100000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16  
 4548  nvidia-smi
 4549  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='ledov' --model_code='v4-2' --videolength=16
 4550  cd pwd/saliency_on_videoset/Train/scripts/
 4551  source set_env.sh ../C3D-v1.1 0
 4552  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='ledov' --model_code='v4-2' --videolength=16
 4553  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='msu' --model_code='v4-2' --videolength=16
 4554  python ss_test_video.py 
 4555  clear && clear
 4556  python ss_test_video.py 
 4557  top
 4558  nvidia-smi
 4559  top
 4560  nvidia-smi
 4561  df -h
 4562  nvidia-smi
 4563  top
 4564  nvidia-smi
 4565  cd /data/sunnycia/SaliencyDataset/Video/GAZECOM
 4566  python gen_fixation.py 
 4567  clear && clear
 4568  cd -
 4569  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/fixations' --density_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/density' --fixationtype='image'
 4570  python utils/VorI/one2all.py --videodirbase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/fixations' --alldir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/All_in_one/fixations'
 4571  clear && clear
 4572  git status
 4573  git add --all
 4574  git commit -m "find best & worst batch script; metric_distribution script; small scale test script; add dropout prototxt;"
 4575  git push -u origin master
 4576  clear && clear
 4577  matlab -nodesktop -nosplash -nodisplay
 4578  cd pwd/saliency_on_videoset/Train/scripts/
 4579  source set_env.sh ../C3D-v1.1 7
 4580  python ss_test_video.py 
 4581  ssh qiudan@172.31.234.205
 4582  source set_env.sh ../C3D-v1.1 7
 4583  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 4584  top
 4585  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=8
 4586  cd pwd/saliency_on_videoset/Train/scripts/
 4587  clear
 4588  source set_env.sh ../C3D-v1.1 7
 4589  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=12
 4590  cd pwd/saliency_on_videoset/Train/scripts/
 4591  ls
 4592  top
 4593  clear
 4594  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=14
 4595  source set_env.sh ../C3D-v1.1 4
 4596  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=14
 4597  top
 4598  cd pwd/saliency_on_videoset/Train/scripts/
 4599  python utils/dsutil/fixmat2img.py --matdir='/data/sunnycia/SaliencyDataset/Video/MSU/fixation/mat_allinone' --imgdir='/data/sunnycia/SaliencyDataset/Video/MSU/fixation/image_allinone'
 4600  top
 4601  nvidia-smi
 4602  top
 4603  nvidia-smi
 4604  cd /data/sunnycia/SaliencyDataset/Video/SFU_etdb
 4605  matlab 
 4606  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4607  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/movies' --outputbase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/frames'
 4608  clear && clear
 4609  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/movies' --outputbase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/frames'
 4610  cd /data/sunnycia/SaliencyDataset/Video/GAZECOM
 4611  python gen_fixation.py 
 4612  clear
 4613  python gen_fixation.py 
 4614  clear && clear
 4615  python gen_fixation.py 
 4616  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4617  python utils/gen_density.py --sigma=32 --fixation_base='' --density_base='' --fixationtype='image'
 4618  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/fixations' --density_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/density' --fixationtype='image'
 4619  cd ../
 4620  cd ../_Train/
 4621  ls
 4622  cd OMCNN_2CLSTM/
 4623  ls
 4624  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/saliency_map/xu_lstm' --outputtype='image'
 4625  export CUDA_VISIBLE_DEVICES=6
 4626  nvidia-smi
 4627  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/saliency_map/xu_lstm' --outputtype='image'
 4628  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/MSU/saliency_map/xu_lstm' --outputtype='image'
 4629  top
 4630  nvidia-smi
 4631  top
 4632  nvidia-smi
 4633  pwd
 4634  cd ../../Train/scripts/
 4635  git status
 4636  git add --all
 4637  git commit -m "combine metric statistics function into metirc_video_base script"
 4638  git push -u origin master
 4639  top
 4640  nvidia-smi
 4641  top
 4642  nvidia-smi
 4643  python
 4644  source set_env.sh ../C3D-v1.1 6
 4645  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.00001-snapshot-4000-display-1-lowbaselr_05dropout_fulldens-batch-2_1515212244' --modeliter=20000
 4646  python utils/model_guardian.py --modeldir='' --modeliter=50000
 4647  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788' --modeliter=50000
 4648  clear && clear
 4649  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.00001-snapshot-4000-display-1-lowbaselr_05dropout_fulldens-batch-2_1515212244' --modeliter=20000
 4650  clear && clear
 4651  cd metric/
 4652  matlab -nodesktop -nodisplay
 4653  cd ..
 4654  top
 4655  nvidia-smi
 4656  clear && clear
 4657  python top
 4658  top
 4659  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-dropout.prototxt' --user_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexamplepropx=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4660  source set_env.sh ../C3D-v1.1 5
 4661  clear && claer
 4662  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-dropout.prototxt' --user_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexamplepropx=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4663  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexamplepropx=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4664  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4665  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4666  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4667  clear && clear
 4668  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4669  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4670  cd pwd/saliency_on_videoset/Train/scripts/
 4671  clear
 4672  source set_env.sh ../C3D-v1.1 6
 4673  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4674  top
 4675  nvidia-smi
 4676  cd pwd/saliency_on_videoset/Train/scripts/
 4677  source set_env.sh ../C3D-v1.1 7
 4678  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4679  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4680  clear && clear
 4681  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4682  cd pwd/saliency_on_videoset/Train/scripts/
 4683  nvidia-smi
 4684  source set_env.sh ../C3D-v1.1 6
 4685  history > history
 4686  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=8
 4687  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=8 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=12 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=14
 4688  top
 4689  nvidia-smi
 4690  top
 4691  nvidia-smi
 4692  git status
 4693  git add --all
 4694  git commit -m "add model_guradian"
 4695  git push -u origin master
 4696  top
 4697  df -h
 4698  cd metric/
 4699  matlab -nodesktop
 4700  clear && clear
 4701  matlab -nodesktop -nodisplay
 4702  top
 4703  cd pwd/saliency_on_videoset/Train/scripts/
 4704  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.00001-snapshot-4000-display-1--batch-2_1515225254' --modeliter=20000
 4705  nvidia-smi
 4706  source set_env.sh ../C3D-v1.1 4
 4707  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.00001-snapshot-4000-display-1--batch-2_1515225254' --modeliter=20000
 4708  cd pwd/saliency_on_videoset/Train/scripts/
 4709  ls
 4710  locate LSTMconv_prefinal_loss05_dp075_075MC100-200000.data-00000-of-00001
 4711  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 4712  nvidia-smi
 4713  top
 4714  export CUDA_VISIBLE_DEVICES=0
 4715  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/DIEM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map' --outputtype='image'
 4716  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/DIEM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/xu-lstm' --outputtype='image'
 4717  clear && clear
 4718  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/DIEM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/xu-lstm' --outputtype='image'
 4719  cd 
 4720  cd /data/sunnycia/SaliencyDataset/Video/MSU
 4721  python gen_fixation.py 
 4722  cd /data/sunnycia/saliency_on_videoset/Train/scripts/data/sunnycia/saliency_on_videoset/Train/scripts
 4723  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4724  python utils/dsutil/fixmat2img.py --matdir='/data/sunnycia/SaliencyDataset/Video/MSU/fixation/mat' --imgdir='/data/sunnycia/SaliencyDataset/Video/MSU/fixation/image_convert'
 4725  cd ..
 4726  cd ../_Model/
 4727  matlab -nodesktop -nodisplay
 4728  top
 4729  nvidia-smi
 4730  top
 4731  nvidia-smi
 4732  df -h
 4733  top
 4734  nvidia-smi
 4735  top
 4736  nvidia-smi
 4737  top
 4738  nvidia-smi
 4739  top
 4740  nvidia-smi
 4741  top
 4742  clear
 4743  matlab -nodesktop -nodisplay
 4744  cd /data/sunnycia/SaliencyDataset/Video/Coutort2
 4745  unzip ERB4_Stimuli.zip 
 4746  matlab -nodesktop -nodisplay
 4747  top
 4748  nvidia-smi
 4749  cd ../Coutort2
 4750  python generate_fixation.py 
 4751  ssh sunnycia@172.31.234.248
 4752  clear && clear
 4753  ls
 4754  cd pwd/saliency_on_videoset/Train/scripts/
 4755  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-display-1--batch-2_1515247477' --modeliter=20000
 4756  source set_env.sh ../C3D-v1.1 4
 4757  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-display-1--batch-2_1515247477' --modeliter=20000
 4758  nvidia-smi
 4759  top
 4760  nvidia-smi
 4761  top
 4762  nvidia-smi
 4763  df -h
 4764  top
 4765  nvidia-smi
 4766  clear
 4767  ssh qiudan@172.31.234.205
 4768  cd pwd/saliency_on_videoset/Train/scripts/
 4769  git status
 4770  python utils/scavenger.py 
 4771  python utils/scavenger.py --snapshot
 4772  python utils/scavenger.py --snapshot=1
 4773  clear && clear
 4774  top
 4775  nvidia-smi
 4776  top
 4777  clear
 4778  python utils/dsutil/slice_frames.py 
 4779  python utils/dsutil/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/Coutort1/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/Coutort1/frames'
 4780  cd /data/sunnycia/SaliencyDataset/Video/Coutort1
 4781  python generate_fixation.py 
 4782  clear && clear
 4783  python generate_fixation.py 
 4784  clear && clear
 4785  python generate_fixation.py 
 4786  clear && clear
 4787  python generate_fixation.py 
 4788  clear && python generate_fixation.py 
 4789  clear && clear
 4790  python generate_fixation.py 
 4791  clear && clear
 4792  python generate_fixation.py 
 4793  top
 4794  python generate_fixation.py 
 4795  df -h
 4796  python generate_fixation.py 
 4797  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4798  python utils/dsutil/gen_density.py 
 4799  python utils/dsutil/gen_density.py --fixation_base='/data/sunnycia/SaliencyDataset/Video/Coutort1/fixation' --sigma=32 --fixationtype='image' --density_base='/data/sunnycia/SaliencyDataset/Video/Coutort1/density'
 4800  top
 4801  clear
 4802  python utils/dsutil/gen_density.py 
 4803  python utils/dsutil/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/Coutort2/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/Coutort2/density' --fixationtype='image'
 4804  cd pwd/saliency_on_videoset/Train/scripts/
 4805  source set_env.sh ../C3D-v1.1 4
 4806  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-static-resnet-dropout' --modeliter=20000
 4807  nvidia-smi
 4808  cd pwd/saliency_on_videoset/Train/scripts/
 4809  source set_env.sh ../C3D-v1.1 7
 4810  clear && clear
 4811  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --inferoverlap=8 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --inferoverlap=12 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --inferoverlap=14
 4812  clear && clear
 4813  top
 4814  nvidia-smi
 4815  top
 4816  nvidia-smi
 4817  cd metric/
 4818  clear && clear
 4819  matlab -nodesktop -nodisplay
 4820  top
 4821  cd pwd/saliency_on_videoset/
 4822  cd Train/scripts/metric/
 4823  clear
 4824  matlab -nodesktop -nodisplay
 4825  nvidia-smi
 4826  cd pwd/saliency_on_videoset/Train/scripts/
 4827  clear
 4828  top
 4829  nvidia-smi
 4830  clear && clear
 4831  cd /data/sunnycia/saliency_on_videoset/Train/caffe-master
 4832  make clean && make -j8 all
 4833  top
 4834  cd ~/pwd/saliency_on_videoset/Train/scripts/
 4835  ls
 4836  cd /data/sunnycia/saliency_on_videoset/Train/metric-matlab/diem
 4837  cd ..
 4838  cd metric
 4839  ls
 4840  cd ..
 4841  cd scripts/metric/
 4842  matlab -nodesktop -nodisplay
 4843  clear && clear
 4844  matlab -nodesktop -nodisplay
 4845  cd pwd/saliency_on_videoset/Train/scripts/
 4846  python utils/watcher.py 
 4847  top
 4848  nvidia-smi
 4849  source set_env.sh ../C3D-v1.1 5
 4850  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputdir='./' --layer='conv1' --type='3d'
 4851  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputdir='./conv1.jpg' --layer='conv1' --type='3d'
 4852  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4853  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/deploy_p3d_resnet_sports1m.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4854  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4855  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1-new.jpg' --layer='conv1' --type='3d'
 4856  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1-new.jpg' --layer='res5b_branch2b' --type='3d'
 4857  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1-new.jpg' --layer='res2a_branch1' --type='3d'
 4858  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1-new.jpg' --layer='res2a_branch2a' --type='3d'
 4859  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='res2a_branch2a' --type='3d'
 4860  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4861  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='res5b_branch2a' --type='3d'
 4862  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC001.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --layername='conv1' 
 4863  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='res5b_branch2a' --type='3d'
 4864  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC001.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --layername='conv1' 
 4865  df - h
 4866  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC001.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --layername='res2b' 
 4867  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC001.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel'
 4868  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC041.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel'
 4869  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC041.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_126000.caffemodel'
 4870  ssh qiudan@172.31.234.248
 4871  clear && clear
 4872  git status
 4873  git add --all
 4874  git push -u origin master
 4875  git commit -m "add feature map visualization function. add jigsaw util"
 4876  git push -u origin master
 4877  ssh qiudan@172.31.234.248
 4878  clear && clear
 4879  ssh qiudan@172.31.234.248
 4880  du -h
 4881  du --help
 4882  du -d=1
 4883  du -d=1 /
 4884  du --max-depth=1
 4885  du --max-depth=1 /home/
 4886  su
 4887  top
 4888  top
 4889  nvidia-smi
 4890  top
 4891  nvidia-smi
 4892  top
 4893  nvidia-smi
 4894  top
 4895  cd /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505
 4896  bash configure
 4897  make core'
 4898  make core
 4899  make clean
 4900  make core
 4901  make clean
 4902  bash configure
 4903  make core
 4904  make clean
 4905  ./configure
 4906  make -j4
 4907  su
 4908  make -j4
 4909  make clean
 4910  -j4 ./configure
 4911  ./configure -j2
 4912  ./configure
 4913  make clean
 4914  ./configure
 4915  svn
 4916  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4917  source set_env.sh ../C3D-v1.1 6
 4918  nvidia-smi
 4919  top
 4920  clear
 4921  nvidia-smi
 4922  clear
 4923  source set_env.sh ../C3D-v1.1 4
 4924  python utils/weight_visualization.py 
 4925  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1'
 4926  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1' -h
 4927  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1' type='3d'
 4928  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4929  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./res5b_branch2b.jpg' --layer='res5b_branch2b' --type='3d'
 4930  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./res2b_branch2b.jpg' --layer='res2b_branch2b' --type='3d'
 4931  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./deconv1.jpg' --layer='deconv1' --type='3d'
 4932  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./predict.jpg' --layer='predict' --type='3d'
 4933  top
 4934  clear
 4935  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./deconv2.jpg' --layer='deconv2' --type='3d'
 4936  python visualization_featuremap.py -h
 4937  python visualization_featuremap.py --videopath='' --deploypath='' --modelpath=''
 4938  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC041.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel'
 4939  cd /data/sunnycia/SaliencyDataset/Video/Hollywood2
 4940  rm -rf Hollywood2
 4941  df -h
 4942  tar -xzf Hollywood2-scenes.tar.gz 
 4943  rm -rf Hollywood2
 4944  gunzip Hollywood2-scenes.tar.gz 
 4945  cd ~/pwd/saliency_on_videoset/
 4946  cd ..
 4947  pwd
 4948  cd /data/sunnycia/SaliencyDataset/
 4949  cd ~/pwd/saliency_on_videoset/_Model/
 4950  matlab -nodesktop -nodisplay
 4951  matlab -nodeskop -nodisplay
 4952  top
 4953  top
 4954  cd pwd/saliency_on_videoset/_Model/
 4955  matlab -nodesktop -nodisplay
 4956  top
 4957  nvidia-smi
 4958  top
 4959  cd pwd/saliency_on_videoset/_Model/
 4960  matlab -nodesktop -nodisplay
 4961  matlab
 4962  matlab -nodesktop -nodisplay
 4963  clear && clear
 4964  cd /data/sunnycia/saliency_on_videoset/_Model
 4965  mkdir OBDL && mv kvbs_cvpr2015.rar OBDL && cd OBDL && unzip kvbs_cvpr2015.rar
 4966  pwd
 4967  ls
 4968  unrar kvbs_cvpr2015.rar 
 4969  unrar x kvbs_cvpr2015.rar 
 4970  cd DATA/
 4971  matlab -nodesktop -nodispaly
 4972  matlab -nodesktop -nodisplay
 4973  cd ../../
 4974  cd ../Train/
 4975  cd -
 4976  python gen_saliency_SALICON.py -h
 4977  python gen_saliency_SALICON.py --gpu=4 --framebase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/saliency_map/SALICON' && python gen_saliency_SALICON.py --gpu=4 --framebase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/saliency_map/SALICON'
 4978  top
 4979  cd ../Train/scripts/metric/
 4980  matlab -nodesktop -nodisplay
 4981  ls /home
 4982  pwd
 4983  ls
 4984  top
 4985  clear
 4986  cd pwd/saliency_on_videoset/Train/scripts/
 4987  git status
 4988  git push -u origin master
 4989  top
 4990  df -h
 4991  su
 4992  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1-kldloss
 4993  make clean
 4994  make -j4 all
 4995  make clean
 4996  make -j4 all
 4997  make -j8 pycaffe
 4998  cd ..
 4999  cd scripts/
 5000  cd prototxt/
 5001  ls
 5002  cd ..
 5003  clear
 5004  cd pwd/saliency_on_videoset/Train/scripts/
 5005  git stauts
 5006  git status
 5007  git add --all
 5008  git commit -m "add calculate process fps function"
 5009  top
 5010  su
 5011  top
 5012  cd ..
 5013  cd ~/pwd/
 5014  ls
 5015  git clone https://github.com/iamaaditya/image-compression-cnn.git
 5016  python
 5017  su
 5018  python
 5019  su
 5020  python
 5021  clear && clear
 5022  su
 5023  clear
 5024  python
 5025  clear
 5026  cd pwd/saliency_on_videoset/Train/scripts/
 5027  claer
 5028  source set_env.sh ../C3D-v1.1-tmp/ 3
 5029  nvidia-smi
 5030  top
 5031  nvidia-smi
 5032  top
 5033  cd pwd/saliency_on_videoset/Train/scripts/
 5034  python utils/dsutil/one2all.py 
 5035  python utils/dsutil/one2all.py --videodirbase='/data/sunnycia/SaliencyDataset/Video/Coutort2/fixation' --alldir='/data/sunnycia/SaliencyDataset/Video/Coutort2/fixation_all'
 5036  python  utils/dsutil/slice_frames.py 
 5037  python  utils/dsutil/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/Coutort2/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/Coutort2/frames'
 5038  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 5039  export CUDA_VISIBLE_DEVICES=4 && python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/Coutort2/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/Coutort2/saliency_map' --outputtype='image'
 5040  export CUDA_VISIBLE_DEVICES=4 && python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/Coutort2/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/Coutort2/saliency_map/xu_lstm' --outputtype='image'
 5041  top
 5042  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 5043  clear
 5044  python utils/model_guardian.py 
 5045  source set_env.sh  ../C3D-v1.1 4
 5046  nvidia-smi
 5047  source set_env.sh  ../C3D-v1.1 4
 5048  python utils/model_guardian.py 
 5049  cd /data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-bn-base_lr-0.01--batch-2_1515676931
 5050  python
 5051  cd -
 5052  python utils/model_guardian.py 
 5053  source set_env.sh ../C3D-v1.1 4python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-bn-base_lr-0.0001-snapshot-4000--batch-2_1515726293' --modeliter=20000
 5054  source set_env.sh ../C3D-v1.1 4 && python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-bn-base_lr-0.0001-snapshot-4000--batch-2_1515726293' --modeliter=20000
 5055  top
 5056  gem
 5057  ruby -v && gem -v && nodejs -v && jekyll -v &&  python --version
 5058  su
 5059  nodejs -v
 5060  nodejs
 5061  su
 5062  cd pwd/saliency_on_videoset/Train/scripts/
 5063  nvidia-smi
 5064  source set_env.sh ../C3D-v1.1 4
 5065  python utils/model_guardian.py --help
 5066  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-fixc2-drop-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-finetunefrom26k-batch-2_1515819089' --modeliter=20000
 5067  clear
 5068  cd /data/sunnycia/sunnycia.github.io/_posts/
 5069  ls
 5070  touch 2018-01-20-how-i-established-this-blog.md
 5071  ls
 5072  cd ..
 5073  ls
 5074  rm -rf *
 5075  git clone https://github.com/sharu725/krishna.git
 5076  cp -R  krishna/* ./ && rm -rf krishna/
 5077  ls
 5078  jekyll server
 5079  git add --all && git commit -m "change to krishna theme" 
 5080  git push -u origin master
 5081  clear
 5082  ls
 5083  git pull
 5084  ls
 5085  cd ..
 5086  rm -rf sunnycia.github.io/
 5087  top
 5088  su
 5089  history
 5090  top
 5091  nvidia-smi
 5092  clear
 5093  top
 5094  nvidia-smi
 5095  su
 5096  ruby -v
 5097  jekyll -v
 5098  matlab -v
 5099  matlab -nodisplay -nodesktop
 5100  python
 5101  su
 5102  go -v
 5103  go
 5104  go help
 5105  go version
 5106  top
 5107  nvidia-smi
 5108  su
 5109  python3
 5110  clear
 5111  nvidia-smi
 5112  cd /data/sunnycia/image_compression_challenge/_Train
 5113  unzip ImageCompression-master.zip 
 5114  cd ImageCompression-master/
 5115  ls
 5116  nvidia-smi
 5117  top
 5118  nvidia-smi
 5119  export CUDA_VISIBLE_DEVICES=2
 5120  python test_imp.py 
 5121  rar -h
 5122  unrar -h
 5123  unrar --help
 5124  unrar -help
 5125  unrar 
 5126  unrar x pycaffe.rar 
 5127  touce set_env.sh
 5128  touch set_env.sh
 5129  vim set_env.sh 
 5130  nvidia-smi
 5131  source set_env.sh 2
 5132  python
 5133  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 5134  source set_env.sh ../C3D-v1.1 2
 5135  python
 5136  cd -
 5137  source set_env.sh 0
 5138  ls
 5139  rm -rf pycaffe*
 5140  git clone https://github.com/taesikna/DPS.git
 5141  cd DPS/
 5142  ls
 5143  cp Makefile.config.example Makefile.config
 5144  vim Makefile.config
 5145  make -j8 all && make -j4 pycaffe
 5146  cd ..
 5147  vim set_env.sh 
 5148  source set_env.sh 2
 5149  python
 5150  source set_env.sh DPS/ 2
 5151  nvidia-smi
 5152  python test_imp.py 
 5153  python
 5154  ls
 5155  rm -rf DPS/
 5156  git clone https://github.com/sonack/my_caffe.git
 5157  unzip my_caffe-master.zip 
 5158  cd my_caffe-master/
 5159  ls
 5160  cp Makefile.config.example Makefile.config
 5161  vim Makefile.config
 5162  make -j8 all && make -j4 pycaffe
 5163  cd ..
 5164  source set_env.sh ./my_caffe-master 2
 5165  python test_imp.py 
 5166  [A
 5167  python test_imp.py 
 5168  ls
 5169  python test_entropy_encoder.py 
 5170  python binary_encoder.py
 5171  python create_lmdb_for_imp_map.py 
 5172  python test_
 5173  python test_imp.py 
 5174  touch read_caffemodel.py
 5175  vim read_caffemodel.py 
 5176  python read_caffemodel.py 
 5177  vim read_caffemodel.py 
 5178  python read_caffemodel.py 
 5179  vim read_caffemodel.py 
 5180  python read_caffemodel.py 
 5181  vim read_caffemodel.py 
 5182  python read_caffemodel.py 
 5183  python test_imp.py 
 5184  python read_caffemodel.py 
 5185  python test_imp.py 
 5186  nvidia-smi
 5187  top
 5188  cd ..
 5189  ls
 5190  cd ..
 5191  ls
 5192  cd _Train/
 5193  ls
 5194  git clone https://github.com/uclouvain/openjpeg.git
 5195  ls
 5196  unzip openjpeg-2.3.0.zip 
 5197  cd openjpeg-2.3.0/
 5198  mkdir build && cd build 
 5199  cmake .. -DCMAKE_BUILD_TYPE=Release && make -j4
 5200  su
 5201  cd ..
 5202  cd /data/sunnycia/image_compression_challenge/dataset
 5203  opj_compress -i KODAK_PNG/kodim22.png -o kodim22.jpeg
 5204  opj_compress -i KODAK_PNG/kodim22.png -o kodim22.j2k
 5205  opj_decompress -i kodim22.j2k kodim.jpeg
 5206  opj_decompress -i kodim22.j2k -o kodim.jpeg
 5207  opj_decompress -i kodim22.j2k -o kodim.png
 5208  libpng
 5209  ssh qiudan@172.31.234.205
 5210  clear
 5211  wget http://193.205.194.113/RAISE/TIFF/r00b3931bt.TIF
 5212  ls
 5213  rm -rf r00b3931bt.TIF 
 5214  ls
 5215  cd RAISE-1k/
 5216  python get_raise.py 
 5217  vim ~/.bashrc
 5218  vim ~/.wgetrc
 5219  source ~/.wgetrc 
 5220  python get_raise.py 
 5221  top
 5222  nvidia-smi
 5223  cd /data/sunnycia/image_compression_challenge/utils
 5224  ls
 5225  git clone https://github.com/Rolinh/VQMT.git
 5226  ls
 5227  cd VQMT/
 5228  ls
 5229  make -j2
 5230  ls
 5231  ls build/
 5232  ls build/bin/
 5233  ls build/bin/Release/
 5234  vqmt
 5235  vim ~/.bashrc
 5236  source ~/.bashrc
 5237  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 5238  python get_raise.py raise_1k_url-5.txt
 5239  su
 5240  top
 5241  nvidia-smi
 5242  top
 5243  su
 5244  nvidia-smi
 5245  top
 5246  nvidia-smi
 5247  claer
 5248  clear
 5249  top
 5250  nvidia-smi
 5251  ssh sunnycia@172.31.234.250
 5252  clear && clear
 5253  svn
 5254  cd /data/sunnycia/image_compression_challenge/_Train
 5255  svn export https://github.com/tensorflow/models/tree/master/research/compression compression_tfnn
 5256  cd tfnn_compression/image_encoder/
 5257  tar xf compression_residual_gru-2016-08-23.tar.gz 
 5258  python
 5259  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=2 --model='model/residual_gru.pb' 
 5260  nvidia-smi
 5261  export CUDA_VISIBLE_DEVICES=0
 5262  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=2 --model='model/residual_gru.pb' 
 5263  python decoder.py --input_codes='output.npz' --output_directory='output' --model='model/residual_gru.pb'
 5264  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=16 --model='model/residual_gru.pb' 
 5265  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=15 --model='model/residual_gru.pb' 
 5266  nvidia-smi
 5267  export CUDA_VISIBLE_DEVICES=
 5268  export CUDA_VISIBLE_DEVICES=1
 5269  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=15 --model='model/residual_gru.pb' 
 5270  python decoder.py --input_codes='output.npz' --output_directory='output' --model='model/residual_gru.pb'
 5271  cd /data/sunnycia/image_compression_challenge/_Train
 5272  unzip KDU7A2_Demo_Apps_for_Centos7-x86-64_170827.zip 
 5273  cd KDU7A2_Demo_Apps_for_Centos7-x86-64_170827/
 5274  vim ~/.bashrc
 5275  source ~/.bashrc
 5276  kdu_compress -h
 5277  kdu_compress
 5278  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression-master
 5279  ls
 5280  cd ..
 5281  cd /data/sunnycia/image_compression_challenge/dataset
 5282  opj_compress -i kodim22.png -o kodim22.jp2
 5283  opj_decompress  -i kodim22.jp2 -o kodim22-output.png
 5284  opj_compress -i kodim22.png -o kodim22.jp2 -r 20
 5285  ls
 5286  opj_compress -ImgDir KODAK_PNG/ -OutFor JP2 -r 200
 5287  cd ..
 5288  python compress_image.py --input_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --output_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000/compression_ration_200' --ratio=200 --output_dir='' --codec='jpeg2000'
 5289  python compress_image.py --input_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --output_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000/compression_ration_200' --ratio=200 --codec='jpeg2000'
 5290  bash jpeg2000_compress.sh 
 5291  python
 5292  clear
 5293  python
 5294  su
 5295  python -m visdom.server
 5296  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 5297  python get_raise.py 
 5298  python get_raise.py raise_1k_url-1.txt 
 5299  python
 5300  python -m visdom.server
 5301  df -h
 5302  su
 5303  clear
 5304  top
 5305  nvidia-smi
 5306  clear
 5307  ssh chenzihao@172.31.234.205
 5308  python
 5309  su
 5310  ssh chenzihao@172.31.234.205
 5311  clear
 5312  cd /data/sunnycia/image_compression_challenge
 5313  bash jpeg_compress.sh 
 5314  bash jpeg2000_compress.sh 
 5315  cd /data/sunnycia/image_compression_challenge/utils
 5316  git clone https://github.com/aizvorski/video-quality.git
 5317  cd /data/sunnycia/image_compression_challenge/utils/video-quality/demo
 5318  python jpg_demo.py 
 5319  gm
 5320  ls
 5321  python
 5322  cd ../..
 5323  cd ..
 5324  bash jpeg_compress.sh 
 5325  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg' && python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg2000'
 5326  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg'
 5327  top
 5328  cd /data/sunnycia/image_compression_challenge
 5329  bash jpeg2000_compress.sh 
 5330  top
 5331  top
 5332  clear
 5333  ssh qiudan@172.31.234.205
 5334  cd pwd/saliency_on_videoset/Train/scripts/
 5335  git status
 5336  git add --all
 5337  git commit -m "Add bn after deconvolution 3d"
 5338  git push -u origin master
 5339  history > history
 5340  source set_env.sh ../C3D-v1.1 6
 5341  nvidia-smi
 5342  .prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5343  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5344  python utils/scavenger.py 
 5345  python utils/scavenger.py --snapshot=1
 5346  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5347  python utils/scavenger.py --snapshot=1
 5348  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5349  python utils/scavenger.py 
 5350  python utils/scavenger.py --snapshot=1
 5351  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5352  python utils/scavenger.py 
 5353  python utils/scavenger.py --snapshot=1
 5354  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5355  python utils/scavenger.py --snapshot=1
 5356  python utils/scavenger.py 
 5357  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5358  python utils/scavenger.py 
 5359  python utils/scavenger.py --snapshot=1
 5360  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5361  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat-bnorm.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5362  clear && clear
 5363  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat-bnorm.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5364  top
 5365  nvidia-smi
 5366  cd pwd/saliency_on_videoset/Train/scripts/
 5367  source set_env.sh ../C3D-v1.1
 5368  python test_video.py 
 5369  source set_env.sh ../C3D-v1.1 5
 5370  python test_video.py --output_type='image' --test_base='coutort2' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --inferoverlap=15 
 5371  python utils/dsutil/gen_density.py 
 5372  python utils/dsutil/gen_density.py --fixationtype='image' --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/Coutort2/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/Coutort2/density'
 5373  cd metric/
 5374  matlab -nodesktop -nodisplay
 5375  cd /data/sunnycia/saliency_on_videoset/_Model
 5376  python gen_saliency_SALICON.py --gpu=3
 5377  python gen_saliency_SALICON.py --gpu=3 --framebase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/SALICON'
 5378  cd /data/sunnycia/SaliencyDataset/Video/DIEM
 5379  python frames_rename.py 
 5380  clear
 5381  cd -
 5382  python gen_saliency_SALICON.py --gpu=3 --framebase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/SALICON'
 5383  python gen_saliency_SALICON.py --gpu=4 --framebase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/SALICON'
 5384  python gen_saliency_SALICON.py --gpu=3 --framebase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/SALICON'
 5385  cd ../Train/scripts/metric/
 5386  clear && clear
 5387  matlab -nodesktop -nodisplay
 5388  clear && clear
 5389  cd ..
 5390  python training_video_voxel_based.py -h
 5391  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5392  source set_env.sh ../C3D-v1.1-kldloss/ 4
 5393  nvidia-smi
 5394  source set_env.sh ../C3D-v1.1-kldloss/ 5
 5395  clear && clear
 5396  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5397  python utils/scavenger.py 
 5398  python utils/scavenger.py --snapshot
 5399  python utils/scavenger.py --snapshot=1
 5400  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5401  python utils/scavenger.py 
 5402  python utils/scavenger.py --snapshot=1
 5403  clear && clear
 5404  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5405  clear && clear
 5406  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5407  nvidia-smi
 5408  source set_env.sh ../C3D-v1.1-tmp/ 3
 5409  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat-highlr.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5410  clear && clear
 5411  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5412  cd pwd/saliency_on_videoset/Train/scripts/
 5413  cd metric/
 5414  matlab -nodesktop -nodisplay
 5415  top
 5416  cd ..
 5417  source set_env.sh ../C3D-v1.1 7
 5418  nvidia-smi
 5419  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_snapshot='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-display-1--batch-2_1515247477/snapshot-_iter_272000.solverstate' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5420  top
 5421  nvidia-smi
 5422  top
 5423  nvidia-smi
 5424  watch -h
 5425  watch -n 1 nvidia-smi
 5426  to
 5427  top
 5428  nvidia-smi
 5429  su
 5430  ssh qiudan@172.31.234.205
 5431  su
 5432  cd /data/zhangpp/
 5433  ls
 5434  cd ..
 5435  ls /data
 5436  cd data/
 5437  ls -l
 5438  chmod 755 *
 5439  su
 5440  clear
 5441  df -h
 5442  clear
 5443  cd sunnycia/saliency_on_videoset/Train/scripts/
 5444  python calc_fps.py 
 5445  top
 5446  clear
 5447  su
 5448  clear
 5449  pwd
 5450  top
 5451  su
 5452  clear
 5453  gym
 5454  python
 5455  cd metric/
 5456  matlab -nodesktop -nodisplay
 5457  matlab 
 5458  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/density_fc
 5459  python rename.py 
 5460  cd -
 5461  matlab -nodesktop -nodisplay
 5462  cd -
 5463  matlab 
 5464  matlab -nodesktop -nodisplay
 5465  clear && clear
 5466  matlab -nodesktop -nodisplay
 5467  clear && clear
 5468  cd ..
 5469  python utils/model_guardian.py -h
 5470  source set_env.sh ../C3D-v1.1-kldloss/ 4
 5471  python utils/model_guardian.py --modeliter=20000 --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-kldloss-snapshot-4000--batch-2_1516181888'
 5472  clear && clear
 5473  source set_env.sh ../C3D-v1.1 3
 5474  nvidia-smi
 5475  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5476  cd ../../
 5477  cd Train/
 5478  cp C3D-v1.1 C3D-v1.1-tmp
 5479  cp -R C3D-v1.1 C3D-v1.1-tmp
 5480  cd C3D-v1.1-tmp/
 5481  make clean
 5482  make all && make -j2 pycaffe
 5483  cd scripts/
 5484  pwd
 5485  cd ../../scripts/
 5486  source set_env.sh ../C3D-v1.1-tmp/ 4
 5487  clear clear
 5488  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5489  clear && clear
 5490  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5491  top
 5492  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5493  top
 5494  cd pwd/saliency_on_videoset/Train/scripts/
 5495  ls
 5496  python training_video_voxel_based.py 
 5497  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' 
 5498  python training_video_voxel_based.py 
 5499  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k'
 5500  source set_env.sh ../C3D-v1.1 5
 5501  nvidia-smi
 5502  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k'
 5503  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 5504  nvidia-smi
 5505  top
 5506  cd /data/sunnycia/
 5507  ls
 5508  cd image_compression_challenge/
 5509  clear
 5510  top
 5511  nvidia-smi
 5512  clear
 5513  python plot_scatter.py -h
 5514  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK'
 5515  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 5516  cd utils/
 5517  python a_little_test.py 
 5518  top
 5519  nvidia-smi
 5520  cd .
 5521  cd ..
 5522  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK'
 5523  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 5524  matlab -nodesktop
 5525  firefox
 5526  top
 5527  cd /data/sunnycia/image_compression_challenge/
 5528  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/jpeg' 
 5529  VQMT
 5530  cd utils/
 5531  ls
 5532  cd VQMT/
 5533  ls
 5534  cd build/
 5535  ls
 5536  cd bin/
 5537  ls
 5538  cd Release/
 5539  ls
 5540  vqmt
 5541  vqmt -v
 5542  vqmt -h
 5543  vqmt --help
 5544  clear
 5545  pwd
 5546  vim ~/.bashrc
 5547  cd ../../..
 5548  cd ..
 5549  vqmt
 5550  bash webp_compress.sh KODAK
 5551  python image_metric.py -h
 5552  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --color_space='YVU'
 5553  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-psnr' --metric_index=11 --debug=True
 5554  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-psnr' --metric_index=11
 5555  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-ssim' --metric_index=15 
 5556  vim /usr/local/gpu_stuff
 5557  clear
 5558  cd /data/sunnycia/image_compression_challenge
 5559  clear
 5560  vim plotly_demo.py 
 5561  python plotly_demo.py 
 5562  ls ~/.ssh
 5563   python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/webp'
 5564  bash jpeg2000_compress.sh KODAK
 5565  python image_metric.py -h
 5566  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000'
 5567  vqmd
 5568  vqmt
 5569  vqmt /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV/jpeg/kodim24_quality_100_768_512_444.yuv /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv 512 768 1 1 results PSNR SSIM MSSIM VIFP
 5570  vqmt /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV/jpeg/kodim24_quality_10_768_512_444.yuv /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv 512 768 1 1 results PSNR SSIM MSSIM VIFP
 5571  vqmt /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV/jpeg/kodim24_quality_10_768_512_444.yuv /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv 512 768 1 1 results PSNR SSIM MSSIM VIFP PSNRHVS PSNRHVSM
 5572  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.9/bin
 5573  ls
 5574  TAppEncoderStatic
 5575  ./TAppEncoderStatic
 5576  ./TAppEncoderStatic -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt= 768 -hgt 512 -fr 1 -f 1 -q 47 -InputColourSpaceConvert=RGBtoGBR >> kodim24_result.txt
 5577  ./TAppEncoderStatic -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 -InputColourSpaceConvert=RGBtoGBR >> kodim24_result.txt
 5578  ./TAppEncoderStatic -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 -InputColourSpaceConvert RGBtoGBR >> kodim24_result.txt
 5579  ./TAppEncoderStatic -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 --InputColourSpaceConvert RGBtoGBR >> kodim24_result.txt
 5580  ./TAppEncoderStatic -c ../cfg/per-sequence/WordEditing_RGB.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 --InputColourSpaceConvert RGBtoGBR >> kodim24_result.txt
 5581  ./TAppEncoderStatic -c ../cfg/per-sequence/WordEditing_RGB.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 >> kodim24_result.txt
 5582  ./TAppEncoderStatic -c ../cfg/encoder_intra_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 >> result.txt
 5583  ./TAppEncoderStatic -c ../cfg/encoder_intra_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 >> result.txt
 5584  ./TAppEncoderStatic -c ../cfg/encoder_intra_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 30 -f 1 -q 47 >> result.txt
 5585  ./TAppEncoderStatic -c ../cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 >> result.txt
 5586  ./TAppEncoderStatic -c ../cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -SourceWidth=768 -SourceHeight=512 -fr 1 -f 1 -q 47 >> result.txt
 5587  ./TAppEncoderStatic -c ../cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 --SourceWidth=768 --SourceHeight=512 -fr 1 -f 1 -q 47 >> result.txt
 5588  python
 5589  cd /data/sunnycia/image_compression_challenge
 5590  pwd
 5591  python image_metric.py -h
 5592  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --color_space='YUV'
 5593  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --color_space='YVU'
 5594  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000' --color_space='YVU'
 5595  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' --color_space='YVU'
 5596  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' --color_space='YVU' && python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --color_space='YVU'&& python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000' --color_space='YVU'
 5597  bash jpeg2000_compress.sh KODAK
 5598  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000' --color_space='YVU'
 5599  cd /data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000
 5600  python
 5601  ls
 5602  cd /data/sunnycia/image_compression_challenge/dataset
 5603  convert kodim22-ori.png -quality 50 jp2.jp2
 5604  python
 5605  cd ..
 5606  bash jpeg_compress.sh KODAK
 5607  bash jpeg2000_compress.sh KODAK
 5608  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000' --color_space='YVU' && python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' --color_space='YVU'
 5609  bash hevc-jem_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_result
 5610  clear
 5611  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_result
 5612  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_recon /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_result
 5613  python image_metric.py -h
 5614  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir=' ' --color_space='YVU' --codec='hevc' 
 5615  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir=' ' --color_space='YVU' --codec='hevc' --hevc_result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_result'
 5616  python plot_scatter.py -h
 5617  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='psnr'
 5618  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='Y-psnr' --metric_index=5
 5619  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='Y-psnr' --metric_index=5 --debug=False
 5620  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='Y-psnr' --metric_index=5
 5621  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-psnr' --metric_index=11 --debug=True
 5622  bash hevc-jem_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc_recon /data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc_result
 5623  python image_metric.py -h
 5624  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir=' ' --color_space='YVU' --codec='jem_hevc' --hevc_result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc_result'
 5625  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir=' ' --color_space='YVU' --codec='hevc-jem' --hevc_result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc_result'
 5626  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-psnr' --metric_index=11 --debug=True
 5627  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./metric_data' --metric_name='Y-psnr' --metric_index=8 --debug=True --output_dir='./metric_data/KODAK-YPSNR'
 5628  bc
 5629  python -m visdom.server
 5630  clear
 5631  cd pwd/saliency_on_videoset/
 5632  cd ..
 5633  ls
 5634  cd /data/sunnycia/
 5635  ls
 5636  cd image_compression_challenge/
 5637  ls
 5638  python image_metric.py -h
 5639  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/jpeg2000' 
 5640  ssh qiudan@172.31.234.248
 5641  clear
 5642  cd /data/sunnycia/image_compression_challenge/
 5643  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/CLIC_MOB_YUV /data/sunnycia/image_compression_challenge/compress_set/CLIC_MOB_YUV
 5644  cd /data/sunnycia/image_compression_challenge/dataset
 5645  cd ..
 5646  bash jpeg2000_compress.sh 
 5647  bash jpeg2000_compress.sh CLIP_PRO && bash jpeg2000_compress.sh CLIP_MOB
 5648  clear && clear
 5649  bash jpeg2000_compress.sh CLIC_PRO && bash jpeg2000_compress.sh CLIC_MOB
 5650  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/CLIC_PRO_YUV /data/sunnycia/image_compression_challenge/compress_set/CLIC_PRO_YUV
 5651  vqmt
 5652  vqmt -h
 5653  vqmt --help
 5654  cd /data/sunnycia/image_compression_challenge/dataset
 5655  vqmt kodim22-ori.png kodim22.png 512 768 
 5656  vqmt kodim22-ori.png kodim22.png 512 768 1 1 results PSNR SSIM
 5657  vqmt kodim22-ori.png kodim22-ori.png 512 768 1 1 results PSNR SSIM
 5658  matlab -nodesktop -nodisplay
 5659  jpeg
 5660  ffempg
 5661  ffmpeg
 5662  ls
 5663  pwd
 5664  cd ..
 5665  man ffmpeg >ffmpeg.txt
 5666  ls
 5667  cd dataset/
 5668  ls
 5669  ffmpeg -i kodim-ori.png -compression_level=50 -o jpeg.jpeg
 5670  ffmpeg -i kodim-ori.png --compression_level=50 -o jpeg.jpeg
 5671  ffmpeg -i kodim-ori.png -o jpeg.jpeg
 5672  ffmpeg -i kodim-ori.png jpeg.jpeg
 5673  ls
 5674  ffmpeg -i kodim22-ori.png jpeg.jpeg
 5675  ffmpeg -i kodim22-ori.png jpeg.jpeg -compression_level=100
 5676  ffmpeg -i kodim22-ori.png jpeg.jpeg compression_level=100
 5677  ffmpeg -i kodim22-ori.png jpeg.jpeg compression_level=50
 5678  su
 5679  clear
 5680  cd /data/sunnycia/image_compression_challenge/_Train
 5681  python jpeg_compression.py 
 5682  su
 5683  clear
 5684  python jpeg_compression.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=50
 5685  python jpeg_compression.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=1
 5686  gimp
 5687  help screen
 5688  screen -h
 5689  python jpeg_compression.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=1
 5690  python img_compression_benchmark.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=1
 5691  python img_compression_benchmark.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=1 --codec='jpeg'
 5692  python img_compression_benchmark.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=100 --codec='jpeg'
 5693  touch kodak.sh
 5694  vim kodak.sh 
 5695  bash kodak.sh 
 5696  ls -la
 5697  cd ..dataset/
 5698  ls
 5699  cd ..
 5700  rm -rf ..dataset/
 5701  bash kodak.sh 
 5702  bash kodak.sh jpeg
 5703  bash kodak.sh webp
 5704  bash kodak.sh jpeg
 5705  bash kodak.sh webp
 5706  cd ..
 5707  matlab -nodesktop -nodisplay
 5708  matlab -nodesktop
 5709  bash compress.sh jpeg
 5710  matlab -nodesktop
 5711  python
 5712  python image_metric.py 
 5713  python image_metric.py -h
 5714  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --output_path=''
 5715  bash jpeg_compress.sh 
 5716  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg'
 5717  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000'
 5718  bash jpeg_compress.sh CLIC_PRO && bash jpeg_compress.sh CLIC_MOB
 5719  rm -rf /data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/jpeg
 5720  rm -rf /data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/jpeg2000/
 5721  bash jpeg_compress.sh CLIC_PRO && bash jpeg_compress.sh CLIC_MOB
 5722  clear && clear
 5723  cd _Train/
 5724  ls
 5725  cd HM-16.9/
 5726  ./bin/TAppEncoderStatic -c cfg\encoder_lowdelay_main.cfg -i sci_yuv\Im-7_719_904_444.yuv -o rec\Im-7_719_904_444_scc_.yuv -b stream\Im-7_719_904_444_scc_qp47.scc --InputChromaFormatqp47=444 --ConformanceWindowMode=1 -wdt 719 -hgt 904 -fr 30 -f 1 -q 47 >> result\Im-7_719_904_444_scc_qp47.txt
 5727  ./bin/TAppEncoderStatic -c cfg\encoder_lowdelay_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt  -hgt 904 -fr 30 -f 1 -q 47 
 5728  ./bin/TAppEncoderStatic -c cfg\encoder_lowdelay_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512 -fr 30 -f 1 -q 47 
 5729  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512 -fr 30 -f 1 -q 47 
 5730  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=420 --ConformanceWindowMode=1 -wdt 768  -hgt 512 -fr 30 -f 1 -q 47 
 5731  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512 -fr 30 -f 1 -q 47 
 5732  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 47 
 5733  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 47 -fr 1
 5734  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 15 -fr 1
 5735  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 15 -fr 1 >> result.txt
 5736  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv  --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 15 -fr 1
 5737  cd ../..
 5738  python hevc_compress.py -h
 5739  python hevc_compress.py --yuv_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_YUV' --result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV' --qp=50
 5740  clear && clear
 5741  python hevc_compress.py --yuv_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_YUV' --result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV' --qp=50
 5742  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV
 5743  vim hevc_compress.sh 
 5744  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV
 5745  bash jpeg2000_compress.sh CLIC_MOB
 5746  top
 5747  nvidia-smi
 5748  cd /data/sunnycia/image_compression_challenge/_Train/image-compression-cnn-master
 5749  nvidia-smi
 5750  export CUDA_VISIBLE_DEVICES=7
 5751  clear
 5752  python generate_map.py image.png 
 5753  python combine_images.py -image image.png -map output/msroi_map.jpg 
 5754  pip install webp-converter
 5755  clear
 5756  su
 5757  webpc
 5758  webp
 5759  su
 5760  clear
 5761  nvcc
 5762  nvcc -version
 5763  nvcc -v
 5764  nvcc --help
 5765  vim /etc/profile
 5766  nvcc
 5767  vim ~/.bashrc
 5768  to
 5769  top
 5770  nvidia-smi
 5771  top
 5772  kill -9 33546
 5773  top
 5774  nvidia-smi
 5775  clear
 5776  export CUDA_VISIBLE_DEVICES=7
 5777  python _batch_roi.py --img_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --roi_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_ROI'
 5778  convert -h
 5779  python combine_images.py -image image.png -map output/msroi_map.jpg 
 5780  cd ..
 5781  svn checkout 
 5782  svn checkout https://jvet.hhi.fraunhofer.de/svn/svn_HMJEMSoftware/tags/HM-16.6-JEM-7.1/doc/
 5783  clear
 5784  cd image-compression-cnn-master/
 5785  cd ..
 5786  python compress_image.py -h
 5787  python compress_image.py --input_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --output_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' --quality=50 --codec='webp' 
 5788  bash webp_compress.sh KODAK
 5789  bash webp_compress.sh CLIC_PRO && bash webp_compress.sh CLIC_MOB
 5790  python
 5791  su
 5792  clear
 5793  vim plotly_demo.py
 5794  python plotly_demo.py 
 5795  python
 5796  vim plotly_demo.py
 5797  python plotly_demo.py 
 5798  vim ~/.plotly/.credentials 
 5799  python plotly_demo.py 
 5800  vim plotly_demo.py 
 5801  top
 5802  nvidia-smi
 5803  clear
 5804  python image_metric.py -h
 5805  python image_metric.py --ref_dir=/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO'' --cps_dir='/data/sunnycia/image_compression_challenge/compress_set/CLIC_PRO/jpeg'
 5806  clear
 5807  python image_metric.py --ref_dir=/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO'' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg'
 5808  pwd
 5809  to
 5810  top
 5811  nvidia-smi
 5812  cd pwd/
 5813  pwd
 5814  git clone https://github.com/iamaaditya/image-compression-cnn.git
 5815  ls
 5816  cd /data/sunnycia/pwd
 5817  unzip image-compression-cnn-master.zip 
 5818  cd image-compression-cnn-master/
 5819  ls
 5820  python generate_map.py image.png 
 5821  export CUDA_VISIBLE_DEVICES=3
 5822  nvidia-smi
 5823  python generate_map.py image.png 
 5824  python generate_map.py -h
 5825  python generate_map.py image.png out.png
 5826  python combine_images.py -image image.png -map output/msroi_map.jpg 
 5827  python combine_images.py -image image.png -map output/msroi_map.jpg -print_metircs
 5828  python combine_images.py -image image.png -map output/msroi_map.jpg -print_metrics
 5829  python combine_images.py -image image.png -map output/msroi_map.jpg -print_metrics=1
 5830  su
 5831  gem install jekyll
 5832  su
 5833  pwd
 5834  cd /data/sunnycia/
 5835  ls
 5836  pwd
 5837  git clone https://github.com/sunnycia/sunnycia.github.io
 5838  ls
 5839  cd sunnycia.github.io/
 5840  ls
 5841  rm -rf *
 5842  git clone https://github.com/poole/hyde.git
 5843  ls
 5844  mv hyde/* ./
 5845  ls
 5846  rm -rf hyde/
 5847  ls
 5848  git status
 5849  git add --all
 5850  git commit -m "Add hyde jekyll theme"
 5851  git push -u origin maser
 5852  git push -u origin master
 5853  ls
 5854  git status
 5855  cd _posts/
 5856  ls
 5857  touch 2018-01-18-hello-world.md
 5858  cd ..
 5859  jekyll serve
 5860  jekyll serve --incremental
 5861  firefox
 5862  git status
 5863  git add --all
 5864  git status
 5865  git commit -m "first post"
 5866  git push -u origin master
 5867  git remote add origin https://github.com/sunnycia/sunnycia.github.io.git
 5868  git push -u origin master
 5869  vim _config.yml 
 5870  git add --all
 5871  git commit -m "I'm from future"
 5872  git push -u origin master
 5873  cd ..
 5874  jekyll sunnycia.github.io/
 5875  cd sunnycia.github.io/
 5876  jekyll -h
 5877  jekyll server
 5878  vim _config.yml 
 5879  jekyll server
 5880  top
 5881  clear
 5882  rm -rf *
 5883  ls
 5884  git clone https://github.com/poole/poole.git
 5885  ls
 5886  cp -R poole/* ./
 5887  ls
 5888  rm -rf poole/
 5889  ls
 5890  jekyll server
 5891  su
 5892  jekyll server
 5893  jekyll server --incremental
 5894  git add --all
 5895  git commit -m "Change theme"
 5896  git push -u origin master
 5897  cd _posts/
 5898  ls
 5899  cd ..
 5900  rm -rf *
 5901  git clone https://github.com/poole/hyde.git && cp hyde/* ./ && rm -rf hyde
 5902  ls
 5903  cp -R hyde/* ./ && rm -rf hyde
 5904  ls
 5905  git add --all && git commit -m "Change to hyde theme"
 5906  git push -u origin master
 5907  ls
 5908  jekyll server
 5909  su
 5910  jekyll server
 5911  su
 5912  jekyll server
 5913  git add --all
 5914  git commit -m "Debug Hyde theme"
 5915  git push -u origin master
 5916  rm -rf CNAME 
 5917  git add --all
 5918  git commit -m "Debug Hyde theme 2 "
 5919  git push -u origin master
 5920  jekyll server
 5921  git add --all && git commit -m "Edit info"
 5922  git push -u origin master
 5923  gem sourse -l
 5924  gem sorce -l
 5925  gem source -l
 5926  su
 5927  git status
 5928  df -h
 5929  ln -s /data/sunnycia/sunnycia.github.io ~/sunnycia.github.io
 5930  ls ~
 5931  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 5932  python utils/vizutil/image_table.py -h
 5933  python utils/vizutil/image_table.py --output_path='./msu.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --padding=10
 5934  python utils/vizutil/image_table.py --output_path='./msu.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --padding=5
 5935  python utils/vizutil/image_table.py --output_path='./diem.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --padding=5
 5936  python utils/vizutil/image_table.py --output_path='./MSU.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --padding=5
 5937  python utils/vizutil/image_table.py --output_path='./diem.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --padding=5
 5938  python utils/vizutil/image_table.py --output_path='./GAZECOM.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/frames' --padding=5
 5939  python utils/vizutil/image_table.py --output_path='./videoset.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frame' --padding=5
 5940  cd /data/sunnycia/SaliencyDataset/Video/DIEM
 5941  python 
 5942  ssh qiudan@172.31.234.248
 5943  clear
 5944  cd -
 5945  git stauts
 5946  git status
 5947  git add --all
 5948  git commit -m "add new feature concat network. add image table ffunction."
 5949  git push -u origin master
 5950  docker
 5951  cd /data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828
 5952  ls
 5953  python
 5954  clear
 5955  cd /data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/webp
 5956  cd /data/sunnycia/image_compression_challenge
 5957  nvidia-smi
 5958  top
 5959  nvidia-smi
 5960  kill -9 24019
 5961  clear
 5962  ls
 5963  python image_metric.py -h
 5964  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' && python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/webp' 
 5965  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/webp'
 5966  clear && clear
 5967  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/webp'
 5968  su
 5969  firefox
 5970  su
 5971  cd pwd/saliency_on_videoset/Train/
 5972  mv ../Tobii/ ../_Tobii
 5973  ls ..
 5974  cd scripts/
 5975  ls
 5976  python ss_test_video.py -h
 5977  source set_env.sh ../C3D-v1.1-tmp/ 3
 5978  nvidia-smi
 5979  source set_env.sh ../C3D-v1.1-tmp/ 5
 5980  python ss_test_video.py -h
 5981  python utils/model_guardian.py -h
 5982  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=116000
 5983  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=116000 --protocode=2
 5984  nvidia-smi
 5985  d f-h
 5986  df -h
 5987  ls utils/
 5988  ls utils/vizutil/
 5989  python utils/vizutil/visualization_weight.py -h
 5990  python utils/vizutil/visualization_weight.py -h --type='3d' --modelpath='heaven' --deploypath='' --outputpath='' --layer=''
 5991  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=164000 --protocode=2
 5992  nvidia-smi
 5993  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=212000 --protocode=2
 5994  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-dropout-snapshot-4000--batch-2_1516517784' --modeliter=44000 --protocode=2
 5995  cd /data/sunnycia/image_compression_challenge/CLIC_dataset
 5996  unzip mobile_*
 5997  unzip mobile_train.zip 
 5998  unzip professional_train.zip 
 5999  top
 6000  nvidia-smi
 6001  clear
 6002  cd -
 6003  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-fixc2-drop-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-finetunefrom26k-batch-2_1515819089' --modeliter=584000 --protocode=1
 6004  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=268000 --protocode=2
 6005  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000--batch-2_1515773757_usesnapshot_1515247477_snapshot-_iter_272000' --modeliter=89200 --protocode=1
 6006  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000--batch-2_1515773757_usesnapshot_1515247477_snapshot-_iter_272000' --modeliter=892000 --protocode=1
 6007  top
 6008  nvidia-smi
 6009  clear
 6010  nvidia-smi
 6011  clear
 6012  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-fixc2-drop-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-finetunefrom26k-batch-2_1515819089/snapshot-_iter_656000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 6013  cd metric/
 6014  matlab -nodesktop -nodisplay
 6015  cd ..
 6016  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-bnorm-snapshot-4000--batch-2_1516724056' --modeliter=120000 --protocode=2
 6017  nvidia-smi
 6018  source set_env.sh 7
 6019  nvidia-smi
 6020  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-bnorm-snapshot-4000--batch-2_1516724056' --modeliter=120000 --protocode=2
 6021  source set_env.sh 1
 6022  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-bnorm-snapshot-4000--batch-2_1516724056' --modeliter=120000 --protocode=2
 6023  source set_env.sh ../C3D-v1.1-tmp/ 7
 6024  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-bnorm-snapshot-4000--batch-2_1516724056' --modeliter=120000 --protocode=2
 6025  cd /data/sunnycia/image_compression_challenge/_Train
 6026  unzip image-compression-cnn-master.zip 
 6027  unzip benchmark.zip 
 6028  ls
 6029  svn -h
 6030  svn https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/HM-16.9/
 6031  svn export https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/HM-16.9/
 6032  svn checkout
 6033  svn checkout https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/HM-16.9/
 6034  tar xf HM-16.9.tar.gz 
 6035  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.9/build/linux
 6036  make -j3
 6037  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.9/bin
 6038  ./TAppDecoderAnalyserStatic
 6039  TAppEncoderStatic
 6040  ./TAppEncoderStatic
 6041  ./TAppEncoderStatic > TAppEncoderStatic_usage.txt
 6042  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 6043  matlab -nodesktop -nodisplay
 6044  clear && clear
 6045  cd ../..
 6046  cd _Train/
 6047  tar xf HM-16.6-JEM-7.1.tar.gz 
 6048  ls
 6049  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.6-JEM-7.1/build/linux
 6050  make -j4
 6051  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.6-JEM-7.1/doc
 6052  make
 6053  cd /data/sunnycia/image_compression_challenge
 6054  python image_metric.py -h
 6055  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg2000'
 6056  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg2000'
 6057  firefox
 6058  clear
 6059  cd /data/sunnycia/image_compression_challenge/
 6060  cd _Train/image-compression-cnn/
 6061  python _batch_roi.py -h
 6062  python _batch_roi.py --img_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --roi_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_ROI'
 6063  nvidia-smi
 6064  export CUDA_VISIBLE_DEVICES=7
 6065  python _batch_roi.py --img_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --roi_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_ROI'
 6066  ls
 6067  convert -colorspace sRGB -filter Lanczos -interlace Plane -type truecolor -quality 5 image.png wht.jpg
 6068  convert -colorspace sRGB -filter Lanczos -interlace Plane -type truecolor -quality 11 image.png wht.jpg
 6069  convert -colorspace sRGB -filter Lanczos -interlace Plane -type truecolor -quality 51 image.png wht.jpg
 6070  python
 6071  cd ..
 6072  ls
 6073  clear
 6074  cd utils/
 6075  ls
 6076  git clone https://github.com/Anserw/Bjontegaard_metric.git
 6077  ls
 6078  cd Bjontegaard_metric/
 6079  ls
 6080  python demo.py 
 6081  cd ..
 6082  git clone https://github.com/serge-m/bjontegaard2.git
 6083  cd ..
 6084  python calc_bdbr_bdpsnr.py -h
 6085  pytho calc_bdbr_bdpsnr.py --dataset=KODAK --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 6086  python calc_bdbr_bdpsnr.py --dataset=KODAK --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 6087  history > history
 6088  top
 6089  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 6090  python get_raise.py raise_1k_url-3.txt
 6091  top
 6092  nvidia-mis
 6093  nvidia-smi
 6094  cd /data/sunnycia/image_compression_challenge/
 6095  ls
 6096  python image_metric.py -h
 6097  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/tfrnn' --color_space='YVU' --codec='tfrnn' 
 6098  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./metric_data' --metric_name='Y-psnr' --metric_index=8 --debug=True --output_dir='./metric_data/KODAK-YPSNR' 
 6099  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./metric_data' --metric_name='Y-psnr' --metric_index=8  --output_dir='./metric_data/KODAK-YPSNR' 
 6100  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 6101  matlab -nodesktop -nodisplay
 6102  top
 6103  cd ..
 6104  bash hevc-jem_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/ffffjem_hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/ffffjem_hevc_recon /data/sunnycia/image_compression_challenge/compressed_set/KODAK/ffffjem_hevc_result
 6105  su
 6106  ls
 6107  clear
 6108  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 6109  matlab -nodesktop -nodisplay
 6110  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 6111  python get_raise.py raise_1k_url-4.txt
 6112  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 6113  python get_raise.py raise_1k_url-2.txt
 6114  cd /data/sunnycia/
 6115  cd image_compression_challenge/
 6116  history >history
 6117  cd /data/sunnycia/image_compression_challenge/_Train/tfnn_compression/image_encoder
 6118  python encoder.py --input_image='example.png' --output_codes=output_codes.pkl --iteration=15 --model=model/residual_gru.pb
 6119  export CUDA_VISIBLE_DEVICES=7
 6120  top
 6121  nvidia-smi
 6122  python encoder.py --input_image='example.png' --output_codes=output_codes.pkl --iteration=15 --model=model/residual_gru.pb
 6123  python decoder.py --input_codes=output_codes.pkl --iteration=15 --output_directory=output --model=model/residual_gru.pb
 6124  python encoder.py --input_image='example.png' --output_codes=output_codes.pkl --iteration=15 --model=model/residual_gru.pb
 6125  python compress.py -h
 6126  python compress.py --oridir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/tfrnn'
 6127  python compress.py --ori_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/tfrnn'
 6128  top
 6129  nvidia-smi
 6130  clear
 6131  cd ../..
 6132  cd ..
 6133  bash hevc_compress.sh ./dataset/KODAK_YUV420 ./compressed_set/KODAK/hevc420 ./compressed_set/KODAK/hevc420_recon 
 6134  bash hevc_compress.sh ./dataset/KODAK_YUV420 ./compressed_set/KODAK/hevc420 ./compressed_set/KODAK/hevc420_recon ./compressed_set/KODAK/hevc420_result
 6135  bash hevc_compress.sh dataset/KODAK_YUV420 compressed_set/KODAK/hevc420 compressed_set/KODAK/hevc420_recon compressed_set/KODAK/hevc420_result
 6136  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV420 /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc420 /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc420_recon /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc420_result
 6137  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/CLIC_PRO_YUV420 /data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/hevc420 /data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/hevc420_recon /data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/hevc420_result
 6138  python yuv_import.py 768x512
 6139  pip install YUV
 6140  pip install yuv
 6141  python
 6142  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 6143  ls
 6144  matlab -nodesktop -nodisplay
 6145  cd /data/sunnycia/image_compression_challenge/_Train/ARCNN
 6146  unzip ARCNN.zip 
 6147  ls
 6148  unzip AR-CNN\ test\ code.zip 
 6149  ls
 6150  cd ..
 6151  ls
 6152  git clone https://github.com/limuhit/TrimmedConvolution.git
 6153  clear
 6154  top
 6155  nvidia-smi
 6156  ls
 6157  top
 6158  nvidia-smi
 6159  watch -n 5 nvidia-smi
 6160  ping 172.31.234.250
 6161  ping 172.31.234.248
 6162  top
 6163  ls
 6164  top
 6165  nvidia-smi
 6166  su
 6167  ifconfig
 6168  top
 6169  nvidia-smi
 6170  nvidia
 6171  su
 6172  to
 6173  top
 6174  nvidia-smi
 6175  top
 6176  nvidia-smi
 6177  cd /data/sunnycia/SaliencyDataset/Video/MSU
 6178  tar cf frames frames.tar.gz
 6179  tar cf frames.tar.gz frames
 6180  nvidia-smi
 6181  cd /data/sunnycia/image_compression_challenge/Train/scripts/data/sunnycia/image_compression_challenge/Train/scripts
 6182  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6183  pwd
 6184  clear
 6185  export CUDA_VISIBLE_DEVICES=7
 6186  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir=''
 6187  clear && clear
 6188  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir=''
 6189  clear
 6190  topq
 6191  top
 6192  clear
 6193  cd /data/sunnycia
 6194  tar cf image_compression_challenge.tar.gz image_compression_challenge
 6195  top
 6196  cd /data/sunnycia/image_compression_challenge/dataset/KODAK
 6197  python
 6198  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6199  python Dataset.py 
 6200  clear
 6201  python Dataset.py 
 6202  python
 6203  python Dataset.py 
 6204  export CUDA_VISIBLE_DEVICES=7
 6205  nvidia-smi
 6206  export CUDA_VISIBLE_DEVICES=7
 6207  python training.py 
 6208  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO'
 6209  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir=''
 6210  pwd
 6211  vim ~/.bashrc
 6212  ssh chenzihao@172.31.70.212
 6213  ssh wangxu@172.31.70.212
 6214  clear
 6215  vim ~/.bashrc
 6216  ssh chenzihao@172.31.70.212
 6217  clear
 6218  nvidia-smi
 6219  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6220  python encoder.py 
 6221  python -m
 6222  python -m 'import caffe;caffe.__version__'
 6223  python -m 'import caffe;  caffe.__version__'
 6224  python -m 'import caffe,  caffe.__version__'
 6225  python -m 'caffe.__version__'
 6226  python -m 'caffe'
 6227  pytho -c 'import caffe;caffe.__version__'
 6228  python -c 'import caffe;caffe.__version__'
 6229  python -c 'import caffe; print caffe.__version__'
 6230  python -c 'import gym as g;print g.__version__'
 6231  python
 6232  python model.py 
 6233  source set_env.sh ../caffe-master 4
 6234  python model.py 
 6235  clear
 6236  python model.py 
 6237  clear && clear
 6238  python model.py 
 6239  python
 6240  python solver.py 
 6241  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model=''
 6242  python
 6243  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model=''
 6244  python inference.py 
 6245  clear && clear
 6246  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression 
 6247  python test_imp.py 
 6248  source set_env.sh my_caffe-master 6
 6249  python test_imp.py 
 6250  cd -
 6251  python inference.py 
 6252  df -h
 6253  python inference.py 
 6254  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1064000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6255  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1064000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6256  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6257  cd -
 6258  python visualization_weight.py --modelpath='/data/sunnycia/image_compression_challenge/_Train/ImageCompression/model/cmp/5.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6259  python visualization_weight.py --modelpath='/data/sunnycia/image_compression_challenge/_Train/ImageCompression/model/cmp/1.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6260  python inference.py 
 6261  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model=''
 6262  python inference.py 
 6263  su
 6264  python
 6265  su
 6266  python
 6267  su
 6268  python
 6269  top
 6270  python visualization_weight.py --modelpath='/data/sunnycia/image_compression_challenge/_Train/ImageCompression/model/cmp/1.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6271  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1064000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6272  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1064000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6273  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1164000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6274  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1164000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='inv_conv4'
 6275  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1164000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='pdata'
 6276  su 
 6277  nvidia-smi
 6278  tar -cf density.tar.gz density
 6279  cd /data/sunnycia/SaliencyDataset/Video/MSU
 6280  tar -cf density.tar.gz density
 6281  top
 6282  pwd
 6283  ls
 6284  ssh wangxu@172.31.70.212
 6285  ssh chenzihao@172.31.70.212
 6286  ssh root@172.31.70.212
 6287  ssh wangxu@172
 6288  ssh wangxu@172.31.70.212
 6289  ssh chenzihao@172.31.70.212
 6290  ssh wangxu@172.31.70.212
 6291  ssh chenzihao@172.31.70.212
 6292  ssh zhouyu@172.31.70.212
 6293  pwd
 6294  ssh chenzihao@172.31.70.212
 6295  ssh wangxu@172.31.70.212
 6296  ssh chenzihao@172.31.70.212
 6297  ssh wangxu@172.31.70.212
 6298  ssh chenzh@172.31.70.212
 6299  ssh wangxu@172.31.70.212
 6300  ssh chenzihao@172.31.70.212
 6301  ssh wangxu@172.31.70.212
 6302  ssh chenzihao@172.31.70.212
 6303  ssh wangxu@172.31.70.212
 6304  ls
 6305  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6306  unzip my_caffe-master.zip 
 6307  ls
 6308  cd my_caffe-master/
 6309  ls
 6310  make -j8 all && make pycaffe
 6311  cp Makefile.config.example Makefile.config
 6312  vim Makefile.config
 6313  make -j8 all && make pycaffe
 6314  cd ..
 6315  ls
 6316  nvidia-smi
 6317  source set_env.sh my_caffe 6
 6318  python
 6319  clear
 6320  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6321  ssh chenzihao@172.31.70.212
 6322  ssh wangxu@172.31.70.212
 6323  clear
 6324  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6325  ssh chenzihao@172.31.70.212
 6326  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6327   free -h
 6328  nvidia-smi
 6329  clear
 6330  source set_env.sh my_caffe 6
 6331  cd my_caffe/
 6332  make clean
 6333  vim Makefile.config
 6334  make -j16 all && make -j4 pycaffe
 6335  pip install --user --upgrade protobuf==3.1.0.post1
 6336  cd ..
 6337  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6338  cd my_caffe/
 6339  make install
 6340  make test
 6341  make -j8 test
 6342  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6343  cd ..
 6344  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6345  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6346  cd my_caffe/
 6347  vim Makefile.config
 6348  make clean
 6349  make -j8 all && make pycaffe
 6350  cd ..
 6351  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6352  nvidia-smi
 6353  source set_env.sh my_caffe 4
 6354  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6355  cd my_caffe/
 6356  make runtest
 6357  make -j8 runtest
 6358  cd ..
 6359  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6360  cd ..
 6361  cd ../_Train/
 6362  ls
 6363  cd ImageCompression/
 6364  ls
 6365  source set_env.sh my_caffe-master 4
 6366  python test_imp.py 
 6367  cd ../..
 6368  cd _Train/
 6369  cd ../Train/
 6370  unzip caffe-master.zip 
 6371  ls
 6372  cd caffe-master/
 6373  cp Makefile.config.example Makefile.config
 6374  vim Makefile.config
 6375  make -j8 all
 6376  cd ..
 6377  unzip caffe-master.zip 
 6378  cd caffe-master/
 6379  cp Makefile.config.example Makefile.config
 6380  make -j8 all
 6381  make clean
 6382  vim Makefile.config
 6383  make
 6384  make pycaffe
 6385  cd ..
 6386  cd scripts/
 6387  source set_env.sh ../caffe-master 4
 6388  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6389  source set_env.sh my_caffe 4
 6390  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6391  source set_env.sh ../my_caffe 4
 6392  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6393  source set_env.sh ../caffe-master 4
 6394  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6395  cd ../caffe-master/
 6396  vim Makefile.config
 6397  make clean
 6398  make -j2 all && make -j2 pycaffe
 6399  make clean
 6400  make -j2
 6401  make clean
 6402  make && make pycaffe
 6403  cd ..
 6404  cd scripts/
 6405  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6406  cd ../caffe-master/
 6407  make clean
 6408  vim Makefile.config
 6409  make -j8 all
 6410  vim /etc/profile
 6411  make clean
 6412  vim Makefile.config
 6413  make 
 6414  make clean
 6415  make -j4
 6416  make clean
 6417  make
 6418  cd ../scripts/
 6419  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6420  cd ../caffe-master/
 6421  make -j8 pycaffe
 6422  cd ../scripts/
 6423  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6424  cd ../caffe-master/
 6425  make clean
 6426  cd ../scripts/
 6427  cd -
 6428  make
 6429  make clean
 6430  make
 6431  make clean
 6432  make
 6433   make clean
 6434  make
 6435  make clean
 6436  make
 6437  cd -
 6438  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6439  cd -
 6440  make pycaffe
 6441  cd -
 6442  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6443  cd -
 6444  source set_env.sh ../caffe-master 4
 6445  cd -
 6446  source set_env.sh ../caffe-master 4
 6447  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6448  cd -
 6449  make clean
 6450  make -j8 all && make -j8 pycaffe
 6451  cd -
 6452  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6453  cd -
 6454  make clean
 6455  make -j8 all && make -j8 pycaffe
 6456  cd -
 6457  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6458  cd -
 6459  make clean
 6460  make -j8 all && make -j8 pycaffe
 6461  cd -
 6462  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6463  cd -
 6464  make clean
 6465  make -j8 all && make -j8 pycaffe
 6466  cd -
 6467  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6468  cd -
 6469  make clean
 6470  make -j8 all && make -j8 pycaffe
 6471  cd -
 6472  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6473  cd -
 6474  make clean
 6475  make -j8 all && make -j8 pycaffe
 6476  cd -
 6477  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6478  cd -
 6479  make clean
 6480  make -j16 all && make -j16 pycaffe
 6481  cd -
 6482  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6483  cd -
 6484  make clean
 6485  make -j16 all && make -j16 pycaffe
 6486  make clean
 6487  make -j16 all && make -j16 pycaffe
 6488  cd -
 6489  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6490  cd -
 6491  make clean
 6492  make -j16 all && make -j16 pycaffe
 6493  cd -
 6494  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6495  cd -
 6496  make clean
 6497  make -j16 all && make -j16 pycaffe
 6498  make clean
 6499  make -j16 all && make -j16 pycaffe
 6500  make clean
 6501  make -j16 all && make -j16 pycaffe
 6502  make clean
 6503  make -j16 all && make -j16 pycaffe
 6504  make clean
 6505  make -j16 all && make -j16 pycaffe
 6506  make clean
 6507  make -j16 all && make -j16 pycaffe
 6508  cd -
 6509  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6510  cd -
 6511  make clean
 6512  make -j16 all && make -j16 pycaffe
 6513  make clean
 6514  make -j16 all && make -j16 pycaffe
 6515  cd -
 6516  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6517  nvidia-smi
 6518  cd -
 6519  make clean
 6520  make -j16 all && make -j16 pycaffe
 6521  cd -
 6522  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6523  cd -
 6524  make clean
 6525  make -j16 all && make -j16 pycaffe
 6526  cd -
 6527  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6528  clear && clear
 6529  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6530  top
 6531  su
 6532  python
 6533  su
 6534  python
 6535  vim ~/.bashrc
 6536  ldconfig
 6537  python
 6538  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6539  history > history
 6540  su
 6541  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001'
 6542  python
 6543  cd ..
 6544  ls
 6545  cd caffe-master/
 6546  make clean
 6547  make -j16 all && make -j8 pycaffe
 6548  vim Makefile.config
 6549  make -j16 all && make -j8 pycaffe
 6550  make clean
 6551  make -j16 all && make -j8 pycafef
 6552  make clean
 6553  make -j8 all
 6554  top
 6555  nvidia-smi
 6556  make
 6557  make -j8
 6558  boost
 6559  make clean
 6560  make -j8
 6561  source ~/.bashrc
 6562  make clean
 6563  make -j8 all
 6564  vim ~/.bashrc
 6565  source ~/.bashrc
 6566  make -j8 all
 6567  vim ~/.bashrc
 6568  source ~/.bashrc
 6569  vim /etc/profile
 6570  su
 6571  clear && clear
 6572  python
 6573  top
 6574  nvidia-smi
 6575  top
 6576  python
 6577  ls /usr/local
 6578  vim /etc/profile
 6579  vim ~?.bashrc
 6580  vim ~/.bashrc
 6581  source ~/.bashrc
 6582  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6583  ls
 6584  python read_caffemodel.py 
 6585  clear && clear
 6586  top
 6587  nvidia-smi
 6588  clear && clear
 6589  top
 6590  nvidia-smi
 6591  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6592  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6593  python inference.py 
 6594  source set_env.sh ../caffe-master 4
 6595  python inference.py 
 6596  python visualize_featuremap.py 
 6597  python visualize_featuremap.py --image_path='kodim16-imp.png' --deploypath='prototxt/cwic_deploy.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_170000.caffemodel'
 6598  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_deploy.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_170000.caffemodel'
 6599  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_170000.caffemodel'
 6600  python inference.py 
 6601  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_170000.caffemodle'
 6602  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6603  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6604  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6605  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6606  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_deploy.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6607  python inference.py 
 6608  cat ~/.bashrc
 6609  python visualize_featuremap.py --image_path='kodim23.png'
 6610  python visualize_featuremap.py --image_path='kodim18.png'
 6611  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6612  source set_env.sh ../caffe-master 6
 6613  clear && clear
 6614  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-048' --batch=16  --compression_ratio=0.48
 6615  clear && clear
 6616  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-048' --batch=16  --compression_ratio=0.48 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-048/snapshot-_iter_290000.solverstate'
 6617  clear && clear
 6618  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-048' --compression_ratio=0.48 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-048/snapshot-_iter_200000.solverstate' --base_lr=0.00001 --batch=64
 6619  clear && clear
 6620  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-048' --compression_ratio=0.48 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-048/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6621  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6622  source set_env.sh ../caffe-master 5
 6623  python inference.py 
 6624  clear && clear
 6625  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-011' --batch=16  --compression_ratio=0.11
 6626  clear && clear
 6627  source set_env.sh ../caffe-master 5
 6628  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-011' --batch=16  --compression_ratio=0.11
 6629  clear && clear
 6630  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-011' --batch=16  --compression_ratio=0.11 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-011/snapshot-_iter_20000.solverstate'
 6631  clear && clear
 6632  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-011' --compression_ratio=0.11 --pretrained_model='cwic_training_output_fixw00001_ADAM_cmprto-011/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6633  clear && clear
 6634  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-011' --compression_ratio=0.11 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-011/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6635  nvidia-smi
 6636  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6637  clear && clear
 6638  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/datas      et/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir=      'cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6639  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6640  source set_env.sh ../caffe-master 6
 6641  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6642  source set_env.sh ../caffe-master 4
 6643  clear && clear
 6644  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6645  clear && clear
 6646  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-018/snapshot-_iter_120000.solverstate'
 6647  clear && clear
 6648  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-018' --compression_ratio=0.18 --pretrained_model='cwic_training_output_fixw00001_ADAM_cmprto-018/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6649  clear && clear
 6650  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-018' --compression_ratio=0.18 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-018/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6651  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6652  clear && clear
 6653  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6654  source set_env.sh ../caffe-master 6
 6655  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6656  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-028' --batch=16  --compression_ratio=0.28
 6657  source set_env.sh ../caffe-master 3
 6658  clear && clear
 6659  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-028' --batch=16  --compression_ratio=0.28
 6660  clear && clear
 6661  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-028' --batch=16  --compression_ratio=0.28 --use_snapshot='/snapshot-_iter_220000.solverstate'
 6662  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-028' --batch=16  --compression_ratio=0.28 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.solverstate'
 6663  clear && clear
 6664  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-028' --compression_ratio=0.28 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_200000.solverstate' --base_lr=0.00001 --batch=64
 6665  clear && clear
 6666  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-028' --compression_ratio=0.28 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6667  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6668  nvidia-smi
 6669  source set_env.sh ../caffe-master 5
 6670  clear && clear
 6671  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68
 6672  clear && clear
 6673  source set_env.sh ../caffe-master 7
 6674  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68
 6675  clear && clear
 6676  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68 --use_shapshot='cwic_training_output_fixw0001_ADAM_cmprto-068/snapshot-_iter_20000.solverstate'
 6677  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-068/snapshot-_iter_20000.solverstate'
 6678  clear && clear
 6679  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-068/snapshot-_iter_20000.solverstate'
 6680  clear && clear
 6681  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-068' --compression_ratio=0.68 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-068/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6682  python
 6683  nvidia-smi
 6684  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6685  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16
 6686  source set_env.sh ../caffe-master 5
 6687  clear && clear
 6688  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16
 6689  source set_env.sh ../caffe-master 4
 6690  clear && clear
 6691  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16
 6692  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6693  clear && clear
 6694  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6695  clear && clear
 6696  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6697  clear && clear
 6698  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6699  clear && clear
 6700  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6701  clear && clear
 6702  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6703  clear && clear
 6704  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM' --pretrained_model='cwic_training_output_fixw0001_ADAM/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6705  cd /data/sunnycia/image_compression_challenge/Train/caffe-master
 6706  make clean
 6707  make -j8 all
 6708  vim Makefile.config
 6709  make clean
 6710  make -j8 all
 6711  cd .
 6712  cd ..
 6713  cd scripts/
 6714  clear && clear
 6715  python
 6716  vim ~/.bashrc
 6717  clear
 6718  source set_env.sh ../caffe-master 7
 6719  nvidia-smi
 6720  python
 6721  cd ../caffe-master/
 6722  make pycaffe
 6723  cd -
 6724  clear
 6725  history > history
 6726  top
 6727  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001'
 6728  clear && clear
 6729  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001'
 6730  clear && clear
 6731  python
 6732  clear && clear
 6733  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001' --batch=1
 6734  clear && clear
 6735  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001' --batch=16
 6736  source set_env.sh ../caffe-master 4
 6737  clear && clear
 6738  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001' --batch=16
 6739  clear && clear
 6740  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001' --batch=16
 6741  clear && clear
 6742  top
 6743  nvidia-smi
 6744  top
 6745  free -h
 6746  top
 6747  nvidia-smi
 6748  top
 6749  nvidia-smi
 6750  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6751  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6752  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv3'
 6753  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv4'
 6754  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='blk1_branch2b'
 6755  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='blk1_branch2c'
 6756  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6757  top
 6758  nvidia-smi
 6759  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6760  history > history
